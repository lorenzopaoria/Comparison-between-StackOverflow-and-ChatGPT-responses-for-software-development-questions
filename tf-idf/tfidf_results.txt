Question 1:
A coworker of mine believes that any use of in-code comments (ie, not javadoc style method or class comments) is a code smell.  What do you think?


TF-IDF Scores:
class: 0.2264
code: 0.3141
comments: 0.6455
method: 0.2457
smell: 0.3967
style: 0.3787
think: 0.2070
use: 0.1717

Termine con il punteggio TF-IDF più alto: comments (0.6455)

Best Answer:
Only if the comment describes what the code is doing.
If I wanted to know what was happening in a method or block, I would read the code. I would hope, anyway, that any developers working on a given project were at least familiar enough with the development language to read what is written and understand what it is doing.
In some cases of extreme optimization, you might be using techniques that makes it difficult for someone to follow what your code is doing. In these cases, comments can and should be used to not only explain why you have such optimizations, but what the code is doing. A good rule of thumb would be to have someone else (or multiple other people) familiar with the implementation language and project look at your code - if they can't understand both the why and the how, then you should comment both the why and the how.
However, what's not clear in the code is why you have done something. If you take an approach that might not be obvious to others, you should have a comment that explains why you made the decisions that you did. I would suspect that you might not even realize that a comment is needed until after something like a code review, where people want to know why you did X instead of Y - you can capture your answer in the code for everyone else who looks at it in the future.
The most important thing, though, is to change your comments when you change your code. If you change an algorithm, be sure to update the comments with why you went with algorithm X over Y. Stale comments are an even bigger code smell.


TF-IDF Scores:
algorithm: 0.1786
answer: 0.0680
approach: 0.0768
bigger: 0.1069
cases: 0.1461
change: 0.2226
clear: 0.1021
code: 0.4233
comment: 0.3924
comments: 0.3480
decisions: 0.1069
developers: 0.0830
development: 0.0699
difficult: 0.0813
explain: 0.0870
familiar: 0.2138
follow: 0.0981
future: 0.1021
given: 0.0830
good: 0.0624
implementation: 0.0797
important: 0.0797
instead: 0.0768
know: 0.1126
language: 0.1221
like: 0.0423
look: 0.0782
looks: 0.0893
makes: 0.0662
method: 0.0662
multiple: 0.0813
needed: 0.0870
optimization: 0.0918
optimizations: 0.1021
people: 0.1324
project: 0.1378
read: 0.1626
realize: 0.0948
rule: 0.0918
smell: 0.1069
sure: 0.0797
suspect: 0.1021
techniques: 0.1021
thing: 0.0797
understand: 0.1564
update: 0.0893
used: 0.0654
using: 0.0553
want: 0.0558
went: 0.1069
working: 0.0719
written: 0.0893

Termine con il punteggio TF-IDF più alto: code (0.4233)

----------------------------------------------------------------------------------------------------

Question 4:
When starting a project for a company that's not primarily a programming company, one of the expectations is that there's a finished product at the end free of all bugs and does everything needed right away. However, that's rarely the case. 
What are some ways to manage expectations and explain to non-programmers how software development differs from other types of product development?


TF-IDF Scores:
away: 0.1978
bugs: 0.1978
case: 0.1438
company: 0.4261
development: 0.2916
end: 0.1733
explain: 0.1816
finished: 0.2232
free: 0.1978
manage: 0.2048
needed: 0.1816
non: 0.1816
product: 0.3834
programmers: 0.1663
programming: 0.1235
project: 0.1438
right: 0.1663
software: 0.1575
starting: 0.2131
types: 0.1864
ways: 0.1773

Termine con il punteggio TF-IDF più alto: company (0.4261)

Best Answer:
IMO, I've found that the transparency offered by agile processes (e.g. Scrum, Crystal, etc.) goes a long ways towards showing how development works to the average stakeholder.


TF-IDF Scores:
agile: 0.4337
average: 0.4543
development: 0.2968
goes: 0.4026
long: 0.3322
ways: 0.3609
works: 0.3386

Termine con il punteggio TF-IDF più alto: average (0.4543)

----------------------------------------------------------------------------------------------------

Question 9:
Sometimes, the things I have to do for my job are interesting and engaging.  Sometimes, they aren't.  Occasionally, they really aren't.
Do you have any particular strategies or tricks for dealing with those dull stretches when your brain would rather be doing anything other than what you're supposed to be doing, particularly when the Internet and its boundless opportunities for interesting Slack beckon?


TF-IDF Scores:
dealing: 0.3042
interesting: 0.5396
internet: 0.3316
job: 0.2521
particular: 0.2521
really: 0.2108
strategies: 0.3316
supposed: 0.2938
things: 0.1957
tricks: 0.3165

Termine con il punteggio TF-IDF più alto: interesting (0.5396)

Best Answer:
Increments. I will pick something that I can do, even if it's a small task (i.e. modify comments in code). Pretty soon, the perfectionist in me wants to do more and more stuff and I'm back rolling.


TF-IDF Scores:
code: 0.1517
comments: 0.3118
modify: 0.3658
pick: 0.3658
pretty: 0.2752
small: 0.3118
soon: 0.3658
stuff: 0.3292
task: 0.2976
wants: 0.3292

Termine con il punteggio TF-IDF più alto: modify (0.3658)

----------------------------------------------------------------------------------------------------

Question 16:
I have read a few articles on Internet about programming language choice in the enterprise. Recently many dynamic typed languages have been popular, i.e. Ruby, Python, PHP and Erlang. But many enterprises still stay with static typed languages like C, C++, C# and Java.
And yes, one of the benefits of static typed languages is that programming errors are caught earlier, at compile time, rather than at run time. But there are also advantages with dynamic typed languages. (more on Wikipedia)
The main reason why enterprises don't start to use languages like Erlang, Ruby and Python, seem to be the fact that they are dynamic typed. That also seem to be the main reason why people on StackOverflow decide against Erlang. See Why did you decide "against" Erlang.
However, there seem to be a strong criticism against dynamic typing in the enterprises, but I don't really get it why it is that strong.
Really, why is there so much criticism against dynamic typing in the enterprises? Does it really affect the cost of projects that much, or what? But maybe I'm wrong.


TF-IDF Scores:
advantages: 0.0808
benefits: 0.0762
caught: 0.0871
choice: 0.0871
compile: 0.0837
cost: 0.0837
decide: 0.1359
dynamic: 0.4184
earlier: 0.0837
erlang: 0.3648
errors: 0.0783
fact: 0.0783
internet: 0.0912
java: 0.0623
language: 0.0521
languages: 0.3274
like: 0.0722
main: 0.1387
maybe: 0.0742
people: 0.0565
php: 0.0808
popular: 0.0871
programming: 0.1009
projects: 0.0783
python: 0.1449
read: 0.0693
really: 0.1739
reason: 0.1359
recently: 0.0808
ruby: 0.1616
run: 0.0693
stackoverflow: 0.0783
start: 0.0623
static: 0.1449
stay: 0.0912
strong: 0.1824
time: 0.0970
typed: 0.4353
typing: 0.1673
use: 0.0395
wrong: 0.0837
yes: 0.0837

Termine con il punteggio TF-IDF più alto: typed (0.4353)

Best Answer:

The main reason why enterprises don't start to use languages like Erlang, Ruby and Python, seem to be the fact that they are dynamic typed.

I think this is only their primary excuse. The real reason is that businesses don’t really take them all that seriously and feel that they are perhaps a bit too amateur. Java and .NET are “big business names”, have good commercial marketing, commercial customer support, and are thus widely taken very seriously indeed.
It is unfortunate that there is practically no statically-typed language that is anywhere near as popular as the big business names. Why are open-source/free-software programming environments almost always dynamically typed? This might indicate that a statically-typed language is actually not that easy to make, and that dynamic typing is a “lazy man’s hack”. If that is the case, the businesses who decide against dynamically-typed languages might actually have a point.


TF-IDF Scores:
actually: 0.1717
big: 0.2154
bit: 0.0893
business: 0.2017
case: 0.0756
customer: 0.1121
decide: 0.0875
dynamic: 0.2154
dynamically: 0.2081
easy: 0.0912
erlang: 0.1174
fact: 0.1009
feel: 0.1040
free: 0.1040
good: 0.0685
java: 0.0802
language: 0.1340
languages: 0.1686
lazy: 0.1174
like: 0.0465
main: 0.0893
make: 0.0624
names: 0.2241
near: 0.1174
net: 0.0912
open: 0.1040
point: 0.0843
popular: 0.1121
primary: 0.1077
programming: 0.0649
python: 0.0932
real: 0.0912
really: 0.0746
reason: 0.1750
ruby: 0.1040
software: 0.0829
source: 0.0912
start: 0.0802
statically: 0.2241
support: 0.0932
taken: 0.1077
think: 0.0613
typed: 0.5604
typing: 0.1077
use: 0.0508
widely: 0.1174

Termine con il punteggio TF-IDF più alto: typed (0.5604)

----------------------------------------------------------------------------------------------------

Question 18:
At first glance, I'd say a good programming team needs to understand the following matters:

The details of the core language / framework
HTML, (asynchronous) javascript
SQL / data model
Usability / UI design
Security
Project management.

If this team is not complete: what is needed?


TF-IDF Scores:
asynchronous: 0.2405
complete: 0.1957
data: 0.1453
design: 0.1549
details: 0.1957
following: 0.1867
framework: 0.1867
good: 0.1403
html: 0.2296
javascript: 0.2131
language: 0.1373
management: 0.2066
matters: 0.2405
model: 0.2066
needed: 0.1957
needs: 0.1792
programming: 0.1330
project: 0.1549
say: 0.1549
security: 0.2296
sql: 0.2296
team: 0.3913
ui: 0.2131
understand: 0.1758

Termine con il punteggio TF-IDF più alto: team (0.3913)

Best Answer:
A good development team is nothing without some support: 
One major role that's missing is IT: systems administration, networking, etc. There are a lot of developers whose knowledge of how computer systems work stop at the compiler.
I'd also add a manager to handle vendor contracts and other support aspects of a development team.


TF-IDF Scores:
add: 0.1666
compiler: 0.2092
computer: 0.2092
developers: 0.1834
development: 0.3085
good: 0.1378
handle: 0.1875
knowledge: 0.2092
lot: 0.1639
manager: 0.2254
stop: 0.2254
support: 0.3751
systems: 0.4722
team: 0.3842
work: 0.1348

Termine con il punteggio TF-IDF più alto: systems (0.4722)

----------------------------------------------------------------------------------------------------

Question 57:
The coding standards for the code hosted in drupal.org suggest to use two spaces to indent the code; other sites suggest to use tabs to indent the code.
What is the proper indentation character for everything, and in every situation? Please explain the answer you give.


TF-IDF Scores:
answer: 0.1834
character: 0.2648
code: 0.3428
coding: 0.2410
explain: 0.2348
org: 0.2755
proper: 0.2886
sites: 0.2648
situation: 0.2648
suggest: 0.5510
use: 0.2499

Termine con il punteggio TF-IDF più alto: suggest (0.5510)

Best Answer:
Tabs
Now, of course, consistency matters more than either one, and a good IDE makes the differences negligible.  That said, the point of this thread is to be a holy war, so:
I prefer tabs:

They're a character specifically meant for indentation
They allow developers with different preferences in indentation size to change how it's the code looks without changing the code (separation of data and presentation for the proverbial win!)
It's impossible to half-indent something with tabs.  So when you copy code from some website that used 3 spaces into your 4-space indented file, you don't have to deal with misalignment.



TF-IDF Scores:
allow: 0.2052
change: 0.1608
changing: 0.2125
character: 0.2125
code: 0.2751
copy: 0.1989
course: 0.1989
data: 0.1399
developers: 0.1798
different: 0.1492
file: 0.1726
good: 0.1351
ide: 0.2125
looks: 0.1934
makes: 0.1434
matters: 0.2316
meant: 0.2316
point: 0.1663
prefer: 0.2316
said: 0.1839
size: 0.1934
space: 0.1989
specifically: 0.2211
used: 0.1417
website: 0.1989
win: 0.2316

Termine con il punteggio TF-IDF più alto: code (0.2751)

----------------------------------------------------------------------------------------------------

Question 73:
We often receive last minute requests from the business asking for an extra feature to be implemented.  The project manager is usually responsible for filtering out these requests as "must haves" or "nice to have", but there are cases where the business wants to squeeze all these features into a release.   Is there a good way to say NO to the business?  What steps can be taken to stop or minimize scope creep?


TF-IDF Scores:
asking: 0.1597
business: 0.4790
cases: 0.1270
extra: 0.1647
feature: 0.1647
features: 0.1597
good: 0.1085
implemented: 0.1647
manager: 0.1774
minimize: 0.1859
minute: 0.1859
nice: 0.1597
project: 0.1197
receive: 0.1859
release: 0.1859
requests: 0.3717
responsible: 0.1774
say: 0.1197
scope: 0.1859
squeeze: 0.1859
steps: 0.1859
stop: 0.1774
taken: 0.1705
usually: 0.1359
wants: 0.1597
way: 0.0935

Termine con il punteggio TF-IDF più alto: business (0.4790)

Best Answer:
Ask them what they want you to drop so you'll have the time to squeeze this latest request in.
I've not had to do this for a while, and when I did, I used it sparingly otherwise it loses it's potency.
I found it most effective towards the end of the phase when you were tidying stuff up or doing the little improvements and tweaks you'd agreed on in the planning stage.


TF-IDF Scores:
ask: 0.2744
effective: 0.3286
end: 0.2552
improvements: 0.3137
little: 0.2610
planning: 0.3137
request: 0.3015
squeeze: 0.3286
stage: 0.3286
stuff: 0.2823
time: 0.1747
used: 0.2010
want: 0.1714

Termine con il punteggio TF-IDF più alto: effective (0.3286)

----------------------------------------------------------------------------------------------------

Question 94:
I realize there have been lots of discussions about this type of thing and they often devolve into dogma around whether you ask the "100 logical pirates" type of questions or whether you get them to write "fizz buzz". 
I'm interested in what techniques and questions have been effective for you when interviewing potential developers for jobs. 
One technique per answer so we can vote on them, please.


TF-IDF Scores:
100: 0.2362
answer: 0.1636
ask: 0.2149
developers: 0.1999
effective: 0.2574
interested: 0.2574
jobs: 0.2457
logical: 0.2574
lots: 0.2457
questions: 0.3836
realize: 0.2281
technique: 0.2457
techniques: 0.2457
thing: 0.1918
type: 0.3573
write: 0.1658

Termine con il punteggio TF-IDF più alto: questions (0.3836)

Best Answer:
Besides real technical questions, and typically at the end of the interview I try to get a grasp of their level of interest in the industry and it's culture with questions like:

Have you seen anything recently programming-related that you found interesting and would like to recommend to other fellow programmers? A new language, tool, platform, technique, website?
Can you name any well known person in our industry whose work you like or find inspiring and why? (developer, web site founder, author, speaker, etc)
What are you reading now or what was the last software related book you read?
What programming related sites do you frequent?

Although failing to answer these questions at all (sadly it happens very frequently) does not mean a 'no-hire' to me, they say a lot about the way a person approaches the software development profession.


TF-IDF Scores:
answer: 0.0962
approaches: 0.1300
author: 0.1513
book: 0.1341
developer: 0.1150
development: 0.0988
end: 0.1175
frequently: 0.1341
happens: 0.1513
interesting: 0.1231
known: 0.1444
language: 0.0864
level: 0.1263
like: 0.1797
lot: 0.1050
mean: 0.1388
new: 0.0837
person: 0.2888
programmers: 0.1127
programming: 0.1674
questions: 0.3382
read: 0.1150
reading: 0.1263
real: 0.1175
recently: 0.1341
recommend: 0.1513
related: 0.3899
say: 0.0975
seen: 0.1175
site: 0.1513
sites: 0.1388
software: 0.2135
technical: 0.1513
technique: 0.1444
tool: 0.1444
try: 0.1086
typically: 0.1513
way: 0.0761
web: 0.1068
website: 0.1300
work: 0.0864

Termine con il punteggio TF-IDF più alto: related (0.3899)

----------------------------------------------------------------------------------------------------

Question 104:
We've often run across scenarios where the business will promise a client a new feature.  The business will promise that the feature be implemented in a specific way.  These technical details promised by the business are usually poor.  Unfortunately, client is now set and want this feature to be implemented in the way described by the business.
In the end, the business just wants this feature to be completed without regard to quality and maintainability.  Is there a good way to push back?  How can we explain to the business that providing technical details before the requirements have been gathered is a bad idea?


TF-IDF Scores:
bad: 0.1017
business: 0.6280
client: 0.1983
details: 0.1983
end: 0.0946
explain: 0.0991
feature: 0.4319
good: 0.0711
idea: 0.0946
implemented: 0.2159
new: 0.0674
promise: 0.2326
push: 0.1218
quality: 0.1118
requirements: 0.0926
run: 0.0926
set: 0.0875
specific: 0.0946
technical: 0.2437
unfortunately: 0.1218
usually: 0.0891
want: 0.0636
wants: 0.1047
way: 0.1840

Termine con il punteggio TF-IDF più alto: business (0.6280)

Best Answer:
That's an organizational issue.  If the higher-ups don't understand this, there's not much you can do.  Try to explain the issue to your non-technical bosses, but don't be surprised when you get nowhere.
It's is a common problem for developers working in non-development companies that, for whatever reason, sell software.
It's not a pleasant tactic, but you can just bludgeon them with evidence.  At the start of a project, write down exactly why it's going to fail (because technical details were poor) and email it to relevant people.  Keep emailing them throughout, and when the project eventually ends up a disaster with pissed off customers, cite those emails you sent at every opportunity.  It may generate some ill will, but there's really no good way to try to fix a systemic issue like that.


TF-IDF Scores:
common: 0.1330
details: 0.1363
developers: 0.1301
development: 0.1094
email: 0.1599
emails: 0.1675
eventually: 0.1599
evidence: 0.1599
exactly: 0.1439
explain: 0.1363
fix: 0.1599
generate: 0.1599
going: 0.1273
good: 0.0977
higher: 0.1330
issue: 0.4196
like: 0.0663
non: 0.2725
opportunity: 0.1599
people: 0.1037
problem: 0.1000
project: 0.2158
really: 0.1065
reason: 0.1248
relevant: 0.1484
sent: 0.1675
software: 0.1182
start: 0.1144
technical: 0.3350
try: 0.2405
understand: 0.1225
ups: 0.1675
way: 0.0843
working: 0.1127
write: 0.1079

Termine con il punteggio TF-IDF più alto: issue (0.4196)

----------------------------------------------------------------------------------------------------

Question 134:
How do you bill your programming projects? Do you do it per hour? Per job? 
Please include what kind of project you are doing in the answer. (Mobile, Web, Desktop, etc... You can be more specific if you want.)
BONUS:
If you'd like to give specific amounts in your answer, you may. ;-)


TF-IDF Scores:
answer: 0.3953
desktop: 0.2969
include: 0.2672
job: 0.2365
kind: 0.2597
like: 0.1231
mobile: 0.3110
programming: 0.1720
project: 0.2004
projects: 0.2672
specific: 0.4830
want: 0.1623
web: 0.2195

Termine con il punteggio TF-IDF più alto: specific (0.4830)

Best Answer:
There's always going to be a struggle between you and the client over costs: you want to charge as much as you can from a client, and a client is going to want to get as much work for as little cost as possible.
So, when you charge hourly, it leaves open to negotiation how many hours a project should take to complete. You may think it'll take 10 hours, but your client thinks you should do it in 5.
By charging by project, there's very little open to negotiation: it costs $X, and the client can take it or leave it.


TF-IDF Scores:
10: 0.1269
client: 0.6499
complete: 0.1300
cost: 0.1466
costs: 0.3195
going: 0.2429
hours: 0.3195
leave: 0.1334
little: 0.2538
open: 0.2831
possible: 0.1109
project: 0.2058
think: 0.0834
want: 0.1667
work: 0.0912

Termine con il punteggio TF-IDF più alto: client (0.6499)

----------------------------------------------------------------------------------------------------

Question 135:
Who in the software engineering and software development fields uses Twitter to tweet about relevant happenings in the field?


TF-IDF Scores:
development: 0.2881
field: 0.4046
fields: 0.3502
relevant: 0.3907
software: 0.6223
uses: 0.3012

Termine con il punteggio TF-IDF più alto: software (0.6223)

Best Answer:
I'll probably get flamed for this but...
140 characters is hardly the format to get any real pearls of programming wisdom.  Most (but not all) programming concepts/thoughts/ideas require more space to be articulated. I would follow the blogs of the list of programmers that everyone is suggesting.


TF-IDF Scores:
characters: 0.2708
concepts: 0.3009
follow: 0.2892
format: 0.3009
list: 0.2120
probably: 0.2263
programmers: 0.2349
programming: 0.3487
real: 0.2448
require: 0.2565
space: 0.2708
suggesting: 0.3009
wisdom: 0.3152

Termine con il punteggio TF-IDF più alto: programming (0.3487)

----------------------------------------------------------------------------------------------------

Question 163:
Are there any great programming or software development books that are language agnostic?  Why should I read it?


TF-IDF Scores:
books: 0.4810
development: 0.3425
great: 0.4265
language: 0.2993
programming: 0.2900
read: 0.3986
software: 0.3700

Termine con il punteggio TF-IDF più alto: books (0.4810)

Best Answer:
The Pragmatic Programmer: From Journeyman to Master - Andrew Hunt and David Thomas
This book is all about how to write code that works and is maintainable. A key concept is being practical. Everything in the book is boiled down to 70 tips that are easy to remember that help you deliver better, higher-quality software.


TF-IDF Scores:
better: 0.1665
book: 0.4825
code: 0.1078
concept: 0.2413
easy: 0.2114
help: 0.1921
higher: 0.2162
maintainable: 0.2498
master: 0.2498
pragmatic: 0.2722
programmer: 0.2029
quality: 0.2498
remember: 0.2498
software: 0.1921
tips: 0.2599
works: 0.2029
write: 0.1754

Termine con il punteggio TF-IDF più alto: book (0.4825)

----------------------------------------------------------------------------------------------------

Question 188:
For the longest time in places like Java's IRC channel, SO, and other places I've been told something along the lines of "Worry about how the code looks and its readability/understandability now, and performance later if absolutely necessary". So for the longest time, I haven't really been OCD about performance for my small desktop or web apps, just removing the obviously inefficient.
Most responses are "What about scalability?". Thats a legitimate point, but if my app was only built to parse, say, files 10,000 lines long, should I make my code a mess for the small percentage of people that are going to shove in a 1,000,000 line file?
My main question is when should I trade the easy but somewhat inefficient ways of doing tasks for big giant complicated beasts that do things extremely quickly but destroy any possible ways of upgrading and make the code excessively difficult and prone to rewriting anyway by the next developer? 


TF-IDF Scores:
10: 0.1188
app: 0.1188
apps: 0.1427
big: 0.1372
built: 0.1427
channel: 0.1495
code: 0.1776
complicated: 0.1372
desktop: 0.1427
developer: 0.1137
difficult: 0.1137
easy: 0.1161
extremely: 0.1427
file: 0.1114
files: 0.1495
going: 0.1137
java: 0.1021
later: 0.1285
like: 0.0592
line: 0.1217
lines: 0.2991
long: 0.1093
looks: 0.1249
main: 0.1137
make: 0.1590
necessary: 0.1325
people: 0.0926
performance: 0.2569
places: 0.2650
point: 0.1074
possible: 0.1038
prone: 0.1427
question: 0.0904
quickly: 0.1427
readability: 0.1427
really: 0.0950
say: 0.0963
small: 0.2433
somewhat: 0.1495
tasks: 0.1372
things: 0.0883
time: 0.1590
told: 0.1427
ways: 0.2375
web: 0.1055
worry: 0.1325

Termine con il punteggio TF-IDF più alto: lines (0.2991)

Best Answer:
Worry about performance when it becomes a problem.
If you write a small app to process 10,000 line files and you get a 1,000,000 line file every 100th file, it probably doesn't matter that it takes longer to process that one file. However, if you are regularly getting files that are 5-10 times larger than initially and your application is taking too long to do its job, then you start profiling and optimizing.
Now, I said "too long to do its job". That is up to the user or sponsoring organization to decide. If I'm doing a task and it takes me 5 minutes to do something when it took me 3 without the software or with a different tool, I'd probably file a bug report or maintenance request to have that improved.
If you are the user, how long you want your software to take to do its job is up to you - only you can decide if you want it done faster or if you are willing to wait longer to have more readable code.


TF-IDF Scores:
10: 0.2002
app: 0.1001
application: 0.1052
bug: 0.1156
code: 0.0499
decide: 0.1878
different: 0.0812
faster: 0.1260
file: 0.3756
files: 0.2520
getting: 0.1025
job: 0.2874
larger: 0.1156
line: 0.2051
long: 0.2764
longer: 0.2312
matter: 0.1156
minutes: 0.1260
optimizing: 0.1260
performance: 0.1083
probably: 0.1810
problem: 0.0752
process: 0.1957
readable: 0.1203
request: 0.1156
said: 0.1001
small: 0.1025
software: 0.1779
start: 0.0861
takes: 0.1779
task: 0.0979
times: 0.0958
took: 0.1203
tool: 0.1203
user: 0.1722
want: 0.1315
willing: 0.1260
worry: 0.1117
write: 0.0812

Termine con il punteggio TF-IDF più alto: file (0.3756)

----------------------------------------------------------------------------------------------------

Question 192:
If I have some code that has 80% test coverage (all tests pass), is it fair to say that it's of higher quality than code with no test coverage?  
Or is it fair to say it's more maintainable?


TF-IDF Scores:
80: 0.3335
code: 0.2640
higher: 0.2649
maintainable: 0.3060
pass: 0.2785
quality: 0.3060
say: 0.4297
test: 0.4876
tests: 0.2485

Termine con il punteggio TF-IDF più alto: test (0.4876)

Best Answer:
By one definition it's more maintainable, as any breaking change is more likely to be caught by the tests.
However, the fact that code passes the unit tests doesn't mean it's intrinsically of higher quality. The code might still be badly formatted with irrelevant comments and inappropriate data structures, but it can still pass the tests.
I know which code I'd prefer to maintain and extend.


TF-IDF Scores:
breaking: 0.2067
caught: 0.2067
change: 0.1503
code: 0.2572
comments: 0.1762
data: 0.1308
definition: 0.1987
extend: 0.2165
fact: 0.1860
higher: 0.1720
know: 0.1140
likely: 0.1681
maintain: 0.2067
maintainable: 0.1987
mean: 0.1987
pass: 0.1808
passes: 0.1919
prefer: 0.2165
quality: 0.1987
structures: 0.2165
tests: 0.4841
unit: 0.1646

Termine con il punteggio TF-IDF più alto: tests (0.4841)

----------------------------------------------------------------------------------------------------

Question 206:
Test driven development. I get it, like it.
But writing tests does require overhead. So should TDD be used universally throughout the code base, or are there areas where TDD provides a high ROI and other areas where the ROI is so low that it is not worth following.


TF-IDF Scores:
base: 0.2738
code: 0.1084
development: 0.1789
driven: 0.2426
following: 0.2126
high: 0.2512
like: 0.1084
low: 0.2738
overhead: 0.2512
provides: 0.2352
require: 0.2228
tdd: 0.4852
test: 0.2002
tests: 0.2040
used: 0.1675
worth: 0.2426
writing: 0.2352

Termine con il punteggio TF-IDF più alto: tdd (0.4852)

Best Answer:
I'd say avoid TDD in places where the code is likely to change structurally a lot.  Ie, it's great to have a pile of tests for a method whose signature changes rarely but gets refactored internally more frequently, but it sucks to have to fix your tests every time a highly volatile interface changes dramatically.
The apps I've been working on recently have been data-driven webapps built on a Gui->Presenter->BusinessLogic->Data Access Layer-based architecture.  My data access layer is tested like nobody's business.  The business logic layer is pretty well tested.  The Presenters are only tested in the more stable areas, and the GUI, which is changing hourly, has almost no tests.


TF-IDF Scores:
access: 0.2150
apps: 0.1350
architecture: 0.1414
avoid: 0.1215
based: 0.1034
built: 0.1350
business: 0.2429
change: 0.0981
changes: 0.2429
changing: 0.1297
code: 0.0560
data: 0.2563
driven: 0.1253
fix: 0.1350
frequently: 0.1253
gets: 0.1297
great: 0.1150
interface: 0.1075
layer: 0.3759
like: 0.0560
likely: 0.1098
logic: 0.1150
lot: 0.0981
method: 0.0876
places: 0.1253
pretty: 0.1015
recently: 0.1253
refactored: 0.1414
say: 0.0911
tdd: 0.1253
tested: 0.4242
tests: 0.3161
time: 0.0752
working: 0.0951

Termine con il punteggio TF-IDF più alto: tested (0.4242)

----------------------------------------------------------------------------------------------------

Question 215:
Having taken a course in Operating Systems I'm interested in expanding my knowledge of the Linux kernel and practice working with a big system. What are some interesting but not overly difficult projects I can try my hand at? 
EDIT: a bit of background on what I did do with the kernel. 

Implemented a new scheduling policy
Implemented User Threads and a corresponding mutex library (not really kernel hacking but contained kernel related theory)



TF-IDF Scores:
background: 0.2003
big: 0.2074
bit: 0.1719
corresponding: 0.2261
course: 0.1942
difficult: 0.1719
edit: 0.1942
hand: 0.1796
implemented: 0.4007
interested: 0.2261
interesting: 0.1839
knowledge: 0.2003
library: 0.2074
new: 0.1250
practice: 0.2003
projects: 0.1942
really: 0.1437
related: 0.1942
systems: 0.2261
taken: 0.2074
threads: 0.2261
try: 0.1623
user: 0.1544
working: 0.1521

Termine con il punteggio TF-IDF più alto: implemented (0.4007)

Best Answer:
It depends on your existing background. If you are an embedded developer, you can write or improve some device driver. There aren't many other task to do in the kernel, unless you want to write a new process scheduler of course. I would suggest instead to study the existing source, it is a boring task but for a beginner it is almost the only thing to do.


TF-IDF Scores:
background: 0.2252
course: 0.2183
depends: 0.2332
developer: 0.1932
existing: 0.4366
instead: 0.1825
new: 0.1406
process: 0.1973
source: 0.1973
study: 0.2426
suggest: 0.2426
task: 0.3947
thing: 0.1894
unless: 0.2332
want: 0.1326
write: 0.3274

Termine con il punteggio TF-IDF più alto: existing (0.4366)

----------------------------------------------------------------------------------------------------

Question 220:
How would someone implement Agile process concepts as a solo developer?  Agile seems useful for getting applications developed at a faster pace, but it also seems very team oriented...


TF-IDF Scores:
agile: 0.5493
applications: 0.2550
concepts: 0.2747
developer: 0.2187
faster: 0.2877
getting: 0.2341
implement: 0.2234
oriented: 0.2877
process: 0.2234
solo: 0.2877
team: 0.2341
useful: 0.2285

Termine con il punteggio TF-IDF più alto: agile (0.5493)

Best Answer:

By doing test-driven development
By developing in small sprints
By having a lot of contact with the customer

I remember reading a thesis about Cowboy Development, that is essentially Agile for solo developers. The thesis can be read here: Cowboy: An Agile Programming Methodology For a Solo Programmer (PDF)


TF-IDF Scores:
agile: 0.4635
customer: 0.2317
developers: 0.1885
developing: 0.1975
development: 0.3172
driven: 0.2151
lot: 0.1685
programmer: 0.1809
programming: 0.1343
read: 0.1846
reading: 0.2027
remember: 0.2227
small: 0.1975
solo: 0.4855
test: 0.1775

Termine con il punteggio TF-IDF più alto: solo (0.4855)

----------------------------------------------------------------------------------------------------

Question 221:

Possible Duplicate:
Using “Foo” and “Bar” in examples 

I know AT&T labs used them in their Unix days, but do they have even deeper histories?


TF-IDF Scores:
days: 0.4789
examples: 0.4082
foo: 0.5016
know: 0.2642
possible: 0.3482
used: 0.3068
using: 0.2593

Termine con il punteggio TF-IDF più alto: foo (0.5016)

Best Answer:
From the Jargon file:

When ‘foo’ is used in connection with ‘bar’ it has generally traced to the WWII-era Army slang acronym FUBAR (‘Fucked Up Beyond All Repair’ or ‘Fucked Up Beyond All Recognition’), later modified to foobar. Early versions of the Jargon File interpreted this change as a post-war bowdlerization, but it it now seems more likely that FUBAR was itself a derivative of ‘foo’ perhaps influenced by German furchtbar (terrible) — ‘foobar’ may actually have been the original form.
For, it seems, the word ‘foo’ itself had an immediate prewar history in comic strips and cartoons. The earliest documented uses were in the Smokey Stover comic strip published from about 1930 to about 1952. Bill Holman, the author of the strip, filled it with odd jokes and personal contrivances, including other nonsense phrases such as “Notary Sojac” and “1506 nix nix”. The word “foo” frequently appeared on license plates of cars, in nonsense sayings in the background of some frames (such as “He who foos last foos best” or “Many smoke but foo men chew”), and Holman had Smokey say “Where there's foo, there's fire”.



TF-IDF Scores:
actually: 0.1016
author: 0.1389
background: 0.1231
best: 0.1103
change: 0.0964
connection: 0.1326
file: 0.2070
foo: 0.8334
form: 0.1103
frequently: 0.1231
generally: 0.1193
later: 0.1193
likely: 0.1079
original: 0.1326
personal: 0.1160
post: 0.1326
say: 0.0895
terrible: 0.1389
used: 0.0850
uses: 0.0949
versions: 0.1389

Termine con il punteggio TF-IDF più alto: foo (0.8334)

----------------------------------------------------------------------------------------------------

Question 247:
Does learning COBOL still make sense?


TF-IDF Scores:
cobol: 0.6075
learning: 0.5314
make: 0.3384
sense: 0.4838

Termine con il punteggio TF-IDF più alto: cobol (0.6075)

Best Answer:
I don't think so, unless you are already in the niche market where COBOL is still maintained.


TF-IDF Scores:
cobol: 0.6708
think: 0.3666
unless: 0.6447

Termine con il punteggio TF-IDF più alto: cobol (0.6708)

----------------------------------------------------------------------------------------------------

Question 252:
There is a widely accepted opinion that Singleton is an anti-pattern. As usual, there are always exceptions to the rule. Can you explain why Singleton is a bad choice in general and give an example of some valid use cases for it?


TF-IDF Scores:
accepted: 0.2493
bad: 0.2181
cases: 0.1784
choice: 0.2493
example: 0.1475
exceptions: 0.2396
explain: 0.2125
general: 0.2125
opinion: 0.2612
pattern: 0.2028
rule: 0.2243
singleton: 0.5223
use: 0.1131
usual: 0.2612
valid: 0.2125
widely: 0.2612

Termine con il punteggio TF-IDF più alto: singleton (0.5223)

Best Answer:
The two main criticisms of Singletons fall into two camps from what I've observed:

Singletons are misused and abused by less capable programmers and so everything becomes a singleton and you see code littered with Class::get_instance() references. Generally speaking there are only one or two resources (like a database connection for example) that qualify for use of the Singleton pattern.
Singletons are essentially static classes, relying on one or more static methods and properties. All things static present real, tangible problems when you try to do Unit Testing because they represent dead ends in your code that cannot be mocked or stubbed. As a result, when you test a class that relies on a Singleton (or any other static method or class) you are not only testing that class but also the static method or class.

As a result of both of these, a common approach is to use create a broad container object to hold a single instance of these classes and only the container object modifies these types of classes while many other classes can be granted access to them to use from the container object.


TF-IDF Scores:
access: 0.0895
approach: 0.0846
class: 0.3361
classes: 0.3582
code: 0.0933
common: 0.0935
connection: 0.1124
create: 0.0720
database: 0.0895
example: 0.0665
generally: 0.1012
instance: 0.1012
like: 0.0466
main: 0.0895
method: 0.1459
methods: 0.0846
object: 0.2276
pattern: 0.0915
present: 0.1124
problems: 0.0861
programmers: 0.0878
properties: 0.1044
real: 0.0915
references: 0.1124
represent: 0.0984
resources: 0.1081
result: 0.2087
single: 0.0958
singleton: 0.3533
static: 0.4677
test: 0.0861
testing: 0.1967
things: 0.0695
try: 0.0846
types: 0.0984
unit: 0.0895
use: 0.1530

Termine con il punteggio TF-IDF più alto: static (0.4677)

----------------------------------------------------------------------------------------------------

Question 262:
Will Java have the same importance it had in the past, or it will be less relevant than nowadays?


TF-IDF Scores:
java: 0.4721
past: 0.6341
relevant: 0.6124

Termine con il punteggio TF-IDF più alto: past (0.6341)

Best Answer:
I would say it's on a decline.  It's not gone, but it's past its peak.


TF-IDF Scores:
past: 0.8184
say: 0.5746

Termine con il punteggio TF-IDF più alto: past (0.8184)

----------------------------------------------------------------------------------------------------

Question 294:
I just started working a year ago, and I want to join an open source project for the same reasons as anyone else: help create something useful and develop my skills further.
My problem is, I don't know how to find a project where I'll fit in.
How can I find a beginner-friendly project?  What attributes should I be searching for?  What are warning signs that a project might not be the right fit?  Are there any tools out there to help match people with open source projects?
There's a similar question here, but that question has to do with employment and is limited to PHP/Drupal.


TF-IDF Scores:
attributes: 0.1773
create: 0.1085
develop: 0.1693
fit: 0.3386
help: 0.2503
know: 0.0934
limited: 0.1693
open: 0.3143
people: 0.1098
php: 0.1572
problem: 0.1059
project: 0.4570
projects: 0.1523
question: 0.2143
reasons: 0.1572
right: 0.1322
similar: 0.1348
skills: 0.1627
source: 0.2754
started: 0.1773
tools: 0.1523
useful: 0.1409
want: 0.0925
working: 0.1193
year: 0.1693

Termine con il punteggio TF-IDF più alto: project (0.4570)

Best Answer:
I suggest to start a project on your own on a topic that you're interested in. 
A lot can be learned by working on a project in general.  It is not needed to see how someone else codes to learn how to code better.  And sometimes you'll actually see what not to do as the other people are often no more experienced than you are.  
It usually helps to see other's code, but you will encounter other people's code in your own project just via the libraries and components you use.  
Experience will teach you what is good and bad practice.


TF-IDF Scores:
actually: 0.1612
bad: 0.1841
better: 0.1348
code: 0.2618
components: 0.1893
experience: 0.1841
experienced: 0.2204
general: 0.1793
good: 0.1286
helps: 0.2204
interested: 0.2204
learn: 0.1643
libraries: 0.2104
lot: 0.1530
needed: 0.1793
people: 0.2730
practice: 0.1953
project: 0.4260
start: 0.1506
suggest: 0.2104
topic: 0.2104
use: 0.0954
usually: 0.1612
working: 0.1483

Termine con il punteggio TF-IDF più alto: project (0.4260)

----------------------------------------------------------------------------------------------------

Question 348:
Elite developers can be 10x more productive than an average developer. 
Clearly it's easier to find an elite developer around the whole world than in a company's backyard. 
If a company is not located in a programming hot spot, should they consider hiring people who work from home?


TF-IDF Scores:
average: 0.2736
clearly: 0.2612
company: 0.5224
consider: 0.2425
developer: 0.4161
developers: 0.2125
easier: 0.2173
home: 0.2612
people: 0.1695
productive: 0.2612
programming: 0.1514
work: 0.1562
world: 0.2173

Termine con il punteggio TF-IDF più alto: company (0.5224)

Best Answer:
Maybe.
Your benefits are:

Access to a wider pool of candidates (as you point out)
Access to people who want to work at home

Your costs are:

More difficult communication- you can't just pull someone into a free conference room.
No guarantee of instant communication- if you're blocked and waiting for Joe Remote, you can't just go over to his desk and ask him what's up.  If he's incommunicado, you're SOL.
Not all developers work well remotely.  Some need the structured environment to be productive.
There's often no guarantee of matching schedules- eg, a work-from-home person might sleep in, or a person in another time-zone might be awake and working at different times than you.

Atwood had a decent article about it.
Edit, from Atwood's article:

The minimum remote team size is two. Always have a buddy, even if your buddy is on another continent halfway across the world.
Only grizzled veterans who absolutely love to code need apply for remote development positions. Mentoring of newbies or casual programmers simply doesn't work at all remotely.
To be effective, remote teams need full autonomy and a leader (PM, if you will) who has a strong vision and the power to fully execute on that vision.



TF-IDF Scores:
access: 0.2285
apply: 0.1379
ask: 0.1255
benefits: 0.1255
code: 0.0595
communication: 0.2663
costs: 0.1503
developers: 0.1167
development: 0.0982
different: 0.0968
difficult: 0.1143
edit: 0.1291
effective: 0.1503
environment: 0.1379
execute: 0.1291
free: 0.1332
guarantee: 0.3006
home: 0.2869
maybe: 0.1223
minimum: 0.1503
need: 0.2444
people: 0.0931
person: 0.2869
point: 0.1079
productive: 0.1435
programmers: 0.1120
simply: 0.1120
size: 0.1255
sleep: 0.1503
strong: 0.1503
team: 0.1223
time: 0.0799
times: 0.1143
want: 0.0784
work: 0.3431
working: 0.1011
world: 0.1194

Termine con il punteggio TF-IDF più alto: work (0.3431)

----------------------------------------------------------------------------------------------------

Question 368:
For a long time in SO and in other places Java has the reputation of being slow. From jokes to many comments in questions and answers, people still believe Java is slow based solely on experience with it in the 90s.
This is my issue: we have disproved (most) of the reasons that people believe Java is slow. Outside of small things, Java is pretty fast.
So why is it that people still refuse to believe Java is fast now? Is it part of their mindset that anything thats not C/C++ is slow? Is it because people don't check over time? Is it because people are just biased?


TF-IDF Scores:
answers: 0.1254
based: 0.1000
believe: 0.3763
check: 0.1062
comments: 0.1112
experience: 0.1142
issue: 0.1142
java: 0.4669
long: 0.1000
outside: 0.1174
people: 0.4233
places: 0.1212
pretty: 0.0982
questions: 0.1019
reasons: 0.1212
slow: 0.5220
small: 0.1112
things: 0.0807
time: 0.1454

Termine con il punteggio TF-IDF più alto: slow (0.5220)

Best Answer:
It's the applications. As you note, we have proved, time and time again, that in contrived scenarios Java code can meet or even beat the performance of so-called "performant" languages like C, C++, Lisp, VB6, or JavaScript. And when presented with such evidence, most sane, open-minded opponents will hang their heads in shame and promise never again to spread such slander.
...but then, they fire up Eclipse, or NetBeans, or Guiffy, or enable the Java support in their browser, or try to run an app on their favorite feature phone. And they wait for it to become responsive...
...and wait...


...and wait...




...and wait...








...and wait...












...and...





...what did I promise never to do again? Sorry, must have dozed off...


TF-IDF Scores:
app: 0.1825
applications: 0.2036
browser: 0.2297
called: 0.1825
code: 0.0910
evidence: 0.2193
feature: 0.2036
hang: 0.2297
java: 0.3139
javascript: 0.2036
languages: 0.1650
like: 0.0910
note: 0.1919
open: 0.2036
performance: 0.1974
phone: 0.2297
promise: 0.4386
run: 0.1747
support: 0.1825
time: 0.2443
try: 0.1650

Termine con il punteggio TF-IDF più alto: promise (0.4386)

----------------------------------------------------------------------------------------------------

Question 370:
I've been told that to be taken seriously as a job applicant, I should drop years of relevant experience off my résumé, remove the year I got my degree, or both. Or not even bother applying, because no one wants to hire programmers older than them.1
Or that I should found a company, not because I want to, or because I have a product I care about, but because that way I can get a job if/when my company is acquired.
Or that I should focus more on management jobs (which I've successfully done in the past) because… well, they couldn't really explain this one, except the implication was that over a certain age you're a loser if you're still writing code. But I like writing code.
Have you seen this? Is this only a local (Northern California) issue?
If you've ever hired programmers:2

Of the résumés you've received, how old was the eldest applicant?
What was the age of the oldest person you've interviewed?
How old (when hired) was the oldest person you hired?

How old is "too old" to employed as a programmer?
1 I'm assuming all applicants have equivalent applicable experience. This isn't about someone with three decades of COBOL applying for a Java guru job.
2 Yes, I know that (at least in the US) you aren't supposed to ask how old an applicant is. In my experience, though, you can get a general idea from a résumé.


TF-IDF Scores:
ask: 0.0994
care: 0.1136
certain: 0.1136
cobol: 0.1136
code: 0.0942
company: 0.2272
degree: 0.1136
equivalent: 0.1092
experience: 0.2981
explain: 0.0968
focus: 0.1136
general: 0.0968
got: 0.0994
idea: 0.0924
issue: 0.0994
java: 0.0813
job: 0.2714
jobs: 0.1136
know: 0.0627
like: 0.0471
local: 0.1092
management: 0.1022
old: 0.5460
older: 0.1190
past: 0.1092
person: 0.2272
product: 0.1022
programmer: 0.0887
programmers: 0.1774
really: 0.0756
relevant: 0.1055
remove: 0.0994
seen: 0.0924
supposed: 0.1055
taken: 0.1092
told: 0.1136
want: 0.0621
wants: 0.1022
way: 0.0599
writing: 0.2045
year: 0.1136
years: 0.1190
yes: 0.1092

Termine con il punteggio TF-IDF più alto: old (0.5460)

Best Answer:
Having just got a new job at nearly 50 in the UK I can say that it's possible and you're never too old.
There are two approaches - both rely on your skills being relevant to the job.

Stick with what you know and become a guru. This is risky as the number of jobs requiring "old" technologies are becoming fewer and further between as each year passes. However, as people retire from such jobs there will be openings.
Keep refreshing your skills. I moved into Silverlight last year, which is what got me this job. That and my previous team leadership roles which my new employer saw as relevant.



TF-IDF Scores:
approaches: 0.1468
fewer: 0.1631
got: 0.2854
job: 0.3897
jobs: 0.3262
know: 0.0900
new: 0.1890
number: 0.1167
old: 0.3135
passes: 0.1514
people: 0.1058
possible: 0.1186
previous: 0.1568
relevant: 0.3028
rely: 0.1631
say: 0.1101
skills: 0.3135
team: 0.1390
technologies: 0.1709
year: 0.3262

Termine con il punteggio TF-IDF più alto: job (0.3897)

----------------------------------------------------------------------------------------------------

Question 404:
Joel Spolsky wrote a famous blog post "Human Task Switches considered harmful".
While I agree with the premise and it seems like common sense, I'm wondering if there are any studies or white papers on this to calculate the overhead on task switches, or is the evidence merely anecdotal? 


TF-IDF Scores:
blog: 0.2828
common: 0.2534
considered: 0.3046
evidence: 0.3046
like: 0.1263
overhead: 0.2928
post: 0.3046
sense: 0.2426
task: 0.4956
wondering: 0.2928
wrote: 0.2928

Termine con il punteggio TF-IDF più alto: task (0.4956)

Best Answer:
The abstract of a study that says 'maybe'
Another study [PDF] that says interruptions make things seem like they took longer.
A study[PDF] that says interruptions increase resumption lag time, but that cues seen in the task before the interruption can speed recovery time.
Task switching[PDF] takes a significant portion of our work week.
More reading on the psychology of interruptions than you can shake a stick at.


TF-IDF Scores:
like: 0.0737
longer: 0.1709
make: 0.0990
maybe: 0.1515
reading: 0.1555
says: 0.5588
seen: 0.1446
significant: 0.1709
speed: 0.1863
study: 0.5334
takes: 0.1314
task: 0.2893
things: 0.1099
time: 0.1981
took: 0.1778
week: 0.1778
work: 0.1063

Termine con il punteggio TF-IDF più alto: says (0.5588)

----------------------------------------------------------------------------------------------------

Question 408:
"Regular" golf vs. code golf:
Both are competitions.  Both have a well-defined set of rules, which I'll leave out for simplicity.  Both have well-defined goals; in short, "use fewer hits/characters than your competitors."
To win matches, athletic golfers rely on

equipment

Some situations call for a sand wedge; others, a 9-iron.


techniques

The drive works better when your feet are about shoulder width apart and your arms are relaxed.


and strategies

Sure, you could take that direct shortcut to the hole... but do you really want to risk the water hazard or sand bunker when those trees are in the way and the wind is so strong?  It might be better to go around the long way.



What do code golfers have that's analagous to athletic golfers' equipment, techniques and strategies?
Sample answer to get this started: use the right club!  Choose GolfScript instead of C#.


TF-IDF Scores:
answer: 0.1066
apart: 0.1601
better: 0.2051
characters: 0.1440
choose: 0.1601
code: 0.1328
direct: 0.1601
fewer: 0.1601
golf: 0.3353
instead: 0.1204
leave: 0.1400
long: 0.1226
really: 0.1066
regular: 0.1601
rely: 0.1601
right: 0.1250
rules: 0.1601
sample: 0.1677
set: 0.1204
short: 0.1677
situations: 0.1677
started: 0.1677
strategies: 0.3353
strong: 0.1677
sure: 0.1250
techniques: 0.3201
use: 0.1452
vs: 0.1601
want: 0.0875
way: 0.1688
width: 0.1677
win: 0.1677
works: 0.1250

Termine con il punteggio TF-IDF più alto: golf (0.3353)

Best Answer:
Depending on the Golf Code challenge, just start by coding it. No mather the amount of initial character, it's the first step. Trying to code from scratch with the least character can just make it harder. After that look for where you can optimize your code (use 1 character variable, do chainning operation, etc.) . This part involves mastering the language in which you are doing the Golf Code, the better you know it, the more you will know tweak that will save you characters.
Example of this strategy/technique :
https://stackoverflow.com/questions/3173415/code-golf-2d-platformer/3173614#3173614
As for the equipment, for most Golf Code challenge, the ideal equipment is to use a custom language made just for the challenge. Sometimes that language already exist, sometimes you can just invent it and code an interpreter of it.


TF-IDF Scores:
better: 0.0780
challenge: 0.3825
character: 0.3510
characters: 0.1095
code: 0.3534
coding: 0.1065
com: 0.1038
depending: 0.1275
example: 0.0720
exist: 0.1275
golf: 0.5101
harder: 0.1275
https: 0.1095
initial: 0.1217
know: 0.1343
language: 0.2184
look: 0.0932
make: 0.0678
operation: 0.1217
optimize: 0.1170
questions: 0.0950
save: 0.1217
stackoverflow: 0.1095
start: 0.0871
step: 0.1170
strategy: 0.1130
technique: 0.1217
trying: 0.1013
use: 0.1104
variable: 0.0990

Termine con il punteggio TF-IDF più alto: golf (0.5101)

----------------------------------------------------------------------------------------------------

Question 487:
If you were to design a programming language, how would you do it? What features would you put in? What would you leave out? Statically or dynamically typed? Strongly or weakly typed? Compiled or interpreted? Justify your answers.


TF-IDF Scores:
answers: 0.3117
design: 0.2189
dynamically: 0.3010
features: 0.2918
language: 0.1939
leave: 0.2837
programming: 0.1879
statically: 0.3243
typed: 0.6486

Termine con il punteggio TF-IDF più alto: typed (0.6486)

Best Answer:

I definitely think that functional programming languages will catch on, so my language will be functional. See Taming Effects with Functional Programming
I think the CPUs soon will have hundreads of cores, and threads will he a hell to manage. So the Actor Model is a must instead of threads. See Erlang - software for a concurrent world
I also think that OOP has failed, the communication between objects was assumed to be asynchronous. So I think we need message passing, with immutable messages. Send and Forget. As in the Actor model. See Object Oriented Programming: The Wrong Path?
I think that it would be good to have static typing, so errors are catched earlier in the development cycle. But I would use type inference as in Haskell, so that the developer don't need to write the type everywhere in the code as in C, C# and Java. See Learn You A Haskell for Great Good
I would also design a great UI library, with declarative layout, as in WPF and Android. But I would like to have it as in Functional Reactive Programming.

So my language would be like the concurrency in Erlang but with the typing as in Haskell and a GUI framework as in WPF.NET.


TF-IDF Scores:
android: 0.0959
asynchronous: 0.1116
catch: 0.1116
code: 0.0442
communication: 0.0989
cycle: 0.1116
design: 0.0719
developer: 0.0849
development: 0.0729
earlier: 0.1024
effects: 0.1065
erlang: 0.2232
errors: 0.0959
forget: 0.0989
framework: 0.0867
functional: 0.3632
good: 0.1303
great: 0.1816
haskell: 0.3348
instead: 0.0801
java: 0.0762
language: 0.1274
languages: 0.0801
learn: 0.0832
library: 0.1024
like: 0.0884
manage: 0.1024
message: 0.1065
messages: 0.1065
model: 0.1918
need: 0.1210
net: 0.0867
object: 0.0719
objects: 0.0816
oop: 0.0989
oriented: 0.1116
passing: 0.1024
programming: 0.2469
send: 0.1116
software: 0.0788
soon: 0.1065
static: 0.0886
think: 0.2912
threads: 0.2232
type: 0.1549
typing: 0.2048
ui: 0.0989
use: 0.0483
world: 0.0886
write: 0.0719
wrong: 0.1024

Termine con il punteggio TF-IDF più alto: functional (0.3632)

----------------------------------------------------------------------------------------------------

Question 492:
Did you learn to touch-type when you were already working as a programmer?  If so how did it affect your productivity?  Or are you still unable to touch type and do you think it holds you back?
According to Steve Yegge it is essential,
Personally I did not notice much difference, possibly because I was spending less than 25% of my work time actually typing (I was working on a large legacy project at the time and I was spending more time on reading and debugging existing code.)


TF-IDF Scores:
actually: 0.1875
code: 0.1015
debugging: 0.2448
difference: 0.2272
existing: 0.2202
large: 0.1991
learn: 0.1911
personally: 0.2352
possibly: 0.2141
programmer: 0.1911
project: 0.1652
reading: 0.2141
think: 0.1338
time: 0.4090
type: 0.3559
typing: 0.2352
work: 0.1464
working: 0.3449

Termine con il punteggio TF-IDF più alto: time (0.4090)

Best Answer:
The main benefit for me is the ability to work more ergonomically (no looking down and straining your neck and top back). I don't think it actually affects your speed though, except for comments, because of the excessive use of punctuation marks in programming languages. Touch Typing is really more suited for words... at least on a QWERTY keyboard. 
I think Steve Yegge is overreacting about this. We're not typists, we're problem solvers. At the end what's important is for your typing to not get in your way. If it's not causing you physical strain, and your typing speed is not disruptively behind your though speed, then you can type in whatever way you want, and trust me- it is possible to type fast without touch typing. 


TF-IDF Scores:
ability: 0.1521
actually: 0.1212
affects: 0.1658
benefit: 0.1521
comments: 0.1349
end: 0.1287
important: 0.1235
languages: 0.1190
looking: 0.1317
main: 0.1260
possible: 0.1151
problem: 0.0990
programming: 0.0917
really: 0.1054
speed: 0.4974
think: 0.1730
type: 0.2302
typing: 0.6085
use: 0.0718
want: 0.0865
way: 0.1669
words: 0.1469
work: 0.0946

Termine con il punteggio TF-IDF più alto: typing (0.6085)

----------------------------------------------------------------------------------------------------

Question 500:
Rather than slavishly pair program all the time, we use pair programming selectively on our team. I think it works best in the following circumstances:

Ramping up brand new team members on a project (instead of letting them wade through documentation or code on their own).
Having junior and senior people work together (helps to show some of the skills and tricks of the more experienced developers, plus it allows the old dogs to learn new tricks sometimes).
When someone is trying to track down a defect, it often helps to pair with a fresh set of eyes.

When to use pair program and why?
When to avoid pair programming? Why?


TF-IDF Scores:
allows: 0.1199
avoid: 0.1162
best: 0.1075
circumstances: 0.1353
code: 0.0536
developers: 0.1051
documentation: 0.1353
experienced: 0.1353
following: 0.1051
helps: 0.2706
instead: 0.0971
learn: 0.1008
members: 0.1241
new: 0.1497
old: 0.1241
pair: 0.6764
people: 0.0838
program: 0.1848
programming: 0.1497
project: 0.0872
set: 0.0971
skills: 0.1241
team: 0.2202
think: 0.0706
time: 0.0719
track: 0.1199
tricks: 0.2583
trying: 0.1075
use: 0.1171
work: 0.0772
works: 0.1008

Termine con il punteggio TF-IDF più alto: pair (0.6764)

Best Answer:
I have never worked in a "Pair Programming" setup and yet I can claim to have been a part of the three circumstances you've listed. The scenario you mention seems more "regular programming" with phases of helping / training thrown in. Did we not do all of this before "pair programming" came into being? Pair Programming, I'd assume would require a more committed approach where the process of sharing within a team doesn't stop the minute you tackle the immediate task or problem at hand. But then this is what I "think" not what I "know".
Personally for Pair Programming I'd like to work in a team where I get a chance to learn and share my knowledge. An unbalanced team where everyone you work with is miles ahead of you, or then way below par can get quite uninteresting quite quickly. Also, I'd be afraid to work with people who are set in their beliefs and hard to convince.


TF-IDF Scores:
approach: 0.0992
assume: 0.1381
came: 0.1381
chance: 0.1318
circumstances: 0.1381
hand: 0.1097
hard: 0.1153
know: 0.0727
knowledge: 0.1224
learn: 0.1029
like: 0.0547
minute: 0.1381
pair: 0.5524
people: 0.0855
personally: 0.1267
problem: 0.0825
process: 0.1073
programming: 0.3820
quickly: 0.1318
quite: 0.2058
regular: 0.1318
require: 0.1124
scenario: 0.1318
set: 0.0992
setup: 0.1381
stop: 0.1318
task: 0.1073
team: 0.3371
think: 0.0721
way: 0.0695
work: 0.2365

Termine con il punteggio TF-IDF più alto: pair (0.5524)

----------------------------------------------------------------------------------------------------

Question 501:
No matter how much you love a programming language, there are always a few details in it that aren’t quite as nice as they could be.
In this question, I would like to specifically focus on syntax elements. In a programming language that you use frequently (perhaps your favourite programming language, or perhaps the one you are forced to use at work), which syntax element do you find most unreadable, unclear, inconvenient or unpleasant?


TF-IDF Scores:
details: 0.1947
element: 0.2196
elements: 0.2121
focus: 0.2285
frequently: 0.2121
language: 0.4099
like: 0.0948
matter: 0.2196
nice: 0.2056
programming: 0.3972
question: 0.1446
quite: 0.1784
specifically: 0.2285
syntax: 0.4242
use: 0.2073
work: 0.1366

Termine con il punteggio TF-IDF più alto: syntax (0.4242)

Best Answer:
Semicolon insertion in JavaScript.
I haven't really been bitten by it often, but it's just such a phenomenally bad idea it makes my head spin.

Here's the rules (from ECMA-262 Section 7.9)

When the program contains a token that is not allowed by the formal grammar, then a semicolon is inserted if (a) there is a line break at that point, or (b) the unexpected token was a closing brace.
When the end of a file is reached, if the program cannot be parsed otherwise, then a semicolon is inserted.
When a "restricted production" is encountered and contains a line terminator in a place where the grammar contains the annotation "[no LineTerminator here]", then a semicolon is inserted. 


Example:
return 1; // returns 1

return
1; // returns undefined



TF-IDF Scores:
bad: 0.1443
break: 0.1650
contains: 0.5186
end: 0.1342
example: 0.0976
file: 0.1288
head: 0.1650
idea: 0.1342
javascript: 0.1532
line: 0.2813
makes: 0.1071
place: 0.1406
point: 0.1241
production: 0.1729
program: 0.2362
really: 0.1099
return: 0.2440
returns: 0.2887
rules: 0.1650
section: 0.1729
token: 0.3457
unexpected: 0.1650

Termine con il punteggio TF-IDF più alto: contains (0.5186)

----------------------------------------------------------------------------------------------------

Question 502:
I think everyone has their own program or set of features beyond "Hello World!", that they use when trying out a new language.
Mine is a guessing game:
I'm thinking of a number 1-10, guess what it is!
Guess: 3
Nope, too low!
Guess: 7
Nope, too high!
Guess: 5
Yes, You win!
Play again (Y/N)? N

What do you write?


TF-IDF Scores:
10: 0.1548
features: 0.1674
game: 0.1788
guess: 0.7443
hello: 0.1949
high: 0.1788
language: 0.1113
low: 0.1949
new: 0.1078
number: 0.1331
program: 0.1331
set: 0.1400
think: 0.1017
thinking: 0.1548
trying: 0.1548
use: 0.0844
win: 0.1949
world: 0.1548
write: 0.1256
yes: 0.1788

Termine con il punteggio TF-IDF più alto: guess (0.7443)

Best Answer:
It usually goes like this:

Hello World
Hello [user inputted name]
A few problems from Project Euler
A linked list
A simple blog engine (either terminal or web-based, depending on what language)
And from there I dive into a project that I want to work on (but don't care if the design gets mangled as I learn my way through a new language).



TF-IDF Scores:
based: 0.1729
blog: 0.2095
care: 0.2257
depending: 0.2365
design: 0.1523
gets: 0.2170
goes: 0.2095
hello: 0.4729
language: 0.2700
learn: 0.1762
like: 0.0936
list: 0.1591
new: 0.1308
problems: 0.1729
project: 0.3047
simple: 0.1924
user: 0.1615
usually: 0.1729
want: 0.1234
way: 0.1190
web: 0.1669
work: 0.1350
world: 0.1878

Termine con il punteggio TF-IDF più alto: hello (0.4729)

----------------------------------------------------------------------------------------------------

Question 507:
I have seen this on the SO on many times. Whenever a question is vague and the question is asking some magical answer somebody or the other leaves a comment saying answer is 42. Even a book I am reading right now uses '42' as the number whenever it wants demonstrate some basic concept using an integer. So is there any history behind it or it is just a coincidence?


TF-IDF Scores:
answer: 0.3747
asking: 0.2532
book: 0.2612
comment: 0.2704
concept: 0.2612
number: 0.2013
question: 0.3562
reading: 0.2461
right: 0.2197
saying: 0.2814
seen: 0.2289
times: 0.2241
uses: 0.2013
using: 0.1524
wants: 0.2532

Termine con il punteggio TF-IDF più alto: answer (0.3747)

Best Answer:
It's the answer to Life, The Universe, and Everything from Douglas Adams' Hitchhiker's Guide to the Galaxy.


TF-IDF Scores:
answer: 0.5542
guide: 0.8324

Termine con il punteggio TF-IDF più alto: guide (0.8324)

----------------------------------------------------------------------------------------------------

Question 558:
I am a moderately capable web developer. I can put stuff where I want it to go and put some JQuery stuff in there if I need to. However, if I am making my own website (which I am starting to do) I have no idea how to design it. If someone was to sit next to me a point to the screen and say "put this picture there, text there" I can do that quite easily. But designing my own site with my choice of colours and text will look like a toddler has invented it.
Does anyone know any websites/books I can look at or has anyone got any tips on the basics of non-toddler web design?


TF-IDF Scores:
books: 0.1823
choice: 0.1896
design: 0.2559
developer: 0.1510
easily: 0.1578
got: 0.1659
idea: 0.1543
know: 0.1046
like: 0.0786
look: 0.2905
making: 0.1578
need: 0.1077
non: 0.1616
point: 0.1426
quite: 0.1480
say: 0.1280
screen: 0.1986
site: 0.1986
starting: 0.1896
stuff: 0.3413
text: 0.3973
tips: 0.1896
want: 0.1036
web: 0.2804
website: 0.1706

Termine con il punteggio TF-IDF più alto: text (0.3973)

Best Answer:
You have a few things to do.
Tips:
Learn to use Photoshop. (In particular, layer styles are excellent. Just note that they can be difficult effects to reimplement in CSS2) It goes a long way towards making good mockups. 
Look at professionally designed sites. What sites have you been to that look nice to you?  
Find sites that bother you and consider what could make it better. Look at product advertisements as well. Food packaging. Newspaper ads. You name it. 
Also, once you start getting the hang of it, practice, practice, practice. Graphics takes time to develop as a skill, especially from a programmer who has coding to consider. (Gradients vs "tileability") 
Tools:
(Photoshop is a personal favorite. Paint.NET is a good Windows alternative, but is not quite as powerful.)
Nathan Smith's 960 grid system. It has templates for many of the mainstream graphics programs. Check it out.
References:
Look at some of these sites: (I've seen more, I'll try to add as I come across them)

A List Apart
John McCain
BarackObama.com 
Hayon2010.com (Okay, I made this one, but I think that it's nice. edit: I'd appreciate comments on it too. ;-D)



TF-IDF Scores:
add: 0.0841
alternative: 0.1192
apart: 0.1138
better: 0.0729
check: 0.0926
coding: 0.0996
com: 0.1940
come: 0.0926
comments: 0.0970
consider: 0.2113
designed: 0.1138
develop: 0.1138
difficult: 0.0906
edit: 0.1024
effects: 0.1138
especially: 0.1094
getting: 0.0970
goes: 0.1056
good: 0.1391
grid: 0.1192
hang: 0.1192
layer: 0.1056
learn: 0.0888
list: 0.0802
long: 0.0872
look: 0.3487
make: 0.0634
making: 0.0947
net: 0.0926
nice: 0.2048
note: 0.0996
particular: 0.0906
personal: 0.0996
powerful: 0.1138
practice: 0.3169
product: 0.1024
programmer: 0.0888
programs: 0.1192
quite: 0.0888
references: 0.1138
seen: 0.0926
sites: 0.4375
start: 0.0814
takes: 0.0841
things: 0.0704
think: 0.0622
time: 0.0634
tips: 0.1138
tools: 0.1024
try: 0.0856
use: 0.0516
vs: 0.1138
way: 0.0600
windows: 0.1192

Termine con il punteggio TF-IDF più alto: sites (0.4375)

----------------------------------------------------------------------------------------------------

Question 566:
goto is almost universally discouraged. Is using this statement ever worthwhile?


TF-IDF Scores:
using: 1.0000

Termine con il punteggio TF-IDF più alto: using (1.0000)

Best Answer:
This has been discussed several times on Stack Overflow, and Chris Gillum summarized the possible uses of goto:

Cleanly exiting a function
Often in a function, you may allocate resources and need to exit in multiple places.  Programmers can simplify their code by putting the resource cleanup code at the end of the function all all "exit points" of the function would goto the cleanup label.  This way, you don't have to write cleanup code at every "exit point" of the function.
Exiting nested loops
If you're in a nested loop and need to break out of all loops, a goto can make this much cleaner and simpler than break statements and if-checks.
Low-level performance improvements
This is only valid in perf-critical code, but goto statements execute very quickly and can give you a boost when moving through a function.  This is a double-edged sword, however, because a compiler typically cannot optimize code that contains gotos.

I'd argue, as many others would argue, that in all of these cases, the usage of goto is used as a means to get out of a corner one coded oneself into, and is generally a symptom of code that could be refactored.


TF-IDF Scores:
break: 0.2533
cases: 0.0906
cleaner: 0.1327
code: 0.3151
compiler: 0.1176
contains: 0.1327
discussed: 0.1327
end: 0.1030
execute: 0.1140
function: 0.5716
generally: 0.1140
improvements: 0.1266
level: 0.1108
loop: 0.1266
low: 0.1327
make: 0.0705
means: 0.1030
multiple: 0.1009
need: 0.1438
optimize: 0.1217
performance: 0.1140
places: 0.1176
point: 0.0953
points: 0.1217
possible: 0.0921
programmers: 0.0989
quickly: 0.1266
refactored: 0.1327
resource: 0.1266
resources: 0.1217
stack: 0.1079
statements: 0.2533
times: 0.1009
typically: 0.1327
used: 0.0811
uses: 0.0906
valid: 0.1079
way: 0.0668
write: 0.0855

Termine con il punteggio TF-IDF più alto: function (0.5716)

----------------------------------------------------------------------------------------------------

Question 570:
All but the most trivial programs are filled with bugs and so anything that promises to remove them is extremely alluring. At the moment, correctness proofs are code are extremely esoteric, mainly because of the difficultly of learning this and the extra effort it takes to prove a program correct. Do you think that code proving will ever take off?


TF-IDF Scores:
bugs: 0.2391
code: 0.2137
correct: 0.2253
effort: 0.2576
extra: 0.2391
extremely: 0.5152
learning: 0.2253
moment: 0.2699
program: 0.1843
programs: 0.2699
prove: 0.2576
remove: 0.2253
takes: 0.1904
think: 0.1408
trivial: 0.2318

Termine con il punteggio TF-IDF più alto: extremely (0.5152)

Best Answer:
Not really in that sense, but pure functional programming is good in this domain. If you use Haskell, it's likely that your program is correct if the code compiles. Except from IO, a good type system is a good help.
Also programming to contract can be helpful. See Microsoft Code Contracts


TF-IDF Scores:
code: 0.2099
correct: 0.2214
domain: 0.2531
functional: 0.2157
good: 0.4641
haskell: 0.2651
help: 0.1871
io: 0.2651
likely: 0.2059
microsoft: 0.2531
program: 0.1811
programming: 0.2933
pure: 0.2531
really: 0.1685
sense: 0.2016
type: 0.1840
use: 0.1148

Termine con il punteggio TF-IDF più alto: good (0.4641)

----------------------------------------------------------------------------------------------------

Question 604:
on a widescreen monitor one can easily see more than 80 characters at a time, without scrollbars. even linus torvalds sees the 80 character limit as outdated.
so, is the 80 character limit still relevant in times of widescreen monitors?


TF-IDF Scores:
80: 0.7649
character: 0.4679
characters: 0.2190
easily: 0.2025
relevant: 0.2260
time: 0.1356
times: 0.1939

Termine con il punteggio TF-IDF più alto: 80 (0.7649)

Best Answer:
If I keep my lines to less than about 100 characters, I can have two editor windows side-by-side on a widescreen monitor.  It's very useful to have both the class header file and implementation both visible at the same time, or have code on one side that calls into the code on the other.  And, if I keep the lines short, I don't need a horizontal scrollbar on my editor windows, which gives me more vertical space.
80 characters may be outdated, but there's some merit in keeping things within reason.


TF-IDF Scores:
100: 0.1950
80: 0.2125
calls: 0.1826
characters: 0.3651
class: 0.1213
code: 0.1683
file: 0.1584
gives: 0.1883
header: 0.2125
implementation: 0.1584
keeping: 0.2029
lines: 0.4250
need: 0.1152
reason: 0.1584
short: 0.2125
space: 0.1826
things: 0.1254
time: 0.1130
useful: 0.1688
windows: 0.4250

Termine con il punteggio TF-IDF più alto: lines (0.4250)

----------------------------------------------------------------------------------------------------

Question 616:
When I am in a code or design rut, I tend to find a non-dev coworker to discuss the problem with. It forces me to explain the problem in great detail and I'll usually find something I missed in the process.
What are your "unsticking" methods?


TF-IDF Scores:
code: 0.1347
design: 0.2192
explain: 0.2769
forces: 0.3403
great: 0.2769
methods: 0.2443
missed: 0.3403
non: 0.2769
problem: 0.4063
process: 0.2642
tend: 0.3403
usually: 0.2488

Termine con il punteggio TF-IDF più alto: problem (0.4063)

Best Answer:
Some of my tactics:

Explain the problem to someone, or even no one.  My girlfriend used to explain problems to a potato she kept.
Work on something else for a bit (if opportunity allows)- some other functionality or even another project.  Get your ming off the current project.  A lot of times problems that seem impossible at 4:30pm seem trivial at 9:30 am the next day.
Go to the pub (if possible).  Same principle as above.
Beat your head against it.  This isn't often that productive for solving the problem, but at least for me, I tend to learn a lot.  If my gridview isn't auto-sorting, I'll try and read everything I can about the problem.  It'll still take me 3 hours to solve a stupid error on my part, but by the end, I'll have learned everything there is to know about gridviews and how they bind to data- I'll be able to solve any number of similar problems in the future.
Get another input- preferably someone who knows at least something about the context of the project.  Most of my errors are stupid ones that only require a few minutes from a second set of eyes to solve where it would take me hours.
Isolate the problem.  I keep a folder labeled "proof of bugs" where I keep a pile of project that each reproduce a specific issue outside the overall context of the large, complex project.  This can be a little time consuming, but it allows you to narrow down the cause of the issue independent of the bazillion interfering factors of a large project.



TF-IDF Scores:
able: 0.0829
allows: 0.1932
bit: 0.0829
bugs: 0.0966
cause: 0.1041
complex: 0.1000
context: 0.1873
current: 0.0847
data: 0.0659
day: 0.0966
end: 0.0847
error: 0.0936
errors: 0.0936
explain: 0.1774
functionality: 0.0936
future: 0.1041
head: 0.1041
hours: 0.2180
independent: 0.1090
input: 0.0910
issue: 0.1821
know: 0.0574
large: 0.1693
learn: 0.0812
little: 0.0866
lot: 0.1513
minutes: 0.1090
number: 0.0745
ones: 0.0966
opportunity: 0.1041
outside: 0.0936
overall: 0.1000
possible: 0.0757
principle: 0.1041
problem: 0.2604
problems: 0.2391
productive: 0.1041
project: 0.4214
read: 0.0829
require: 0.0887
second: 0.0829
set: 0.0783
similar: 0.0829
solve: 0.2731
solving: 0.1041
specific: 0.0847
stupid: 0.2180
tend: 0.1090
time: 0.0580
times: 0.0829
trivial: 0.0936
try: 0.0783
used: 0.0667
work: 0.0622

Termine con il punteggio TF-IDF più alto: project (0.4214)

----------------------------------------------------------------------------------------------------

Question 648:
We, as programmers, are constantly being asked 'How long will it take'?
And you know, the situation is almost always like this:

The requirements are unclear. Nobody has done an in depth analysis of all the implications.
The new feature will probably break some assumptions you made in your code and you start thinking immediately of all the things you might have to refactor. 
You have other things to do from past assignments and you will have to come up with an estimate that takes that other work into account.
The 'done' definition is probably unclear: When will it be done? 'Done' as in just finished coding it, or 'done' as in "the users are using it"?
No matter how conscious you are of all these things, sometimes your "programmer's pride" makes you give/accept shorter times than you originally suppose it might take. Specially when you feel the pressure of deadlines and management expectations.

Many of these are organizational or cultural issues that are not simple and easy to solve, but in the end the reality is that you are being asked for an estimate and they expect you to give a reasonable answer. It's part of your job. You cannot simply say: I don't know. 
As a result, I always end up giving estimates that I later realize I cannot fulfill. It has happened countless of times, and I always promise it won't happen again. But it does.
What is your personal process for deciding and delivering an estimate? What techniques have you found useful?


TF-IDF Scores:
account: 0.1313
analysis: 0.1366
answer: 0.0909
asked: 0.2861
break: 0.1366
code: 0.0566
coding: 0.1195
come: 0.1111
definition: 0.1313
easy: 0.1111
end: 0.2222
expect: 0.1366
feature: 0.1268
feel: 0.1268
finished: 0.1431
giving: 0.1313
happen: 0.1366
immediately: 0.1366
issues: 0.1313
job: 0.1088
know: 0.1507
later: 0.1229
like: 0.0566
long: 0.1046
makes: 0.0886
management: 0.1229
matter: 0.1313
new: 0.0791
past: 0.1313
personal: 0.1195
probably: 0.2054
process: 0.1111
programmer: 0.1066
programmers: 0.1066
promise: 0.1366
realize: 0.1268
reasonable: 0.1431
refactor: 0.1313
requirements: 0.1088
result: 0.1268
say: 0.0922
simple: 0.1164
simply: 0.1066
situation: 0.1313
solve: 0.1195
start: 0.0977
suppose: 0.1313
takes: 0.1010
techniques: 0.1366
things: 0.2533
thinking: 0.1136
times: 0.2175
useful: 0.1136
users: 0.1195
using: 0.0740
work: 0.0817

Termine con il punteggio TF-IDF più alto: asked (0.2861)

Best Answer:
From The Pragmatic Programmer: From Journeyman to Master:

What to Say When Asked for an Estimate
You say "I'll get back to you."
You almost always get better results if you slow the process down and spend some time going through the steps we describe in this section. Estimates given at the coffee machine will (like the coffee) come back to haunt you.

In the section, the authors recommend the following process:

Determine the accuracy that you need. Based on the duration, you can quote the estimate in different precision. Saying "5 to 6 months" is different than saying "150 days". If you slip a little into the 7th month, you're still pretty accurate. But if you slip into the 180th or 210th day, not so much.
Make sure you understand what is being asked. Determine the scope of the problem.
Model the system. A model might be a mental model, diagrams, or existing data records. Decompose this model and build estimates from the components. Assign values and error ranges (+/-) to each value.
Calculate the estimate based on your model.
Track your estimates. Record information about the problem you are estimating, your estimate, and the actual values.
Other things to include in your estimate are developing and documenting requirements or changes to requirements specifications, creating or updating design documents and specifications, testing (unit, integration, and acceptance), creating or updating user's manuals or READMEs with the changes. If 2 or more people working together, there's overhead of communication (phone calls, emails, meetings) and merging source code. If it's a long task, account for things like other work, time off (holidays, vacation, sick time), meetings, and other overhead tasks when picking a delivery date.



TF-IDF Scores:
account: 0.0911
actual: 0.0880
asked: 0.1985
based: 0.1452
better: 0.0607
build: 0.0788
calls: 0.0853
changes: 0.1705
code: 0.0393
coffee: 0.1985
come: 0.0771
communication: 0.0880
components: 0.0853
creating: 0.1425
data: 0.0600
day: 0.0880
days: 0.0948
design: 0.0639
determine: 0.1985
developing: 0.0808
different: 0.1279
documents: 0.0993
emails: 0.0993
error: 0.0853
existing: 0.0853
following: 0.0771
given: 0.0771
going: 0.0755
include: 0.0853
information: 0.0713
integration: 0.0911
like: 0.0786
little: 0.0788
long: 0.0726
make: 0.0528
master: 0.0911
model: 0.4263
need: 0.0538
overhead: 0.1821
people: 0.0615
phone: 0.0993
pragmatic: 0.0993
pretty: 0.0713
problem: 0.1185
process: 0.1542
programmer: 0.0740
recommend: 0.0993
record: 0.0948
requirements: 0.1509
results: 0.0880
say: 0.1279
saying: 0.1895
scope: 0.0993
section: 0.1985
slow: 0.0948
source: 0.0771
spend: 0.0993
steps: 0.0993
sure: 0.0740
task: 0.0771
tasks: 0.0911
testing: 0.0829
things: 0.1172
time: 0.1583
track: 0.0880
understand: 0.0726
unit: 0.0755
user: 0.0678
value: 0.0808
values: 0.1705
work: 0.0567
working: 0.0668

Termine con il punteggio TF-IDF più alto: model (0.4263)

----------------------------------------------------------------------------------------------------

Question 678:
I know some people are massive proponents of test driven development. I have used unit tests in the past, but only to test operations that can be tested easily or which I believe will quite possibly be correct. Complete or near complete code coverage sounds like it would take a lot of time.

What projects do you use test-driven development for? Do you only use it for projects above a certain size?
Should I be using it or not? Convince me!



TF-IDF Scores:
believe: 0.1710
certain: 0.1779
code: 0.0738
complete: 0.3033
correct: 0.1556
development: 0.2435
driven: 0.3303
easily: 0.1480
know: 0.0982
like: 0.0738
lot: 0.1294
near: 0.1864
operations: 0.1556
past: 0.1710
people: 0.1154
possibly: 0.1556
projects: 0.3202
quite: 0.1389
size: 0.1556
sounds: 0.1556
test: 0.4088
tested: 0.1864
tests: 0.1389
time: 0.0991
unit: 0.1417
use: 0.1614
used: 0.1140
using: 0.0964

Termine con il punteggio TF-IDF più alto: test (0.4088)

Best Answer:
Ok, some advantages to TDD:

It means you end up with more tests.  Everyone likes having tests, but few people like writing them.  Building test-writing into your development flow means you end up with more tests.
Writing to a test forces you to think about the testability of your design, and testable design is almost always better design.  It's not entirely clear to me why this happens to be the case, but my experience and that of most TDD evangelists seems to bear it out.
Here's a study saying that although TDD takes a bit longer to write, there's a good return on investment because you get higher quality code, and therefore fewer bugs to fix.
It gives you confidence in refactoring.  It's a great feeling to be able to change one system without worrying about breaking everything else because it's pretty well covered by unit tests.
You almost never get a repeat bug, since every one you find should get a test before it gets a fix.

You asked to be convinced, so these were benefits.  See this question for a more balanced view.


TF-IDF Scores:
able: 0.0928
advantages: 0.1082
asked: 0.1221
benefits: 0.1020
better: 0.0747
bit: 0.0928
breaking: 0.1166
bug: 0.1121
bugs: 0.1082
building: 0.1121
case: 0.0787
change: 0.0848
clear: 0.1166
code: 0.0483
design: 0.2360
development: 0.0798
end: 0.1897
experience: 0.1020
fewer: 0.1166
fix: 0.2332
flow: 0.1166
forces: 0.1221
gets: 0.1121
gives: 0.1082
good: 0.0713
great: 0.0994
happens: 0.1221
higher: 0.0970
like: 0.0483
longer: 0.1121
means: 0.1897
people: 0.0756
pretty: 0.0877
quality: 0.1121
question: 0.0738
refactoring: 0.1121
return: 0.0862
saying: 0.1166
study: 0.1166
takes: 0.0862
tdd: 0.3247
test: 0.2679
tests: 0.3640
think: 0.0637
unit: 0.0928
view: 0.1121
worrying: 0.1221
write: 0.0787
writing: 0.3147

Termine con il punteggio TF-IDF più alto: tests (0.3640)

----------------------------------------------------------------------------------------------------

Question 724:
When learning a new programming language you sometimes come across a language feature which 
makes you wish you had it in your other programming languages that you know.
What are some language feature which were at the time of learning very new to you and that you wish your other programming languages had.  
An example of this is generators in Python or C#.
Other examples may include list comprehensions in Python, template in C++ or LINQ in .NET or lazy evaluation in Haskell.
What other semi-unique language features have you come across which were completely new and enlightening to you?  Are there other features of older programming languages which were unique and have fallen out of fashion?


TF-IDF Scores:
come: 0.2267
completely: 0.1393
example: 0.0824
examples: 0.1187
feature: 0.2587
features: 0.2507
haskell: 0.1459
include: 0.1254
know: 0.0769
language: 0.3332
languages: 0.3144
lazy: 0.1459
learning: 0.2437
list: 0.0982
makes: 0.0904
net: 0.1133
new: 0.2422
older: 0.1459
programming: 0.3229
python: 0.2318
time: 0.0776
unique: 0.2919
wish: 0.2919

Termine con il punteggio TF-IDF più alto: language (0.3332)

Best Answer:
Python's decorator.
It's extremely easy to implement memoization or timing of function using the decorator.
Example of a function timer.
class FuncTimer(object):
    """ Time how much time a function takes """
    def __init__(self, fn):
        self.fn = fn
        self.memo = {}
        self.start_time = time.time()
    def __call__(self, *args):
        self.memo['return'] = self.fn(*args)
        print("Function '%s' took %u seconds" % (self.fn.__name__, time.time() - self.start_time))
        return self.memo['return']

Now if you have a function foo you want to time, you can simply do this,
@FuncTimer
def foo():
    # foo's implememtation goes here

You will see something like,
Function 'foo' took 3 seconds.


TF-IDF Scores:
args: 0.1606
class: 0.0458
decorator: 0.1606
easy: 0.0624
example: 0.0454
extremely: 0.0767
foo: 0.3212
function: 0.3460
goes: 0.0712
implement: 0.0624
like: 0.0318
object: 0.0517
python: 0.0638
return: 0.1700
self: 0.7368
simply: 0.0598
takes: 0.0567
time: 0.2989
took: 0.1533
using: 0.0415
want: 0.0419

Termine con il punteggio TF-IDF più alto: self (0.7368)

----------------------------------------------------------------------------------------------------

Question 729:
As programmers we have a lot of inputs:

Ebooks 
Code snippets 
Interesting emails 
Documents
Web articles 
Blog posts
StackOverflow questions
Podcasts
...

Which tools do you use to store, organize, search and consult all of this stuff?
Is there a silver bullet solution to handle this huge amount of data? 


TF-IDF Scores:
blog: 0.2538
code: 0.1134
data: 0.1731
documents: 0.2864
emails: 0.2864
handle: 0.2275
inputs: 0.2864
interesting: 0.2331
lot: 0.1988
programmers: 0.2135
questions: 0.2135
search: 0.2628
solution: 0.2057
stackoverflow: 0.2461
store: 0.2461
stuff: 0.2461
tools: 0.2461
use: 0.1240
web: 0.2022

Termine con il punteggio TF-IDF più alto: documents (0.2864)

Best Answer:
I'm currently using OneNote from Microsoft to organize and keep record of most of my data, activities and notes. I'm using its online storage to have it automatically shared between my home desktop, personal notebook and office notebook. Unfortunately it has some limits (for example, no integration with eBooks) but it is the most comprehensive and powerful tool I've found.
I tried for a while also Evernote and, while its online sharing is quite better and it can be used on Android (my current mobile platform), it is not powerful as OneNote.


TF-IDF Scores:
android: 0.1795
better: 0.1278
current: 0.1623
currently: 0.1995
data: 0.1263
desktop: 0.1995
example: 0.1180
home: 0.1995
integration: 0.1918
microsoft: 0.1995
mobile: 0.2090
online: 0.4180
personal: 0.1745
powerful: 0.3990
quite: 0.1558
record: 0.1995
shared: 0.2090
tool: 0.1995
tried: 0.1918
unfortunately: 0.2090
used: 0.1278
using: 0.2161

Termine con il punteggio TF-IDF più alto: online (0.4180)

----------------------------------------------------------------------------------------------------

Question 739:
What is the recommended  User Account Control (UAC) setting when developing on Windows?
Even on Win7 I find it annoying enough to turn it off (because it makes me more productive with it off) but sometimes I feel bad because I know I'll find more problems in my code if I leave it on.


TF-IDF Scores:
account: 0.3040
bad: 0.2766
code: 0.1312
control: 0.2766
developing: 0.2696
feel: 0.2936
know: 0.1745
leave: 0.2766
makes: 0.2052
problems: 0.2422
productive: 0.3163
turn: 0.3313
user: 0.2263
windows: 0.3313

Termine con il punteggio TF-IDF più alto: turn (0.3313)

Best Answer:
The recommendation (even from Microsoft) is to leave it ON, and also to run your IDE unelevated whenever possible.
First of all, it forces the programmer to live with the same "annoyances" a real world user will have (if you don't know it, would you program correctly around it?).
Then, disabling UAC and working as an administrator is as bad as in Unix to work as root (decades of common wisdom will tell you why that's bad).


TF-IDF Scores:
bad: 0.4378
common: 0.2082
correctly: 0.2622
forces: 0.2622
ide: 0.2405
know: 0.1381
leave: 0.2189
microsoft: 0.2503
possible: 0.1820
program: 0.1791
programmer: 0.1954
real: 0.2036
run: 0.1993
tell: 0.2405
user: 0.1791
wisdom: 0.2622
work: 0.1496
working: 0.1763
world: 0.2082

Termine con il punteggio TF-IDF più alto: bad (0.4378)

----------------------------------------------------------------------------------------------------

Question 745:
What methods do you use to stay awake and alert while working?
Personally I drink coffee non stop throughout the day.  But I've also heard of this thing called exercise that should help too.  Does anyone else have tips and tricks to stay more awake and alert while working?  Redbull? Maybe a magic pill that won't require me to sleep?


TF-IDF Scores:
called: 0.1953
coffee: 0.2459
day: 0.2179
help: 0.1735
maybe: 0.2000
methods: 0.1765
non: 0.2000
personally: 0.2256
require: 0.2000
sleep: 0.2459
stay: 0.4917
stop: 0.2347
thing: 0.1832
tips: 0.2347
tricks: 0.2347
use: 0.1064
working: 0.3308

Termine con il punteggio TF-IDF più alto: stay (0.4917)

Best Answer:
Caffeine is a major cause of the problem, not the solution.  It might seem to work in the short-term but it makes things worse overall by interfering with your sleep.
If you don't sleep properly you will be tired and unfocused.  If you try to solve that with a high caffeine intake you won't sleep properly.
Exercise, eat well, try to restrict the coffee to a couple of cups a day and don't work stupid long hours.


TF-IDF Scores:
cause: 0.1925
coffee: 0.2017
couple: 0.2017
day: 0.1787
high: 0.1851
hours: 0.2017
long: 0.1475
makes: 0.1249
overall: 0.1851
problem: 0.1204
short: 0.2017
sleep: 0.6051
solution: 0.1448
solve: 0.1684
stupid: 0.2017
things: 0.1190
try: 0.2897
work: 0.2303
worse: 0.2017

Termine con il punteggio TF-IDF più alto: sleep (0.6051)

----------------------------------------------------------------------------------------------------

Question 750:
I'm freshly out of college, and starting university somewhere next week. We've seen unit tests, but we kinda not used them much; and everyone talks about them, so I figured maybe I should do some.
The problem is, I don't know what to test. Should I test the common case? The edge case? How do I know that a function is adequately covered?
I always have the terrible feeling that while a test will prove that a function works for a certain case, it's utterly useless to prove that the function works, period.


TF-IDF Scores:
case: 0.3610
certain: 0.1783
common: 0.1484
edge: 0.1868
function: 0.4024
know: 0.1968
maybe: 0.1520
problem: 0.1115
prove: 0.3566
seen: 0.1451
starting: 0.1783
terrible: 0.1868
test: 0.4098
tests: 0.1392
unit: 0.1420
used: 0.1143
week: 0.1783
works: 0.2784

Termine con il punteggio TF-IDF più alto: test (0.4098)

Best Answer:
My personal philosophy has thusfar been:

Test the common case of everything you can.  This will tell you when that code breaks after you make some change (which is, in my opinion, the single greatest benefit of automated unit testing).
Test the edge cases of a few unusually complex code that you think will probably have errors.
Whenever you find a bug, write a test case to cover it before fixing it
Add edge-case tests to less critical code whenever someone has time to kill.



TF-IDF Scores:
add: 0.1331
automated: 0.1886
benefit: 0.1731
breaks: 0.1886
bug: 0.1731
case: 0.3646
cases: 0.1289
change: 0.1309
code: 0.2241
common: 0.1498
complex: 0.1731
edge: 0.3773
errors: 0.1621
make: 0.1003
opinion: 0.1886
personal: 0.1575
probably: 0.1355
single: 0.1535
tell: 0.1731
test: 0.4138
testing: 0.1575
tests: 0.1406
think: 0.0984
time: 0.1003
unit: 0.1434
write: 0.1215

Termine con il punteggio TF-IDF più alto: test (0.4138)

----------------------------------------------------------------------------------------------------

Question 756:
I'm trying to find places where I can hone my craft outside the context of school or work. Are there places online, or books available, where I can access lists of programming puzzles or challenges?


TF-IDF Scores:
access: 0.2195
available: 0.2559
books: 0.2649
challenges: 0.2887
context: 0.2480
lists: 0.2756
online: 0.2887
outside: 0.2480
places: 0.5117
programming: 0.1597
school: 0.2887
trying: 0.2293
work: 0.1648

Termine con il punteggio TF-IDF più alto: places (0.5117)

Best Answer:
Moderator note: this is intended to be a canonical list; please check to see if your suggestion has already been added to the answer. If it hasn't, edit the answer to add yours, preferably with an explanation or reason why you're suggesting it.
On Stack Exchange
Pick a tag, follow the new questions posted, and try to solve them. If you find a good one, bookmark it for later use:

Stack Overflow
Code Review Community Challenges
Programming Puzzles and Code Golf
Solve algorithmic and datatypes problems

Books

Algorithms for Interviews by Adnan Aziz
Cracking the Coding Interview (6th Edition) by Gayle Laakmann
Programming Challenges by Steven S. Skiena
The Art of Computer Programming by Donald E. Knuth

Communities and Blogs

Algorithm Geeks Google Group
CodeKata
LessThanDot's Programmer Puzzles forum
The Daily WTF's Bring Your Own Code series
/r/dailyprogrammer

Game sites and ongoing contests

Codingame - fun games (solo and multiplayer) to practice your coding skills. Supports 25+ programming languages.
CodeChef
Code Combat - Javascript and Python solo and multiplayer games in the style of a strategy game.
Hacker.org Challenge — "The hacker.org challenges are a series of puzzles, tricks, tests, and brainteasers designed to probe the depths your hacking skills. To master this series you will need to crack cryptography, write clever code, and dissect the impenetrable; and in the process you will enrich your understanding of the world of hacking."
Pex for fun — game from Microsoft research where you duel against other programmers
Rankk — "You start with the easy levels and progress to the intermediate and hard levels by solving the minimum number of required challenges at each level. The journey to the top is an arduous yet rewarding one. You need to be sufficiently determined and persevering to go far. Only a few are expected to reach the apex and attain Geb."
TopCoder
Google Code Jam—algorithmic puzzles

Language specific

4Clojure (Clojure) — "4Clojure is a resource to help fledgling clojurians learn the language through interactive problems. The first few problems are easy enough that even someone with no prior experience should find the learning curve forgiving. See 'Help' for more information."

Prolog Problems (Prolog) — "The purpose of this problem collection is to give you the opportunity to practice your skills in logic programming. Your goal should be to find the most elegant solution of the given problems. Efficiency is important, but logical clarity is even more crucial. Some of the (easy) problems can be trivially solved using built-in predicates. However, in these cases, you learn more if you try to find your own solution."

Python Challenge (Python) — "Python Challenge is a game in which each level can be solved by a bit of (Python) programming."

Ruby Quiz (Ruby) - "Ruby Quiz is a weekly programming challenge for Ruby programmers in the spirit of the Perl Quiz of the Week. A new Ruby Quiz is sent to the Ruby Talk mailing list each Friday."

IOCCC (C) - "A contest to write the most obscure/obfuscated C program. (Fun to try to understand the previous year's entries, or to submit a new one.)"

Underhanded C Contest (C) - "contest to turn out code that is malicious, but passes a rigorous inspection, and looks like an honest mistake. (Try to understand previous year's entries, and learn to find similar mistakes in other people's code)"

CheckiO - Python programming challenges. Custom "Missions" can be created by members.

109 Python Problems for CCPS 109 Python problems of various levels of difficulty, with an automated pseudorandom fuzz tester to verify that the functions are correct.


Online judges / automatic assessment

Codingbat has lots of coding challenges ranging from warm-ups to Harder recursion problems. It is available in Java and Python.
Cyber-dojo has a nice variety of katas and supports a good selection of languages. It is intended to support doing deliberate practice of TDD, but could be used for personal development too.
LeetCode
Peking University JudgeOnline for ACIP/ICPC
Sphere Online Judge
University of Valladolid Online Judge
Codewars — Training witlt;blockquote>
  UI of mobile apps is not always better than that of their websites[...]

That is not nessacerly true. For WP, Sailfish OS or Firefox OS users the UI of websites is often everything but native. The other question is, what is a good UI? But that topic is discussed on https://ux.stackexchange.com/

[...]functionality is usually less.

You can decide that when you develop the app. I personally would develop apps with the same functionality like the mobile website.

Which points can be crucial when determining if there is a need of mobile app for a website?

Like I said earlier, if you need special technologies or if you want to provide all users a native UI. But that is a hard topic, cause there are too many systems out there.
Conclusion
With HTML5, CSS3 and JavaScript webapps kinda grew up. But there is still a range of things that you cannot build with a mobile websites.
Here is a quick list:

Push notifications
Native UI for everybody (could get tricky)
SMS
Addressbook
Camera
Compass
Some more system components
Cryptographics on clientside

I hope it helps :)


TF-IDF Scores:
add: 0.0323
added: 0.0373
algorithm: 0.0382
algorithms: 0.0458
answer: 0.0582
app: 0.0727
apps: 0.0874
automated: 0.0458
available: 0.0406
better: 0.0280
bit: 0.0348
books: 0.0420
build: 0.0364
built: 0.0437
cases: 0.0313
cause: 0.0437
challenge: 0.1831
challenges: 0.2747
check: 0.0356
code: 0.1450
coding: 0.1147
collection: 0.0437
com: 0.0373
components: 0.0393
computer: 0.0406
correct: 0.0382
created: 0.0373
decide: 0.0341
designed: 0.0437
develop: 0.0874
development: 0.0299
discussed: 0.0458
earlier: 0.0420
easy: 0.1067
edit: 0.0393
expected: 0.0420
experience: 0.0382
far: 0.0420
follow: 0.0420
fun: 0.1374
functionality: 0.0787
functions: 0.0373
game: 0.1680
given: 0.0356
goal: 0.0458
golf: 0.0458
good: 0.0802
group: 0.0437
hard: 0.0765
harder: 0.0458
help: 0.0646
helps: 0.0458
https: 0.0393
important: 0.0341
information: 0.0329
interactive: 0.0458
java: 0.0313
javascript: 0.0812
language: 0.0523
languages: 0.0658
later: 0.0393
learn: 0.1024
learning: 0.0382
level: 0.0765
like: 0.0544
list: 0.0924
logic: 0.0373
logical: 0.0458
looks: 0.0382
lots: 0.0437
master: 0.0420
members: 0.0420
microsoft: 0.0437
minimum: 0.0458
mobile: 0.1831
need: 0.0993
new: 0.0760
nice: 0.0393
note: 0.0382
number: 0.0313
online: 0.1374
opportunity: 0.0437
org: 0.0874
os: 0.0916
passes: 0.0406
people: 0.0284
personal: 0.0382
personally: 0.0420
pick: 0.0437
points: 0.0420
practice: 0.1217
previous: 0.0840
prior: 0.0458
problem: 0.0273
problems: 0.3013
process: 0.0356
program: 0.0313
programmer: 0.0341
programmers: 0.0682
programming: 0.2026
provide: 0.0348
purpose: 0.0373
push: 0.0458
python: 0.3273
question: 0.0277
questions: 0.0341
quick: 0.0458
reach: 0.0458
reason: 0.0341
required: 0.0406
resource: 0.0437
ruby: 0.2435
said: 0.0364
sent: 0.0458
similar: 0.0348
sites: 0.0420
skills: 0.1260
solo: 0.0916
solution: 0.0658
solve: 0.0765
solving: 0.0437
special: 0.0406
specific: 0.0356
stack: 0.0745
start: 0.0313
strategy: 0.0406
style: 0.0437
suggesting: 0.0437
suggestion: 0.0437
support: 0.0364
systems: 0.0458
tdd: 0.0406
technologies: 0.0458
tests: 0.0341
things: 0.0270
topic: 0.0874
tricks: 0.0437
true: 0.0406
try: 0.1315
turn: 0.0458
ui: 0.2029
understand: 0.0670
understanding: 0.0458
ups: 0.0458
use: 0.0198
used: 0.0280
users: 0.0765
using: 0.0237
usually: 0.0335
various: 0.0437
want: 0.0239
website: 0.0787
week: 0.0437
world: 0.0364
write: 0.0590
year: 0.0874

Termine con il punteggio TF-IDF più alto: python (0.3273)

----------------------------------------------------------------------------------------------------

Question 267287:
I'd like to know whether a task must be self contained.
Our tasks mostly contain a couple of sentences.
To understand what you are to do you should:

Read the requirements document for several related back log items.
Know how system currently works and understand how it differs
from what is required.

In other words: newcomer or the person who was absent at the planning meeting will require a sufficient amount of time just to comprehend the task.
In addition such way of keeping backlog does not tell much about system evolution and looks more like a primitive contextually conditioned to-do list.


TF-IDF Scores:
addition: 0.1928
contain: 0.2019
couple: 0.2019
currently: 0.1928
document: 0.2019
items: 0.1790
keeping: 0.1928
know: 0.2127
like: 0.1599
list: 0.1358
looks: 0.1686
person: 0.1928
planning: 0.1928
read: 0.1535
related: 0.1735
require: 0.1643
required: 0.1790
requirements: 0.1535
self: 0.1853
sufficient: 0.2019
task: 0.3136
tasks: 0.1853
tell: 0.1853
time: 0.1074
understand: 0.2953
way: 0.1016
words: 0.1790
works: 0.1505

Termine con il punteggio TF-IDF più alto: task (0.3136)

Best Answer:
In most agile framework implementations, the tasks and stories are meant to be a reminder to have a conversation, not a fully detailed spec.
We have had similar problems where new team members who are not familiar with agile or who have missed the planning sessions struggle to work on their own without guidance. The simple solution here is to guide them.
Your Scrum Master, or whomever is playing a similar agile coach role, should be recognizing this dynamic in the team and should be making sure your team member knows that they can reach out to your Product Owner.
The Product Owner, or whomever is playing the role of owning the business requirements, should be available constantly to answer questions, refine acceptance criteria, and generally help the team understand what it is that needs to be built.
That being said, it is generally helpful to capture the output of discussions or decisions made during the conversation on your backlog tasks so that everybody remembers why a decision was made or why there was a deviation from the original criteria.


TF-IDF Scores:
agile: 0.3858
answer: 0.0856
available: 0.1194
built: 0.1286
business: 0.1157
decisions: 0.1347
dynamic: 0.1236
familiar: 0.1347
framework: 0.1046
generally: 0.2314
guide: 0.1286
help: 0.0951
implementations: 0.1236
making: 0.1070
master: 0.1236
meant: 0.1347
member: 0.1125
members: 0.1236
missed: 0.1347
needs: 0.1004
new: 0.0745
original: 0.1286
output: 0.1125
planning: 0.1286
problems: 0.0985
product: 0.2314
questions: 0.1004
reach: 0.1347
requirements: 0.1024
said: 0.1070
sessions: 0.1347
similar: 0.2048
simple: 0.1096
solution: 0.0967
spec: 0.1286
sure: 0.1004
tasks: 0.2472
team: 0.4384
understand: 0.0985
work: 0.0769

Termine con il punteggio TF-IDF più alto: team (0.4384)

----------------------------------------------------------------------------------------------------

Question 267288:
I am trying to get my head around as to why having a local variable or a for loop inside a function is not considered to be pure functional programming. 
Given this function:
int as_int(char *str)
{
    int acc; /* accumulate the partial result */

    for (acc = 0; isdigit(*str); str++) {
        acc = acc * 10 + (*str - '0');
    }

    return acc;
}

Under what circumstances would the variable acc be a side-effect ? Even in a concurrent environment each invocation of the function would have its own copy of acc. So I don't quite get why it isn't allowed in functional programming.


TF-IDF Scores:
10: 0.1534
circumstances: 0.1932
considered: 0.1844
copy: 0.1659
environment: 0.1772
function: 0.4161
functional: 0.3143
given: 0.1500
head: 0.1844
inside: 0.1659
int: 0.3545
local: 0.1772
loop: 0.1844
partial: 0.1932
programming: 0.2137
pure: 0.1844
quite: 0.1440
result: 0.1712
return: 0.1363
trying: 0.1534
variable: 0.3000

Termine con il punteggio TF-IDF più alto: function (0.4161)

Best Answer:
Looping in functional programming isn't done with control statements like for and while, it's done with explicit calls to functions like map, fold, or recursion - all of which involve placing the inner loop call inside another function. If the loop code mutates variables outside the loop, this inner loop function would be manipulating variables outside its scope and would thus be impure. So the whole outer function is pure, but the looping is not. Looping constructs in functional programming require you to make the state explicit. Translating your code to something using functional programming looping tools reveals the impurity:
int as_int(char *str)
{
    int acc = 0; /* accumulate the partial result */

    map(takeWhile(isdigit, str), void function(char *chr) {
      acc = acc * 10 + (chr - '0');
    });

    return acc;
}

(Note - this syntax is approximate to get the general idea across)
This code uses an inner function for the loop body which must mutate the variable acc, which is outside it's scope. This is impure - the inner loop function depends on the outer loop context, calling it multiple times with the same character will have side-effects, and the order you call it on the sequence of characters matters. In functional programming, in order to make this a pure function you would have to make this dependency on state passed between loop iterations explicit with fold:
int as_int(char *str)
{
    return fold(takeWhile(isdigit, str), 0, int function(char *chr, int acc) {
      return acc * 10 + (chr - '0');
    });
}

fold uses a function of two arguments for the inner loop body: the first argument is an item in the sequence that fold is looping over, while the second is some value that the inner loop body uses to build up partial results. For the first loop iteration, acc is 0, for the second, acc is whatever the first inner loop function call returned, for the third, it's whatever the second inner loop returned, and the final loop returns the result of the whole fold expression.
Note that this isn't really a problem with your code from the perspective of the rest of your program - both definitions of as_int are pure. The difference is by making the inner loop code a pure function, you can take advantage of the massive array of tools functional programming offers to decompose the loop into something more declarative (e.g. using takeWhile, fold, filter, map, etc. etc.)


TF-IDF Scores:
10: 0.0742
advantage: 0.0467
argument: 0.0446
arguments: 0.0414
array: 0.0390
body: 0.1338
build: 0.0371
calling: 0.0429
calls: 0.0401
character: 0.0429
characters: 0.0401
code: 0.0925
constructs: 0.0467
context: 0.0401
control: 0.0390
depends: 0.0429
difference: 0.0414
effects: 0.0446
filter: 0.0446
final: 0.0446
function: 0.3690
functional: 0.1901
functions: 0.0380
general: 0.0380
idea: 0.0363
inside: 0.0401
int: 0.2143
like: 0.0370
loop: 0.7135
make: 0.0745
making: 0.0371
map: 0.1402
matters: 0.0467
multiple: 0.0355
note: 0.0780
order: 0.0857
outside: 0.1204
partial: 0.0934
passed: 0.0429
problem: 0.0279
program: 0.0319
programming: 0.1292
pure: 0.1784
really: 0.0297
require: 0.0380
rest: 0.0429
result: 0.0828
results: 0.0414
return: 0.0989
returns: 0.0390
scope: 0.0934
second: 0.1066
state: 0.0780
statements: 0.0446
syntax: 0.0414
times: 0.0355
tools: 0.0803
uses: 0.0957
using: 0.0483
value: 0.0380
variable: 0.0363
variables: 0.0803
void: 0.0429

Termine con il punteggio TF-IDF più alto: loop (0.7135)

----------------------------------------------------------------------------------------------------

Question 267289:
I have the method which returns java.util.Date inside the hibernate-entity class:
package ua.com.winforce.loto_partner.commons.db.entity;

@Entity
@Table(schema = "pr", name = "publice")
public class Pr {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    @Column(name = "id")
    private int id;

    @Column(name = "reg_date")  
    private Date regDate;

    //GET, SET
}

And in a method I need to create the local variable which will be hold getRegDate(); value, or to invoke that method twice. What would be more appropriate in that case? I mean, in the first case we're potentially closing the moment when GC will be triggered, but in the first we waste our time to the second method invocation.


TF-IDF Scores:
case: 0.1893
class: 0.1677
column: 0.2939
com: 0.1195
create: 0.0899
db: 0.1403
entity: 0.4208
id: 0.4208
inside: 0.1262
int: 0.1348
java: 0.1004
local: 0.1348
mean: 0.1348
method: 0.3640
moment: 0.1469
need: 0.0797
private: 0.2604
public: 0.1262
returns: 0.1227
schema: 0.1348
second: 0.1117
set: 0.1055
strategy: 0.1302
table: 0.1469
time: 0.0781
value: 0.1195
variable: 0.1141

Termine con il punteggio TF-IDF più alto: entity (0.4208)

Best Answer:
There are three reasons* to cache a function return in a variable:

You know or suspect that the function has side effects.
The function can return different values on every call, and you need a consistent result. Normally this is due to the function having side-effects, but it can also be due to reading volatile data.
The repeated function call would make the code less clear. This is the "extract explanatory variable" refactoring.

Your example doesn't appear to fit any of these cases.
* there is a fourth, but it's reserved for Doug Lea and Martin Thompson, and is arguably a combination of #1 and #2.


TF-IDF Scores:
cache: 0.1713
cases: 0.1170
clear: 0.1635
code: 0.0678
combination: 0.1713
data: 0.1035
different: 0.1103
effects: 0.3270
example: 0.0967
extract: 0.1713
fit: 0.1635
function: 0.6148
know: 0.0902
make: 0.0911
need: 0.0928
normally: 0.1713
reading: 0.1430
reasons: 0.1518
refactoring: 0.1571
result: 0.1518
return: 0.2417
suspect: 0.1635
values: 0.1471
variable: 0.2660

Termine con il punteggio TF-IDF più alto: function (0.6148)

----------------------------------------------------------------------------------------------------

Question 267304:
I'm building a php system with the Services/DAOs/Domain Models pattern, and now is the time to implement a caching system for the DAOs.
Would you use a decorator pattern, or maybe the strategy pattern?
What are the ups and downs of each one?
added requirement: Like I told in a comment answering to edalorzo I need to be able to use the DAOs without any caching at some moments. For the same method sometimes is acceptable to have cache, but some other times is not.


TF-IDF Scores:
able: 0.1510
acceptable: 0.1986
added: 0.1616
building: 0.1822
cache: 0.1986
caching: 0.3971
comment: 0.1822
decorator: 0.1986
domain: 0.1895
implement: 0.1542
like: 0.0786
maybe: 0.1616
method: 0.1230
need: 0.1076
pattern: 0.4626
php: 0.1760
requirement: 0.1986
services: 0.1895
strategy: 0.1760
time: 0.1056
times: 0.1510
told: 0.1895
ups: 0.1986
use: 0.1719

Termine con il punteggio TF-IDF più alto: pattern (0.4626)

Best Answer:
I have seen the implementation of caches using a Proxy pattern. Particularly frameworks like AOP make use of proxies for most of these things.
According to the book Design Patterns and Elements of Reusable Object-Oriented Software the decorator and proxy pattern may look alike/
Page 216:

"Although decorators may have similar implementations as proxies,
  decorators have a different purpose. A decorator adds one or more
  responsibilities to an object, whereas a proxy controls access to an
  object.
Proxies vary in the degree to which they are implemented like a
  decorator.A protection proxy might be implemented exactly like a
  decorator. On the other hand, a remote proxy will not contain a direct
  reference to its real subject but only an indirect reference, such as
  a "host ID and local address on the host". A virtual proxy will start
  off with an indirect reference such as a file name but will eventually
  obtain and use a direct reference"

It looks like your purpose with the cache is to avoid giving direct access to the real subject, so it sounds more like a proxy to me.
The comment above also clearly makes evident that an important difference between a proxy and a decorator is that the proxy may be responsible for instantiating or getting access to the real subject, whereas in the case of the decorator is kind of expected that such reference will be dynamically provided.
It would seem that the relationship between the proxy and real subject is more static than in the case of the decorator.
That being said, ultimately in you case is a matter of intent more than how the design will look like. At the end the solution is to have a wrapper object (either called Proxy or Decorator) that will intercept the method and allow you to control when to gain access to a cache or not depending on your cache policy.


TF-IDF Scores:
access: 0.2215
address: 0.0728
adds: 0.0728
allow: 0.0645
avoid: 0.0626
book: 0.0645
cache: 0.2185
called: 0.0579
case: 0.1408
clearly: 0.0695
comment: 0.0668
contain: 0.0728
control: 0.0608
decorator: 0.5827
degree: 0.0695
depending: 0.0728
design: 0.0939
difference: 0.0645
different: 0.0469
direct: 0.2086
dynamically: 0.0645
elements: 0.0645
end: 0.0566
eventually: 0.0695
exactly: 0.0626
expected: 0.0668
file: 0.0543
frameworks: 0.0668
gain: 0.0695
getting: 0.0593
giving: 0.0668
hand: 0.0579
id: 0.0695
implementation: 0.0543
implementations: 0.0668
implemented: 0.1291
important: 0.0543
kind: 0.0608
like: 0.1730
local: 0.0668
look: 0.1065
looks: 0.0608
make: 0.0387
makes: 0.0451
matter: 0.0668
method: 0.0451
object: 0.1877
oriented: 0.0728
page: 0.0728
pattern: 0.1131
patterns: 0.0668
provided: 0.0645
purpose: 0.1185
real: 0.2263
reference: 0.3227
relationship: 0.0645
responsible: 0.0695
said: 0.0579
seen: 0.0566
similar: 0.0554
software: 0.0514
solution: 0.0523
sounds: 0.0608
start: 0.0498
static: 0.0579
things: 0.0430
ultimately: 0.0695
use: 0.0631
using: 0.0377
wrapper: 0.0695

Termine con il punteggio TF-IDF più alto: decorator (0.5827)

----------------------------------------------------------------------------------------------------

Question 267305:
We know that checking return values prevent our software from unexpected states. (You can see CWE definition.)
But, we are sometimes sure about the return value. For example:
bool calculateSquareRootReturnFalseIfInputIsNegative(float input, float& output);
float calculateHypotenuse(float a, float b){
  float c2 = (a*a) + (b*b);
  float c;
  calculateSquareRootReturnFalseIfInputIsNegative(c2, c);
  return c;
}

The local variable c2 is always positive. So, calculateSquareRootReturnFalseIfInputIsNegative() always returns true. I shouldn't check its return value.
Finally, Is "check all return values not already known by caller" a valid idiom?
Thanks..


TF-IDF Scores:
check: 0.2722
checking: 0.1553
definition: 0.1608
example: 0.0990
finally: 0.1753
input: 0.1464
know: 0.0923
known: 0.1673
local: 0.1608
output: 0.1464
return: 0.6185
returns: 0.1464
software: 0.1237
sure: 0.1306
thanks: 0.1753
true: 0.1553
unexpected: 0.1673
valid: 0.1426
value: 0.2852
values: 0.3011
variable: 0.1361

Termine con il punteggio TF-IDF più alto: return (0.6185)

Best Answer:

Is checking return values always required?

I don't think so; rather, they are almost always required. Proper error checking is very important, although sometimes it can admittedly be a pain in the neck.
However, your particular example does not describe a typical "perform operation that may fail and check the error" scenario. If your assumption about the sum of squares being positive is right (e. g. you expect this to be the case, and you don't permit e. g. NaN inputs), then what you are looking for is an assertion. 
Assertions are used in situations exactly like this: when you have an operation that can sometimes fail, but you always pass it inputs for which it cannot possibly/shouldn't ever fail. Your program's internal consistency depends on this, so you assert, so that if this promise/assumption in your code ever breaks, you will get notified (i. e. the program crashes reliably at the earliest point it detects the inconsistency).


TF-IDF Scores:
breaks: 0.1678
case: 0.1081
check: 0.1303
checking: 0.2974
code: 0.0664
depends: 0.1540
error: 0.2883
exactly: 0.1441
example: 0.0948
expect: 0.1602
important: 0.1250
inputs: 0.3356
internal: 0.1602
like: 0.0664
looking: 0.1333
operation: 0.3204
particular: 0.1276
pass: 0.1401
perform: 0.1487
point: 0.1205
possibly: 0.1401
program: 0.2292
promise: 0.1602
proper: 0.1678
required: 0.2974
return: 0.1184
right: 0.1250
scenario: 0.1602
situations: 0.1678
think: 0.0876
used: 0.1026
values: 0.1441

Termine con il punteggio TF-IDF più alto: inputs (0.3356)

----------------------------------------------------------------------------------------------------

Question 267306:
This is a really simple question but oddly, I'm finding it difficult to get a definite answer.... 
What do you do with fields? Is this valid?
/** 
 * Keeps track of all usernames in the system.
 */   
private List<String> usernames = new ArrayList<>();

Or is above ingnored by documentation tools, so would it be best to do something like:
 //Keeps track of all usernames in the system.   
private List<String> usernames = new ArrayList<>();

Since (from what I see), documentation only shows methods, constructors and classes, what do programmers usually do with fields?


TF-IDF Scores:
answer: 0.1237
best: 0.1545
classes: 0.1479
difficult: 0.1479
documentation: 0.3891
fields: 0.3091
finding: 0.1946
like: 0.0770
list: 0.2618
methods: 0.1397
new: 0.2153
private: 0.3449
programmers: 0.1450
question: 0.1176
really: 0.1237
simple: 0.1583
string: 0.3250
tools: 0.1671
track: 0.3449
usually: 0.1423
valid: 0.1583

Termine con il punteggio TF-IDF più alto: documentation (0.3891)

Best Answer:
Private fields are usually ignored by documentation tools, so when you ship your API to a third party, they will not be able to see any documentation regarding private fields (unless you specify that you also want to include private fields in the documentation during the documentation generation phase of your project).
That being said, I think it is a good idea to use JavaDoc to also document private fields because:

It will conform to the rest of the other documentation.
Most IDEs will extract JavaDoc and show it to you when you try and access different object properties. This can save time going around the code to see what is the purpose of a particular variable.
In the event that you will want to include private field documentation into your documentation, all the work will have already been done.



TF-IDF Scores:
able: 0.0756
access: 0.0756
api: 0.0949
code: 0.0393
different: 0.0640
document: 0.0994
documentation: 0.6958
event: 0.0949
extract: 0.0994
field: 0.0912
fields: 0.3158
going: 0.0756
good: 0.0580
idea: 0.0772
include: 0.1708
object: 0.0640
particular: 0.0756
private: 0.4404
project: 0.0640
properties: 0.0881
purpose: 0.0809
regarding: 0.0994
rest: 0.0912
said: 0.0789
save: 0.0949
think: 0.0519
time: 0.0528
tools: 0.0854
try: 0.0714
unless: 0.0912
use: 0.0430
usually: 0.0727
variable: 0.0772
want: 0.1037
work: 0.0567

Termine con il punteggio TF-IDF più alto: documentation (0.6958)

----------------------------------------------------------------------------------------------------

Question 267309:
I joined a project were we sell services for different providers through web, iOS and android apps. I am working on iOS. I was ask to display a purchase form via a web view and react by what is entered natively. I do so by intercepting the network communication but as you can imagine it is slow, error prone and just kind of stupid. 
I ask why it has to be done in this way, why I just cannot get the data and render the form myself natively, and I was told that soon also the android app will adapt this feature and as the form can slightly change for each providers that would be the easiest approach.   
While I agree that it is easier to decide on the server which fields are needed for each call, I don't think that the logical conclusion is to request a html form and create hackish interception around it. 
Before the implementation for android starts I want to propose another option:
Instead of rendering a website I want the server to create a JSON to describe the form, that than can easily be used at client-side to create the form. Basically a server generated view model.
My question is: is there some "standard" already how such a JSON should look like?
I imagine it something like this
{
  "form": {
    "action": {
      "action-name": "Send",
      "method": "POST",
      "target": "https://api.mydomain.com/purchase/"
    },
    "fieldsets": [{
      "fieldset-name": "personal information",
      "fields": [{
        "field": {
          "kind": "text-field",
          "field-name": "First Name",
          "validator": {
            "validator-name": "regex-validator",
            "arguments": [{
              "regex": ".{3:}"
            }]
          },
          "optional": false
        }
      }, {
        "field": {
          "kind": "text-field",
          "field-name": "Last Name",
          "validator": {
            "validator-name": "regex-validator",
            "arguments": [{
              "regex": ".{3:}"
            }]
          },
          "optional": false
        }
      }, {
        "field": {
          "kind": "text-field",
          "field-name": "Email",
          "validator": {
            "validator-name": "email-validator"
          },
          "optional": false
        }
      }, {
        "field": {
          "kind": "text-field",
          "field-name": "Confirm Email",
          "validator": {
            "validator-name": "email-validator"
          },
          "optional": false
        }
      }]
    }, {
      "fieldset-name": "Credit Card Data",
      "fields": [{
        "field": {
          "kind": "text-field",
          "field-name": "Credit Card Number",
          "validator": {
            "validator-name": "creditcard-number-validator"
          },
          "optional": false
        }
      }]
    }]
  }
}



TF-IDF Scores:
android: 0.1356
api: 0.0502
app: 0.0418
approach: 0.0378
apps: 0.0502
arguments: 0.0933
ask: 0.0879
basically: 0.0483
card: 0.1052
change: 0.0365
client: 0.0428
com: 0.0428
communication: 0.0466
create: 0.0966
data: 0.0636
decide: 0.0392
different: 0.0339
easier: 0.0418
easily: 0.0418
email: 0.2009
error: 0.0452
feature: 0.0466
field: 0.7242
fields: 0.1254
form: 0.2926
generated: 0.0526
html: 0.0502
https: 0.0452
implementation: 0.0392
information: 0.0378
instead: 0.0378
kind: 0.2637
like: 0.0417
logical: 0.0526
look: 0.0385
method: 0.0326
model: 0.0452
needed: 0.0428
number: 0.0719
option: 0.0439
personal: 0.0439
post: 0.0502
project: 0.0339
prone: 0.0502
question: 0.0318
render: 0.0526
request: 0.0483
send: 0.0526
server: 0.1226
services: 0.0502
slightly: 0.0502
slow: 0.0502
soon: 0.0502
standard: 0.0452
starts: 0.0483
stupid: 0.0526
target: 0.0502
text: 0.2631
think: 0.0275
told: 0.0502
used: 0.0322
view: 0.0966
want: 0.0549
way: 0.0265
web: 0.0743
website: 0.0452
working: 0.0354

Termine con il punteggio TF-IDF più alto: field (0.7242)

Best Answer:
I think the standard you are looking for is JSON Schema. It's not specific to forms, it's a more general specification for defining what a particular JSON format looks like (like an XML schema). There are a few solutions for creating forms with JSON Schema, like joshfire/jsonform.


TF-IDF Scores:
creating: 0.1772
defining: 0.2356
format: 0.2356
general: 0.2008
like: 0.2931
looking: 0.1960
looks: 0.2061
particular: 0.1876
schema: 0.6793
solutions: 0.2356
specific: 0.1917
standard: 0.2120
think: 0.1288

Termine con il punteggio TF-IDF più alto: schema (0.6793)

----------------------------------------------------------------------------------------------------

Question 267310:
I am just learning Java, and am not a practicing programmer.  
The book I am following says that when overriding a method, the argument types must be the same, but the return types can be polymorphically compatible. 
My question is why can't the arguments passed to the overriding method not be a subclass type of the super-type expected? 
In the overloaded method, whatever method I call on the object is guaranteed to be defined on the object. 

Notes on suggested duplicates:
The first suggestion appears to be about class hierarchy and where to put functionality.  My question is more focused on why the language restriction exists.  
The second suggestion explains how to do what I'm asking, but not why it has to be done that way.  My question is focused on the why.


TF-IDF Scores:
argument: 0.1584
arguments: 0.1471
asking: 0.1426
book: 0.1471
class: 0.0947
exists: 0.1584
expected: 0.1523
focused: 0.3319
following: 0.1289
functionality: 0.1426
hierarchy: 0.1660
java: 0.1134
language: 0.0947
learning: 0.1386
method: 0.4112
object: 0.2139
passed: 0.1523
programmer: 0.1237
question: 0.3009
return: 0.1171
says: 0.1660
second: 0.1262
suggestion: 0.3169
type: 0.2304
types: 0.2772
way: 0.0835

Termine con il punteggio TF-IDF più alto: method (0.4112)

Best Answer:
The concept you initially refer to in your question is called covariant return types.
Covariant return types work because a method is supposed to return an object of certain type and overriding methods may actually return a subclass of it. Based on the subtyping rules of a language like Java, if S is a subtype of T, then wherever T appears we can pass an S.
As such it is safe to return an S when overriding a method that expected a T.
Your suggestion to accept that an overriding a method uses arguments that are subtypes of those requested by the overridden method is much more complicated since it leads to unsoundness in the type system.
By one hand, by the same subtyping rules mentioned above, most likely it already works for what you want to do. For instance
interface Hunter {
   public void hunt(Animal animal);
}

Nothing prevents implementations of this class from receiving any kind of animal, as such it already satisfies the criteria in your question. 
But let's suppose we could override this method as you suggested:
class MammutHunter implements Hunter {
  @Override
  public void hunt(Mammut animal) {
  }
}

Here's the funny part, now you could do this:
AnimalHunter hunter = new MammutHunter();
hunter.hunt(new Bear()); //Uh oh

As per the public interface of AnimalHunter you should be able to hunt any animal, but as per your implementation of MammutHunter you only accept Mammut objects. Therefore the overriden method does not satisfy the public interface. We just broke the soundness of the type system here.
You can implement what you want by using generics.
interface AnimalHunter<T extends Animal> {
   void hunt(T animal);
}

Then you could define your MammutHunter 
class MammutHunter implements AnimalHunter<Mammut> {
   void hunt(Mammut m){
   }
}

And using generic covariance and contravariance you can relax the rules in your favor when necessary. For instance we could make sure that a mammal hunter can only hunt felines in a given context:
AnimalHunter<? super Feline> hunter = new MammalHunter();
hunter.hunt(new Lion());
hunter.hunt(new Puma());

Supposing MammalHunter implements AnimalHunter<Mammal>.
In that case this would not be accepted:
hunter.hunt(new Mammut()):

Even when mammuts are mammals it would not be accepted due to the restrictions on the contravariant type we are using here. So, you can still excercice some controll over the types to do things like the ones you mentioned.


TF-IDF Scores:
able: 0.0649
accepted: 0.1630
actually: 0.0624
arguments: 0.0757
based: 0.0624
called: 0.0678
case: 0.0550
certain: 0.0815
class: 0.1462
complicated: 0.0783
concept: 0.0757
context: 0.0733
define: 0.0783
expected: 0.0783
generic: 0.0815
given: 0.0663
hand: 0.0678
implement: 0.0663
implementation: 0.0636
implementations: 0.0783
instance: 0.1467
interface: 0.2596
java: 0.0583
kind: 0.0713
language: 0.0487
let: 0.0678
like: 0.0676
likely: 0.0663
make: 0.0454
mentioned: 0.1707
method: 0.3172
methods: 0.0613
necessary: 0.0757
new: 0.2833
object: 0.0550
objects: 0.0624
ones: 0.0757
pass: 0.0713
public: 0.2933
question: 0.1032
return: 0.3012
rules: 0.2445
suggestion: 0.0815
suppose: 0.0783
supposed: 0.0757
sure: 0.0636
things: 0.0504
type: 0.2370
types: 0.2139
uses: 0.0583
using: 0.1324
void: 0.3133
want: 0.0891
work: 0.0487
works: 0.0636

Termine con il punteggio TF-IDF più alto: method (0.3172)

----------------------------------------------------------------------------------------------------

Question 267313:
I have Student and Group entities. Student can have many groups and Group can have many students too. so in database I should have middle class and change many-to-many relation to one-to-many and many-to-one.
My question is how should I design class diagram in oop?
If middle table does not have any extra field(just student_id and group_id) then I think no middle class is need in oop, is this true or not?


TF-IDF Scores:
change: 0.1508
class: 0.3721
database: 0.1652
design: 0.1400
entities: 0.2173
extra: 0.1925
field: 0.1994
group: 0.4148
need: 0.1178
oop: 0.3851
question: 0.1313
student: 0.4148
students: 0.2173
table: 0.2173
think: 0.1134
true: 0.1925

Termine con il punteggio TF-IDF più alto: group (0.4148)

Best Answer:
You don't need a class for that, but maybe you want one. At the database design level, I like to avoid linking tables and think of those tables as first class entities instead. So if we have student and class tables for example, instead of creating a student_class linking table to satisfy that many-to-many relationship, we could call it something like enrollment.
Now, at the OOP level, we don't have to think about whether we should write something like student.addClass(class) or class.addStudent(student). Instead we can write new Enrollment(student, class). And, if we ever decide that we need to store more data about that relationship, we don't have to deal with awkward problems that come from linking tables having extra fields (especially with respect to ORMs and so on). Since Enrollment is a first-class entity, it can have any other properties we want in addition to student and class.
If you can conceptualize the relationship between a student and a group as its own entity, it would probably be cleanest to model it that way.


TF-IDF Scores:
addition: 0.0986
avoid: 0.0887
class: 0.4717
come: 0.0802
creating: 0.0742
data: 0.0624
database: 0.0785
decide: 0.0770
design: 0.0666
entities: 0.1033
entity: 0.1972
especially: 0.0948
example: 0.0583
extra: 0.0915
fields: 0.0820
group: 0.0986
instead: 0.2225
level: 0.1725
like: 0.1227
maybe: 0.0840
model: 0.0887
need: 0.1120
new: 0.0571
oop: 0.0915
probably: 0.0742
problems: 0.0755
properties: 0.0915
relationship: 0.2746
store: 0.0887
student: 0.5917
table: 0.1033
think: 0.1078
want: 0.1078
way: 0.0520
write: 0.1331

Termine con il punteggio TF-IDF più alto: student (0.5917)

----------------------------------------------------------------------------------------------------

Question 267318:
I have a set of classes that represent different objects (tables in a database):
class ObjA:
    # some class specific attributes and methods

    def refresh(self):
        # implementation
        pass

class ObjB:
    # some class specific attributes and methods

    def refresh(self):
        # implementation
        pass

and they all have a refresh method. Now I have a task manager (like Luigi) that is used to call the refresh method on each class and the definitions look like:
from somewhere import ObjA, ObjB


class RefreshObjA(TaskManager):
    def run(self):
        ObjA.refresh()


class RefreshObjB(TaskManager):
    def run(self):
        ObjB.refresh()

TaskManager here is a parent class provided by the manager module. As you can see, the class definitions all have an identical pattern and naming convention, and it stands to reason that these can be dynamically generated as generateRefreshClasses([ObjA, ObjB, ...]). 
However, I have been resisting this and writing each one out explicitly because

All the information re: the classes is available when the code is written i.e. I'm not reliant on any external/user generated input which is probably where dynamic generation is useful. This use is purely to save space/keystrokes/repetition.
One doesn't know if some ObjX might need modifications/additional requirements and will need to be careful to remove it from the dynamic generator, lest it is overwritten. 
It is harder to reason where (as in file and line no:) an execution error occurs if the code is dynamically generated. 
These classes might be imported elsewhere in the code base and I lose out on the static inspection based checking provided by the IDE.

Are these valid reasons to continue to individually define the classes (there might be about 20 or so of them) or are there other benefits to dynamic generation that might make these concerns small in comparison? Would dynamic generation of classes be considered acceptable/good practice in such an application?


TF-IDF Scores:
20: 0.0831
acceptable: 0.0831
additional: 0.0736
application: 0.0694
attributes: 0.1662
available: 0.0736
base: 0.0831
based: 0.0608
benefits: 0.0694
checking: 0.0736
class: 0.4270
classes: 0.3159
code: 0.0987
comparison: 0.0831
concerns: 0.0793
considered: 0.0793
continue: 0.0831
database: 0.0632
define: 0.0763
different: 0.0535
dynamic: 0.3050
dynamically: 0.1473
error: 0.0714
explicitly: 0.0793
file: 0.0619
generated: 0.2493
good: 0.0485
harder: 0.0831
ide: 0.0763
implementation: 0.1239
information: 0.0597
input: 0.0694
know: 0.0438
like: 0.0658
line: 0.0676
look: 0.0608
make: 0.0442
manager: 0.1587
method: 0.1029
methods: 0.1193
module: 0.0831
need: 0.0901
objects: 0.0608
parent: 0.0831
pass: 0.1388
pattern: 0.0645
practice: 0.0736
probably: 0.0597
provided: 0.1473
reason: 0.1239
reasons: 0.0736
remove: 0.0694
represent: 0.0694
requirements: 0.0632
run: 0.1264
save: 0.0793
self: 0.3050
set: 0.0597
small: 0.0676
space: 0.0714
specific: 0.1291
static: 0.0660
task: 0.0645
use: 0.0360
used: 0.0508
useful: 0.0660
user: 0.0568
valid: 0.0676
writing: 0.0714
written: 0.0694

Termine con il punteggio TF-IDF più alto: class (0.4270)

Best Answer:
You seem to have an appreciation of the trade-offs involved here. As you say, since you know all the information about your classes in advance, it doesn't quite make sense to generate them dynamically.
One alternative to reduce your boring duplicated boilerplate code is to use Python's wonderful support for metaprogramming. If all your refresh methods follow a similar template but the details vary due to the names and types of your classes' attributes, it makes sense to use a metaclass to generate this method when the class is created. In other words, you keep your class statements, and you still declare your class members statically in code, but the information about the refresh boilerplate is kept in one place (in the template that is used by the metaclass). (You could get the same effect using a regular base class and introspection; without more details about your code, I can't give you a clear assessment of what approach would be a good fit for your problem.)
A second option would be to use a code generator. This typically takes the form of a script which takes (for example) some XML or YAML defining your objects as input, and writes out a valid Python file into your build directory. Don't check the generated code into source control; instead just run the generator script every time you build the code. This way you still get file/line information when debugging, and the resulting code is typically not too hard to understand because it's mostly boilerplate. On the other hand, you can't directly edit the file once you've diagnosed a problem because it'll be overwritten next time you run a build - you have to modify the generator. So this approach still has many of the advantages and disadvantages of full-blown runtime class creation.
Another question you should consider asking is "Do we really know everything about these objects in advance?". 20 similar classes is a lot, and it suggests to me that a future requirements change may in fact need you to load these classes at runtime. While you should of course follow YAGNI, you can still design your code in such a way that this change would be easy to make in future. This is another way in which metaprogramming can help you out.


TF-IDF Scores:
20: 0.0874
advantages: 0.0775
alternative: 0.0874
approach: 0.1255
asking: 0.0751
attributes: 0.0874
base: 0.0874
build: 0.2083
change: 0.1213
check: 0.0679
class: 0.2495
classes: 0.2658
clear: 0.0834
code: 0.2768
consider: 0.0775
control: 0.0730
course: 0.0751
created: 0.0711
debugging: 0.0834
declare: 0.0874
defining: 0.0834
design: 0.0563
details: 0.1422
directly: 0.0730
disadvantages: 0.0874
dynamically: 0.0775
easy: 0.0679
edit: 0.0751
example: 0.0494
fact: 0.0751
file: 0.1954
fit: 0.0834
follow: 0.1604
form: 0.0694
future: 0.1669
generate: 0.1669
generated: 0.0874
good: 0.0510
hand: 0.0694
hard: 0.0730
help: 0.0617
information: 0.1883
input: 0.0730
instead: 0.0628
involved: 0.0874
know: 0.0921
line: 0.0711
load: 0.0775
lot: 0.0607
make: 0.0929
makes: 0.0541
members: 0.0802
method: 0.0541
methods: 0.0628
modify: 0.0834
names: 0.0834
need: 0.0474
objects: 0.1278
option: 0.0730
place: 0.0711
problem: 0.1044
python: 0.1388
question: 0.0528
quite: 0.0651
really: 0.0556
reduce: 0.0802
regular: 0.0834
requirements: 0.0665
resulting: 0.0874
run: 0.1329
say: 0.0563
second: 0.0665
sense: 0.1329
similar: 0.1329
source: 0.0679
statements: 0.0834
statically: 0.0834
support: 0.0694
takes: 0.1234
time: 0.0929
types: 0.0730
typically: 0.1748
understand: 0.0639
use: 0.1135
used: 0.0535
using: 0.0452
valid: 0.0711
way: 0.1320
words: 0.0775

Termine con il punteggio TF-IDF più alto: code (0.2768)

----------------------------------------------------------------------------------------------------

Question 267321:
I have two designs which achieve the same result.
-------Design A


MainClass has a List and two methods. The methods create an autonomous object and is added to the list. The reason for the superclass, B and C are similar and I will be adding more subclasses. Furthermore, I can take advantage of polymorphism later on.
-------Design B


mainclass has two methods. The method creates a aggregation link with MiddleClass and directly calls Mainclass methods - which returns an autonomous object of class b/c.
Unlikely A, B benefits from a higher degree of (loose)coupling from the MainClass, where the MiddleClass acts handles information from the inheritance hierarchy to the mainclass - And of course, the more subclasses I add, the mainclass will not have any additional links to the hierarchy, instead, it's all dealt with by middleclass.
However, I am not sure if I am just over-engineering the design or if it's a better design. What do you guys think is the better design and why?


TF-IDF Scores:
add: 0.1012
added: 0.1166
adding: 0.1270
additional: 0.1270
advantage: 0.1433
benefits: 0.1197
better: 0.1753
calls: 0.1231
class: 0.0818
coupling: 0.1433
course: 0.1231
create: 0.0877
degree: 0.1368
design: 0.4617
directly: 0.1197
handles: 0.1433
hierarchy: 0.2867
higher: 0.1138
information: 0.1029
instead: 0.1029
later: 0.1231
link: 0.1433
list: 0.1928
method: 0.0888
methods: 0.4117
object: 0.1847
reason: 0.1068
result: 0.1270
returns: 0.1197
similar: 0.1090
subclasses: 0.2736
sure: 0.1068
think: 0.0748

Termine con il punteggio TF-IDF più alto: design (0.4617)

Best Answer:
In both designs, MainClass has to know about ClassB and ClassC (and any future derived classes) to provide the methods to create and add new list elements. This makes that with the current interface for users of MainClass the first design is the simplest design and the best of the two.
However, it is possible to create a better design by decoupling MainClass and MiddleClass.
MainClass only needs to provide a method to add (already created) items to the list.
MiddleClass is actually a factory class, as already noted in the comments, and should be made available to the user to create the items that should be added to the list.
This way, MainClass doesn't need to be updated if new classes are added to the hierarchy, but only MiddleClass.


TF-IDF Scores:
actually: 0.1187
add: 0.2291
added: 0.2641
available: 0.1438
best: 0.1289
better: 0.0993
class: 0.0926
classes: 0.2468
comments: 0.1321
create: 0.2978
created: 0.1321
current: 0.1260
design: 0.3137
elements: 0.1438
factory: 0.1623
future: 0.1549
hierarchy: 0.1623
interface: 0.1234
items: 0.2876
know: 0.0855
list: 0.3275
makes: 0.1005
method: 0.1005
methods: 0.1165
need: 0.0880
needs: 0.1209
new: 0.1795
possible: 0.1126
provide: 0.2468
user: 0.1109
users: 0.1355
way: 0.0817

Termine con il punteggio TF-IDF più alto: list (0.3275)

----------------------------------------------------------------------------------------------------

Question 267323:
I have a system with a structure like this:

The ConcreteWriteable is caching the ReadOnlyWrapper.
This is a similar system to what .Net's System.Array uses for its Array.AsReadOnly<T>(T[] array) method (ignoring for the moment that System.Array's AsReadOnly is static). However looking at the code for System.Array at reference source, System.Array.AsReadOnly is returning a new wrapper each time, whereas I'm creating the wrapper at the same time as the ConcreteWriteable and caching it, then returning the same one each time.
This got me thinking, is there some reason why I shouldn't be doing this? Is there some reason why creating a new wrapper each time is more desirable than returning the same wrapper (bearing in mind that the wrapper cannot possibly change the ConcreteWriteable and is indeed a wrapper, not a copy)?


TF-IDF Scores:
array: 0.5500
caching: 0.2195
change: 0.0762
code: 0.0435
copy: 0.0943
creating: 0.1576
got: 0.0917
like: 0.0435
looking: 0.0872
method: 0.0680
mind: 0.1048
moment: 0.1098
net: 0.0852
new: 0.1214
possibly: 0.0917
reason: 0.1636
reference: 0.0973
similar: 0.0835
source: 0.0852
static: 0.0872
structure: 0.1048
thinking: 0.0872
time: 0.2334
uses: 0.0750
wrapper: 0.6287

Termine con il punteggio TF-IDF più alto: wrapper (0.6287)

Best Answer:
If the wrapper is truly immutable, program behavior is identical whether you create a new wrapper each time, or reuse one. The only difference is the thrashing of the garbage collector.
I have thought about using structs as read-only collection wrappers, instead of class instances, but I realized there would be little gain, since often a collection is cast as a collection interface, which would box the structure.


TF-IDF Scores:
behavior: 0.2103
class: 0.1201
collection: 0.6024
create: 0.1287
difference: 0.1864
gain: 0.2008
instances: 0.2008
instead: 0.1510
interface: 0.1599
little: 0.1671
new: 0.1163
program: 0.1437
read: 0.1599
structure: 0.2008
thought: 0.2008
time: 0.1118
truly: 0.2103
using: 0.1087
wrapper: 0.4016

Termine con il punteggio TF-IDF più alto: collection (0.6024)

----------------------------------------------------------------------------------------------------

Question 267326:
I was reading about copy constructors for structs and i found this example:
#include <iostream>
#include <string>
using namespace std;

struct SomeData {
    int * pd;
    string id;
    SomeData(SomeData & ref) {
        cout << "Copy Constructor called" << endl;
        pd = new int (*ref.pd);
        id = "Copy Constructed";
    }
    SomeData(string name) {
        pd = new int(0);
        id = name;
        cout << "Constructor for " << id << endl;
    };
    ~SomeData() {
        cout << "Destructor for " << id << endl;
        delete pd;
    }
};

int main() {
    SomeData s("First");
    *s.pd = 9;
    SomeData s2=s;
    cout << *s2.pd << endl;
    return 0;
}

in the main, the member pd of SomeData is accessed using the dereference,
but why is that, isn't the correct way is 
s->pd=9;

why was it written like that in the example?


TF-IDF Scores:
called: 0.0977
constructor: 0.2054
copy: 0.3169
correct: 0.1027
destructor: 0.1230
example: 0.1389
id: 0.5870
include: 0.2113
int: 0.4514
like: 0.0487
main: 0.1870
member: 0.1027
new: 0.1360
reading: 0.1027
return: 0.0868
string: 0.3081
using: 0.1272
way: 0.0619
written: 0.1027

Termine con il punteggio TF-IDF più alto: id (0.5870)

Best Answer:
This is an example of operator precedence not giving quite the results you expect. The example has the code
*s.pd = 9;

which is equivalent to the following:
*(s.pd) = 9;

You query why it isn't written as
s->pd = 9;

but this is equivalent to
(*s).pd = 9;

That is, the code in the example dereferences the value of pd that is a member of s, whereas the code you are asking about dereferences s (which is not legal as s is not a pointer and doesn't have an overload for the "->" operator).
This is because ".", the member selection operator binds more strongly than "*", the dereference operator.  
See http://en.cppreference.com/w/cpp/language/operator_precedence for a complete list; "." has a precedence of 2, while "*" has a precedence of 3. Only "::" binds more strongly than ".".


TF-IDF Scores:
asking: 0.1417
code: 0.1959
com: 0.1342
complete: 0.1342
en: 0.1650
equivalent: 0.3028
example: 0.2795
expect: 0.1575
following: 0.1281
giving: 0.1514
http: 0.1575
language: 0.0942
list: 0.1110
member: 0.2755
operator: 0.6300
pointer: 0.1575
query: 0.1650
quite: 0.1229
results: 0.1462
value: 0.1342
written: 0.1378

Termine con il punteggio TF-IDF più alto: operator (0.6300)

----------------------------------------------------------------------------------------------------

Question 267344:
It is a Design Problem which I am listing out here.
I have different set of business operations that are carried out for different business entities.
Operations: 

Operation A
Operation B
Operation C

For Example I have an Entity A. Entity A's data could be in parts, for example:

Entity A's (Jan Data)
Entity B's (Feb Data) etc.

To complete a Use Case all Operations (A,B,C) should be performed. Now these operations are performed and are independent of each other and can be performed in parallel, the only condition is that they should be of different Entities. So Entity A can't have all the operations (A, B or C) executing in parallel. And these operations are running on server side.
How to scale this and provide a solution?
I am thinking of following solution and would like to have inputs from the community on this.
I am thinking of three Queues for operations which I mentioned above 

Queue A carrying out Operation A
Queue B carrying out Operation B
Queue C carrying out Operation C

And all the Consumers will be listening to these Queues.

Consumer A (or multiple consumers)
Consumer B (or multiple consumers)
Consumer C (or multiple consumers)

And my server would be load balanced, and I will be having a Single Message Queue containing these three queues.
So it is possible that I have 2 servers running and on every server there are for example 5 threads (Consumers) running, so there will be 10 instances of Consumer A running in parallel picking the data from the Message Queue A.
As I stated earlier that for the same entity A(that is the business use case which I have) all these operations (Operation A, Operation B and Operation C) can't be running in parallel, they should be only of them being executed.
So what I am thinking is to have a database entry for the Entity A and all the consumers must check whether there is a Database Entry for Entity A, 

if not then 

Make an entry to Database for Entity A
Go and execute the Operation
Remove the Entry from the Database for Entity A

if there is an entry in Database found

Enqueue the Data for Entity A again from the Queue where it was picked.


Is there any better solution possible for such a design problem?


TF-IDF Scores:
10: 0.0381
better: 0.0293
business: 0.1235
case: 0.0617
check: 0.0372
complete: 0.0390
consumer: 0.1917
data: 0.1448
database: 0.1821
design: 0.0617
different: 0.0926
earlier: 0.0440
entities: 0.0958
entity: 0.5031
entry: 0.2396
example: 0.0812
execute: 0.0412
executed: 0.0479
following: 0.0372
independent: 0.0479
inputs: 0.0479
instances: 0.0457
like: 0.0190
load: 0.0425
make: 0.0255
mentioned: 0.0479
message: 0.0915
multiple: 0.1093
operation: 0.4574
operations: 0.3201
parts: 0.0479
possible: 0.0665
problem: 0.0572
provide: 0.0364
queue: 0.2875
remove: 0.0400
running: 0.2287
scale: 0.0457
server: 0.1116
servers: 0.0479
set: 0.0344
single: 0.0390
solution: 0.1032
thinking: 0.1142
threads: 0.0479
use: 0.0415

Termine con il punteggio TF-IDF più alto: entity (0.5031)

Best Answer:
This sounds like a classic case for the routing slip pattern.
This approach is exactly as you described - separate queues for each consumer / message processor.  Only one consumer can work on a given message (Entity) at a time, but the consumers are free to work on any messages that are in their queue.
The main benefit of this approach is that you don't have to know the message route when you're crafting the code.  You can define run-time routing based upon the message type; load on the individual consumers; or whatever makes sense for your requirements.

The biggest advantages of this approach are:

Each consumer maintains its independence from the other consumers.  A long running consumer process can be individually supplemented by adding additional resources.  Or if your consumers support it, additional resource can be dynamically added or shifted based upon current workloads.
Avoiding the need for database entries and locking.  Generally speaking, DBs don't handle large scale event messaging like this very well.  You can make it work, but the solution tends to be brittle and prone to breaking when requirements change.



TF-IDF Scores:
added: 0.0925
adding: 0.1007
additional: 0.2015
advantages: 0.1007
approach: 0.2448
avoiding: 0.1085
based: 0.1662
benefit: 0.1043
breaking: 0.1085
case: 0.0732
change: 0.0789
code: 0.0450
consumer: 0.4546
current: 0.0883
database: 0.0864
define: 0.1043
dynamically: 0.1007
entity: 0.1085
event: 0.1085
exactly: 0.0976
free: 0.1007
generally: 0.0976
given: 0.0883
handle: 0.0903
know: 0.0599
large: 0.0883
like: 0.0900
load: 0.1007
long: 0.0831
main: 0.0864
make: 0.0604
makes: 0.0704
message: 0.4340
messages: 0.1085
need: 0.0616
pattern: 0.0883
process: 0.0883
prone: 0.1085
queue: 0.1137
requirements: 0.1728
resource: 0.1085
resources: 0.1043
run: 0.0864
running: 0.1085
scale: 0.1085
sense: 0.0864
separate: 0.1137
solution: 0.0816
sounds: 0.0949
support: 0.0903
time: 0.1209
type: 0.0789
work: 0.1946

Termine con il punteggio TF-IDF più alto: consumer (0.4546)

----------------------------------------------------------------------------------------------------

Question 267347:
When do you feel that you need a new class (maybe when you are developing or after development for refactoring purpose)? 
Maybe I can start from my existing variables and think how I can reorganize them into some classes! Please add more!


TF-IDF Scores:
add: 0.2205
class: 0.1784
classes: 0.2376
developing: 0.2542
development: 0.2041
existing: 0.2684
feel: 0.2769
maybe: 0.5085
need: 0.1694
new: 0.1728
purpose: 0.2542
refactoring: 0.2867
start: 0.2134
think: 0.1630
variables: 0.2684

Termine con il punteggio TF-IDF più alto: maybe (0.5085)

Best Answer:
Primary reason to use a class is that there is a concept in domain you are trying to express in your code and you want to codify this concept in some way. Usually, classes are created when you, as a developer, see, through your years of experience, that there is a concept in what you are trying to achieve and you want to explicitly convert this concept into code.
But also, many of the concept show up after you have written the code, quite often as various code smells. There are two examples :
Multiple values being passed around together. 
Be it Point or Customer, you can sometimes see that there are multiple (3+) variable all being passes around together. Code usually needs all, or most of those variables and even if it doesn't directly need them, it's dependencies might do. This is great opportunity to introduce a class to encapsulate all those variables. After that, you realize that many of the functions that work on those fields could actually be part of the class itself. And then, you might realize this is a concept within your domain, that you missed when doing analysis or design.
Big functions
It happened multiple times to me, that I found a function that was just too long. But when I tried to divide it into smaller functions, it resulted in all of the function's state being passed around in parameters. This is great opportunity to introduce a class to represent the whole function itself. The function's parameters might become a classe's constructor. The function's variables become fields. And then, you can easily separate the big function into smaller ones, because they all use shared state instead of relying on parameter passing. And then, you realize some of the ifs and switches might be represented as subclasses instead of code flow constructs, creating rich, maintainable and expressive representation instead of one huge hard-to follow and maintain function. This should make you think : if this piece of code was so complex, shouldn't it be some kind of concept in domain I'm working in?
Classes as "structures with functions"
You are saying you have experience with procedural programming. Then you must know about structures and their use cases. Structures and classes overlap in many of those use cases. Some people even say that classes are just structures with functions bolted onto them and that they are no different than procedural programming. While I disagree, it might be good way for you to start thinking about classes. So whenever you would create a structure, you instead create a non-static class. The rest then follows.
Transparent dependencies and control flow
Another problem with static classes is that of dependency. If method of a class is static, then it becomes hard to tell what code actually uses this method. It becomes even worse problem if static state (in form of static fields) is involved. It becomes extremely hard to follow the flow of a code when you don't know what other methods might be involved. If you use non-static classes, it becomes much cleaner, because you know what piece of memory method can modify, instead of working with global state. Actually, global state is the keyword here. It is generally known problems with global state range from pain in the ass to total nightmare. You should be striving to minimize amount of global state in your programs. Usage of non-static classes should be prioritized over static classes whenever possible.


TF-IDF Scores:
actually: 0.1051
analysis: 0.0457
big: 0.0879
cases: 0.0655
class: 0.1641
classes: 0.3278
cleaner: 0.0479
code: 0.1707
complex: 0.0440
concept: 0.2972
constructor: 0.0400
constructs: 0.0479
control: 0.0400
create: 0.0586
created: 0.0390
creating: 0.0344
customer: 0.0457
design: 0.0309
developer: 0.0364
different: 0.0309
directly: 0.0400
domain: 0.1372
easily: 0.0381
examples: 0.0390
experience: 0.0800
explicitly: 0.0457
extremely: 0.0457
fields: 0.1142
flow: 0.1372
follow: 0.0879
form: 0.0381
function: 0.2408
functions: 0.1949
generally: 0.0412
global: 0.1698
good: 0.0280
great: 0.0780
hard: 0.1200
instead: 0.1720
involved: 0.0958
kind: 0.0400
know: 0.0757
known: 0.0457
long: 0.0350
maintain: 0.0457
maintainable: 0.0440
make: 0.0255
method: 0.0890
methods: 0.0344
minimize: 0.0479
missed: 0.0479
modify: 0.0457
multiple: 0.1093
need: 0.0260
needs: 0.0357
non: 0.1170
ones: 0.0425
opportunity: 0.0915
parameters: 0.0879
passed: 0.0879
passes: 0.0425
passing: 0.0440
people: 0.0297
piece: 0.0915
point: 0.0344
possible: 0.0333
primary: 0.0440
problem: 0.0572
problems: 0.0350
procedural: 0.0958
programming: 0.0530
programs: 0.0479
quite: 0.0357
realize: 0.1274
reason: 0.0357
represent: 0.0400
rest: 0.0440
say: 0.0309
saying: 0.0457
separate: 0.0479
shared: 0.0479
smaller: 0.0915
start: 0.0327
state: 0.2801
static: 0.3044
structure: 0.0457
structures: 0.1917
subclasses: 0.0457
tell: 0.0440
think: 0.0250
thinking: 0.0381
times: 0.0364
total: 0.0479
tried: 0.0440
trying: 0.0761
use: 0.1037
uses: 0.0327
usually: 0.0701
values: 0.0412
variable: 0.0372
variables: 0.1235
various: 0.0457
want: 0.0500
way: 0.0482
work: 0.0274
working: 0.0645
worse: 0.0479
written: 0.0400
years: 0.0479

Termine con il punteggio TF-IDF più alto: classes (0.3278)

----------------------------------------------------------------------------------------------------

Question 267353:
There are two ways to execute AsynTask, i.e., execute and executeOnExecutor. I already know that execute works serially and executeOnExecutor works in parallel. So my question is:

Which one to use? 
Which one is better? 
Can someone help me understand which one to use in which situation?



TF-IDF Scores:
better: 0.1688
execute: 0.7111
help: 0.1947
know: 0.1453
question: 0.1667
situation: 0.2532
understand: 0.2018
use: 0.2389
ways: 0.2192
works: 0.4112

Termine con il punteggio TF-IDF più alto: execute (0.7111)

Best Answer:
On recent versions of android, "execute" will cause your task to be put into a queue from which a single background thread will pick it up and execute it; as you say, such tasks are executed serially (although you should not rely on this, as older versions of android started one thread for each task).
executeOnExecutor, however, gives you more control, because you can use any object that implements the Executor interface to execute the task. Even if you only limit yourself to the standard ThreadPoolExecutor implementation, this means you can take control of:

the maximum number of tasks that can be executed simultaneously
the type and parameters of queue used (e.g. whether the queue is bounded or unbounded)
the behavior when a new task is submitted while the queue is full

For most purposes, execute is adequate, but you would use executeOnExecutor when you need more control, either because a single thread isn't enough, or because you need to guarantee you only get one thread when using older versions of android, or because you have an unusual requirement on how submitted tasks are handled.


TF-IDF Scores:
android: 0.2632
background: 0.0905
behavior: 0.1021
cause: 0.0975
control: 0.2559
execute: 0.3509
executed: 0.2043
gives: 0.0905
guarantee: 0.1021
handled: 0.1021
implementation: 0.0761
interface: 0.0776
maximum: 0.1021
means: 0.0793
need: 0.1107
new: 0.0565
number: 0.0698
object: 0.0658
older: 0.2043
parameters: 0.0937
pick: 0.0975
queue: 0.4085
rely: 0.0975
requirement: 0.1021
say: 0.0658
single: 0.1662
standard: 0.0877
started: 0.1021
task: 0.3172
tasks: 0.2811
type: 0.0709
use: 0.0884
used: 0.0625
using: 0.0528
versions: 0.3064

Termine con il punteggio TF-IDF più alto: queue (0.4085)

----------------------------------------------------------------------------------------------------

Question 267359:
We are developing a framework that has several layers and would be deployed in a multi-threaded environment. Each layer may have its own input/output data type. The top layer takes the input, performs some actions on the data and passes it to the next layer. Based on the output from next layer, the top layer would perform another set of operations on the data. Similar interactions happen between other layers.

There are two use cases that we did not incorporate in the original design:

Generating metrics over what operations each layer performs on the data.
The change in data in one layer affects the operations in another layer, the changes should be recorded and each layer should have capability to fetch the list of changes.

After some thinking we came up with two approaches to accommodate these requirements in the existing design:

Use observer pattern and let each layer report its changes. These changes can be then pulled by the layer that needs to use it.
Pros: 

Since we have already come up with a design for the framework and most of work is complete. This approach would not require significant changes to the existing design, if any. 

Cons: 

It becomes difficult to manage(record and report back) changes corresponding to each layer. 
There is a central class that aggregates all the data for each request. This class acts like a global variable. It has to be initialized and deleted by the top layer. Adding another top layer could be error prone.

Extend the current data classes using an interface equivalent to EventContainer. This way all the layers would record their changes and spit them in their output.
Pros: 

This approach is much more cleaner and extendable than observer pattern. 

Cons: 

It would require significant design changes. 
The concept of data having events as well merges two separate concerns into one and does not seem like a good idea. 



We would like to know if there is a design pattern or any other solution that solves this problem?
Which of the above two solutions should be given higher preference considering that we would want a flexible, extendable and cleaner solution?


TF-IDF Scores:
adding: 0.0493
affects: 0.0556
approach: 0.0799
approaches: 0.0478
based: 0.0407
came: 0.0556
cases: 0.0380
change: 0.0386
changes: 0.3822
class: 0.0635
classes: 0.0423
cleaner: 0.1112
come: 0.0432
complete: 0.0453
concept: 0.0493
concerns: 0.0531
corresponding: 0.0556
current: 0.0432
data: 0.2688
design: 0.2150
developing: 0.0453
difficult: 0.0423
environment: 0.0510
equivalent: 0.0510
error: 0.0478
existing: 0.0955
extend: 0.0556
framework: 0.0864
generating: 0.0556
given: 0.0432
global: 0.0493
good: 0.0325
happen: 0.0531
higher: 0.0442
idea: 0.0432
input: 0.0929
interface: 0.0423
know: 0.0293
layer: 0.6900
let: 0.0442
like: 0.0661
list: 0.0374
manage: 0.0510
metrics: 0.0556
needs: 0.0414
operations: 0.1393
original: 0.0531
output: 0.1393
passes: 0.0493
pattern: 0.1296
perform: 0.0493
problem: 0.0332
prone: 0.0531
record: 0.1062
request: 0.0510
require: 0.0905
requirements: 0.0423
separate: 0.0556
set: 0.0399
significant: 0.1021
similar: 0.0423
solution: 0.0799
solutions: 0.0531
takes: 0.0392
thinking: 0.0442
type: 0.0386
use: 0.0722
using: 0.0288
variable: 0.0432
want: 0.0290
way: 0.0280
work: 0.0317

Termine con il punteggio TF-IDF più alto: layer (0.6900)

Best Answer:

We would like to know if there is a design pattern or any other
  solution that solves this problem?

To me this sound like the kind of problem that Enterprise Integration Patterns solve by using communication channels and message passing.
The patterns can be use to decouple the communication between applications, between layers or between components. 
There is a number of frameworks that can be used to implement this type of applications like Spring Integration, Apache Camel and Mule
What you describe sounds to me like a Service Activator. One of many different types of message endpoints (ME). The communication between your components will happen through message channels.
The components/service activators are totally unaware of each other and the channels define the pipeline that carries the messages between them.
Most frameworks, like Spring Integration, provide you with interceptors to get a chance to do something with the messages as they flow through the pipeline (equivalent to your observer pattern).
Interesting metrics can also be captured in the form of MXBeans as the message flow through the pipeline.

+----+    channel    +----+    channel    +----+
|    |---------------|    |---------------|    |
| ME |  <-message->  | ME |  <-message->  | ME |
|    |---------------|    |---------------|    |
*----+               +----+               +----+

In this type of frameworks the channel abstraction gives you a lot of power. The channel could be direct channels or publish subscribe channels, and the hand off of message can be synchronous or asynchronous. So you have total control of the message flow, the span of transactions, etc.


TF-IDF Scores:
abstraction: 0.0805
applications: 0.1426
asynchronous: 0.0805
chance: 0.0768
channel: 0.3219
communication: 0.2140
components: 0.2074
control: 0.0672
define: 0.0738
design: 0.0518
different: 0.0518
direct: 0.0768
equivalent: 0.0738
flow: 0.2305
form: 0.0639
frameworks: 0.2215
gives: 0.0713
hand: 0.0639
happen: 0.0768
implement: 0.0625
integration: 0.2215
interesting: 0.0655
kind: 0.0672
know: 0.0424
like: 0.1593
lot: 0.0559
message: 0.6146
messages: 0.1536
metrics: 0.0805
number: 0.0550
passing: 0.0738
pattern: 0.1250
patterns: 0.1477
problem: 0.0961
provide: 0.0612
service: 0.1426
solution: 0.0578
solve: 0.0672
sounds: 0.0672
total: 0.0805
type: 0.1117
types: 0.0672
use: 0.0348
used: 0.0492
using: 0.0416

Termine con il punteggio TF-IDF più alto: message (0.6146)

----------------------------------------------------------------------------------------------------

Question 267362:
I really cannot decide what option is the best, I see plenty of down/upsides to both approaches and right now I'm undecided.
For example;
class DX11GBuffer
{
public:
    DX11GBuffer(ID3D11DevicePtr device, ID3D11DeviceContextPtr context, D3D11_TEXTURE2D_DESC backbufferTextureDesc);
    ~DX11GBuffer();

    void BindForGeometryStage(ID3D11DepthStencilViewPtr dsv);
    // ...
}

"dsv" is not owned by the object and thus passed every frame, but it could just aswell be passed as a argument in the constructor and stored seeing as it is a smart pointer.
I guess what I am getting at is I understand there are pitfalls for keeping too much state in an object but also passing so much as function arguments means a whole lot of ASCII. Likewise defining "argument objects", collection of data for functions, seems to add alot of overhead aswell if it is to be applied everywhere as a rule of thumb.
I guess I am looking some general guidelines on when to pass as argument vs when to store as member.


TF-IDF Scores:
add: 0.1057
approaches: 0.1286
argument: 0.4288
arguments: 0.1327
best: 0.1189
class: 0.0855
collection: 0.1429
constructor: 0.1250
context: 0.1286
data: 0.0905
decide: 0.1116
defining: 0.1429
example: 0.0846
function: 0.1075
functions: 0.1218
general: 0.1218
getting: 0.1218
guess: 0.2859
keeping: 0.1429
likewise: 0.1497
looking: 0.1189
lot: 0.1039
means: 0.1163
member: 0.1250
object: 0.1929
objects: 0.1095
option: 0.1250
overhead: 0.1374
pass: 0.1250
passed: 0.2748
passing: 0.1374
pitfalls: 0.1497
pointer: 0.1429
public: 0.1286
really: 0.0952
right: 0.1116
rule: 0.1286
seeing: 0.1497
state: 0.1250
store: 0.1286
stored: 0.1286
understand: 0.1095
void: 0.1374
vs: 0.1429

Termine con il punteggio TF-IDF più alto: argument (0.4288)

Best Answer:
Member variables are variables are a "has a" relationship (the rectangle has a width). If the object does not have the variable then it should be passed into it to be used where required, if it's related to the object itself then it should be stored in the object.
A quick way to test the relation could be seeing how much that object uses the variable. If you use it in just one unit of code, leave it as it is (being passed in) however if multiple functions within that object make use of it then storing it as a member variable would probably make more sense.


TF-IDF Scores:
code: 0.0632
functions: 0.1299
leave: 0.1333
make: 0.1698
member: 0.2666
multiple: 0.1214
object: 0.5143
passed: 0.2930
probably: 0.1146
quick: 0.1596
related: 0.1371
relationship: 0.1415
required: 0.1415
seeing: 0.1596
sense: 0.1214
stored: 0.1371
storing: 0.1596
test: 0.1167
unit: 0.1214
use: 0.1382
used: 0.0976
uses: 0.1091
variable: 0.3719
variables: 0.2743
way: 0.0803
width: 0.1596

Termine con il punteggio TF-IDF più alto: object (0.5143)

----------------------------------------------------------------------------------------------------

Question 267366:
I'm practicing around building e-commerce asp.net applications that allows for users to register to the site and their user credentials are stored in a MySQL database. In my sample project the registration asks for the users username, password, full name, phone #, email, home address (for shipping of products purposes).
I know its good practice to store the user's password as a salted hash.  But is there any other info that should be stored the same way or not?  For example should the username also be stored as a salted hash or even encrypted?
I guess I'm just wondering what kinds of information is it ok to be stored in plain text in MySQL database for an asp.net web app? And which items are recommended to be stored in a salted hash? And which items should be stored using encryption?


TF-IDF Scores:
address: 0.1230
allows: 0.1090
app: 0.0977
applications: 0.1090
building: 0.1128
credentials: 0.1230
database: 0.1870
email: 0.1174
example: 0.0695
good: 0.0718
guess: 0.1174
hash: 0.3690
home: 0.1174
information: 0.0883
items: 0.2180
know: 0.0648
net: 0.1910
phone: 0.1230
practice: 0.1090
products: 0.1230
project: 0.0792
sample: 0.1230
site: 0.1230
store: 0.1056
stored: 0.6339
text: 0.1230
user: 0.1680
users: 0.2054
using: 0.0636
way: 0.0619
web: 0.0868
wondering: 0.1128

Termine con il punteggio TF-IDF più alto: stored (0.6339)

Best Answer:
Passwords must be stored hashed always, and make sure they are never logged, for example by query loggers. Hashing is important as opposed to encryption, because it should be a one-way, nonreversible process.
Secret questions to help recover passwords are good to encrypt. As these are secret, and they themselves can reveal something about the user, it wouldn't be good if they got leaked. In addition to revealing something personal about the user, they could also help attackers to make better guesses. 
Answers to secret questions should be hashed, as these could be intimate secrets. It can be a good idea to hash a sanitized form, such as lowercased and trimmed, to make it easier for users to reenter correctly.
As for other fields, it's case by case, and depends on many factors. You really need to think through each and every one of them, and evaluate in terms of sensitivity, and decide which method is prudent, or overengineering, or paranoia.
Don't forget to secure the communication channel too. For example if the system is accessible via web, make sure it's https, otherwise your hashing and encrypting makes little difference to your overall security, as everything can be eavesdropped en route between your users and your website.
UPDATE
As @MichaelT pointed out in a comment,
the Payment Card Industry Data Security Standard (PCI DSS) document seems to be a comprehensive document, and well worth reading if you're serious about securing your customer data. 
The documents library of PCI may have other interesting items too.


TF-IDF Scores:
addition: 0.1214
answers: 0.1167
better: 0.0778
card: 0.1272
case: 0.1639
channel: 0.1272
comment: 0.1167
communication: 0.1127
correctly: 0.1272
customer: 0.1214
data: 0.1537
decide: 0.0948
depends: 0.1167
difference: 0.1127
document: 0.2544
documents: 0.1272
easier: 0.1010
en: 0.1272
example: 0.1437
fields: 0.1010
forget: 0.1127
form: 0.1010
good: 0.2227
got: 0.1062
hash: 0.1272
help: 0.1796
https: 0.1093
idea: 0.0988
important: 0.0948
interesting: 0.1035
items: 0.1127
library: 0.1167
little: 0.1010
make: 0.2706
makes: 0.0788
method: 0.0788
need: 0.0690
overall: 0.1167
personal: 0.1062
process: 0.0988
query: 0.1272
questions: 0.1896
reading: 0.1062
really: 0.0809
security: 0.2429
standard: 0.1093
stored: 0.1093
sure: 0.1896
think: 0.0664
update: 0.1062
user: 0.1738
users: 0.2125
way: 0.0640
web: 0.0898
website: 0.1093
worth: 0.1127

Termine con il punteggio TF-IDF più alto: make (0.2706)

----------------------------------------------------------------------------------------------------

Question 267374:
I am curious why exception handling is a topic often ignored in Scala. Is it the goal of the language (or the style) to not rely on exception handling except for external input/code? 
I was hoping the style guide had some discussion on exception checking/handling. Is there a good reference that I could consult to understand if there are any differences in handling exceptions in Scala vs. languages I'm more used to (C++/C#/Java/Ruby/etc)?
Would someone with some Scala years under their belt be willing to write down guidelines for exception handling that are Scala specific? or is the answer simply "do as you would in Java"? What is "the functional way"?


TF-IDF Scores:
answer: 0.0725
checking: 0.1011
code: 0.0452
exception: 0.4565
exceptions: 0.1047
functional: 0.0929
goal: 0.1141
good: 0.0666
guide: 0.1089
handling: 0.5706
input: 0.0953
java: 0.1559
language: 0.0651
languages: 0.0820
reference: 0.1011
rely: 0.1089
ruby: 0.1011
scala: 0.4358
simply: 0.0851
specific: 0.0886
style: 0.2179
topic: 0.1089
understand: 0.0834
used: 0.0698
vs: 0.1089
way: 0.0574
willing: 0.1141
write: 0.0735
years: 0.1141

Termine con il punteggio TF-IDF più alto: handling (0.5706)

Best Answer:
Scala encourages the use of constructs like options and futures for error handling. First of all, lazy evaluation makes exceptions problematic, because there is a different stack when a function is executed than when it's queued to execute. Scala isn't lazy by default, but it can be lazy when you choose. 
Also, options and futures are much more powerful than exceptions. You can chain operations on them, and they aren't limited to propagating straight up the stack like exceptions are. You can store them in collections and reduce duplication in handler code. 
Pretty much the only time you use exceptions in Scala is for errors you can't handle that will kill your program anyway. 


TF-IDF Scores:
choose: 0.1360
code: 0.0564
constructs: 0.1424
default: 0.1424
different: 0.0918
error: 0.1224
errors: 0.1224
exceptions: 0.5228
execute: 0.1224
executed: 0.1424
function: 0.1023
handle: 0.1131
handling: 0.1424
lazy: 0.4273
like: 0.1128
limited: 0.1360
makes: 0.0882
operations: 0.1189
powerful: 0.1360
pretty: 0.1023
program: 0.0973
reduce: 0.1307
scala: 0.4079
stack: 0.2318
store: 0.1224
time: 0.0757
use: 0.1233

Termine con il punteggio TF-IDF più alto: exceptions (0.5228)

----------------------------------------------------------------------------------------------------

Question 267382:
I'm familiar with the notion in c++ of the rule of 3, however since the release of C++11 I've seen some sources suggesting it should be extended to a "rule of 5", I.e. the move constructor and move assignment operator should also be implemented whenever the others are. What is the rationale behind such a rule? My understanding is that in most cases implementation of move semantics is only necessary as an optimization - am I wrong about this, or is the so-called rule of five about optimizing my code (and, therefore, substantially less important than the rule of 3, which is about avoiding pitfalls that can lead to unexpected behaviors)?


TF-IDF Scores:
assignment: 0.1669
avoiding: 0.1593
called: 0.1325
cases: 0.1140
code: 0.0661
constructor: 0.1394
familiar: 0.1669
implementation: 0.1244
implemented: 0.1479
important: 0.1244
necessary: 0.1479
operator: 0.1593
optimization: 0.1434
optimizing: 0.1669
pitfalls: 0.1669
release: 0.1669
rule: 0.7168
seen: 0.1296
semantics: 0.1669
suggesting: 0.1593
understanding: 0.1669
unexpected: 0.1593
wrong: 0.1531

Termine con il punteggio TF-IDF più alto: rule (0.7168)

Best Answer:
Move semantics were added to C++11 in such a way that the "rule of 3" is still valid and sufficient to avoid the pitfalls that it is meant to avoid (althogh there are better ways in most situations by applying the "rule of 0").
There are also no additional pitfalls added to the language that the "rule of 5" would help you avoid. In that sense, the rule of 5 is more about optimization than about avoiding pitfalls.
On the other hand, treating the "rule of 5" as an extension to the "rule of 3" does help you to remember that in C++11 there are two additional special member functions that you need to think about when your class does something special that needs a destructor or copy-constructor.
And although move semantics are an optimization, providing a move-constructor and/or move-assignment operator doesn't mean you are prematurely optimising, just like selecting the right algorithm isn't a premature optimization.
Adding support for move semantics to your class, when it makes sense, usually takes little effort and doesn't detract from the readability/maintainability of the code.


TF-IDF Scores:
added: 0.1655
adding: 0.0902
additional: 0.1803
algorithm: 0.0850
assignment: 0.1017
avoid: 0.2622
avoiding: 0.0971
better: 0.0622
class: 0.1161
code: 0.0403
constructor: 0.1699
copy: 0.0874
destructor: 0.1017
effort: 0.0971
functions: 0.0828
hand: 0.0808
help: 0.1436
language: 0.0581
like: 0.0403
little: 0.0808
makes: 0.0630
mean: 0.0933
meant: 0.1017
member: 0.0850
need: 0.0552
needs: 0.0758
operator: 0.0971
optimization: 0.2622
pitfalls: 0.3052
readability: 0.0971
remember: 0.0933
right: 0.0758
rule: 0.5243
semantics: 0.3052
sense: 0.1547
situations: 0.1017
special: 0.1803
sufficient: 0.1017
support: 0.0808
takes: 0.0718
think: 0.0531
usually: 0.0744
valid: 0.0828
way: 0.0512
ways: 0.0808

Termine con il punteggio TF-IDF più alto: rule (0.5243)

----------------------------------------------------------------------------------------------------

Question 267387:
I am still pretty new to programming, but my first app was recently approved and is now for sale on the App Store. My app uses Core Data and is written in Swift. After some initial difficulties, I decide to write the app without unit tests. Now I'd like to implement unit tests to prevent regression.
My managed objects are created inside class methods in my NSManagedObject subclasses and use a global variable "context" which I declare in AppDelegate to store the NSManagedObjectContext created in Apple's default code. I know that global variables are generally discouraged but this approach makes the most sense to me, is easy to write, and hasn't let to any bugs or other issues inside the app itself. Unfortunately, this makes it difficult to unit test. I've tried several different approaches to creating a Core Data stack inside my test target, but I can't seem to get anything to work without rewriting lots of my app code. I really don't want to do that just to make it testable. I've considered using frameworks such as Quick/Nimble or Magical Record but I don't see how that would help my problem.
I did figure out a workaround, but I'm curious if people think this is a bad idea: I created a class in my primary target (non testing) called TestingClass. In my first ViewController's viewDidAppear, I call the startTests method. TestingClass is written in strait Swift with no testing frameworks. I have several if statements which are supposed to be false. If they are true they add a string to an array. When the tests are complete, if the array count is > 0, it prints out the contents and aborts.
I am planning on using this until my update is ready to ship. When it is, I will disable the TestingClass and remove my call to it. I'm curious if anyone has ever done anything like this. Should I just figure out a way to do tests the "right" way?


TF-IDF Scores:
add: 0.0644
app: 0.4346
approach: 0.0655
approaches: 0.0783
array: 0.1523
bad: 0.0762
bugs: 0.0808
called: 0.0724
class: 0.1041
code: 0.0722
complete: 0.0742
considered: 0.0871
context: 0.0783
created: 0.2226
creating: 0.0655
data: 0.1102
decide: 0.0680
declare: 0.0912
default: 0.0912
different: 0.0588
difficult: 0.0693
easy: 0.0708
frameworks: 0.1673
generally: 0.0783
global: 0.1616
help: 0.0644
idea: 0.0708
implement: 0.0708
initial: 0.0871
inside: 0.2350
issues: 0.0837
know: 0.0480
let: 0.0724
like: 0.0722
lots: 0.0871
make: 0.0485
makes: 0.1130
method: 0.0565
methods: 0.0655
new: 0.0504
non: 0.0742
objects: 0.0667
people: 0.0565
planning: 0.0871
pretty: 0.0655
primary: 0.0837
problem: 0.0545
programming: 0.0504
quick: 0.0912
really: 0.0580
recently: 0.0808
record: 0.0871
remove: 0.0762
right: 0.0680
sense: 0.0693
stack: 0.0742
statements: 0.0871
store: 0.1567
string: 0.0762
subclasses: 0.0871
supposed: 0.0808
target: 0.1741
test: 0.1334
testing: 0.1523
tests: 0.2718
think: 0.0476
tried: 0.0837
true: 0.0808
unfortunately: 0.0912
unit: 0.2080
update: 0.0762
use: 0.0395
uses: 0.0623
using: 0.0943
variable: 0.0708
variables: 0.0783
want: 0.0476
way: 0.0918
work: 0.0521
write: 0.1175
written: 0.1523

Termine con il punteggio TF-IDF più alto: app (0.4346)

Best Answer:
Let's look at the broader question first.  In some ways, your question boils down to the balance of pragmatism versus the theoretical "best way" for coding.  I'm in the pragmatic programming camp, especially with your particular situation.  Pragmatic coding means we work around the limitations that the current software stack imposes. 
In your particular case, with your particular understanding of the stack, you're running into a challenge.  You've identified a work-around and you've made things work for the time being.  Part of those challenges are possibly introduced by your use of global variables, but as you stated, it made sense for the information that needed to be stored.
I think using a TestingClass is a perfectly valid approach since you're fulfilling the purpose of testing (making sure things operate as expected) and you're also working within the constraints, as you understand them, of the application you created.  You certainly wouldn't be the first to put a test harness in place during development and then remove it prior to releasing the app.
You do run some risks with that approach.  Specifically, if you forget to disable that class before releasing to production, that could create problems for you.  Likewise, you effectively have to duplicate all of your code between the main path and the testing path.  So you run a risk of a bug escaping if the testing path doesn't exactly reflect how the main path operates.  Finally, it does build up complex test cases which can be more difficult to debug because you have to unwind things to understand where it broke.

So, as far as the particular approach that you've taken - it's valid enough.  
It may not be "pure" in the sense of following traditional, automated unit testing, but I think that pragmatism needs to rule the day.  People don't buy your application because of the unit tests, they buy your app because it works.  Your approach to unit testing provides regression testing and allows you to keep focused on developing new features.


TF-IDF Scores:
allows: 0.0776
app: 0.1391
application: 0.1463
approach: 0.2515
automated: 0.0876
best: 0.0696
bug: 0.0804
build: 0.0696
case: 0.0564
cases: 0.0598
challenge: 0.0876
challenges: 0.0876
class: 0.0500
code: 0.0347
coding: 0.1463
complex: 0.0804
create: 0.0536
created: 0.0713
current: 0.0680
day: 0.0776
debug: 0.0876
developing: 0.0713
development: 0.0572
difficult: 0.0666
especially: 0.0804
exactly: 0.0752
expected: 0.0804
far: 0.0804
features: 0.0752
finally: 0.0876
focused: 0.0876
following: 0.0680
forget: 0.0776
global: 0.0776
information: 0.0629
let: 0.0696
likewise: 0.0876
look: 0.0640
main: 0.1332
making: 0.0696
means: 0.0680
needed: 0.0713
needs: 0.0653
new: 0.0484
particular: 0.2663
people: 0.0542
place: 0.0713
possibly: 0.0731
pragmatic: 0.1752
prior: 0.0876
problems: 0.0640
production: 0.0876
programming: 0.0484
provides: 0.0752
pure: 0.0836
purpose: 0.0713
question: 0.1058
remove: 0.0731
rule: 0.0752
run: 0.1332
running: 0.0836
sense: 0.1332
situation: 0.0804
software: 0.0618
specifically: 0.0836
stack: 0.1425
stored: 0.0752
sure: 0.0653
taken: 0.0804
test: 0.1281
testing: 0.4388
tests: 0.0653
things: 0.1551
think: 0.0914
time: 0.0466
understand: 0.1281
understanding: 0.0876
unit: 0.1997
use: 0.0379
using: 0.0453
valid: 0.1425
variables: 0.0752
way: 0.0441
ways: 0.0696
work: 0.1500
working: 0.0589
works: 0.0653

Termine con il punteggio TF-IDF più alto: testing (0.4388)

----------------------------------------------------------------------------------------------------

Question 267399:
I am having some problems trying to figure out when to use a factory or to wrapper class. This question is slightly geared towards C# I guess, so I'm not sure if this is the correct place to ask.
Say there is a library that exposes an interface called IStackExchangeClient, and multiple differing implementations of that interface (private implementations that clients will not know about), HttpStackExchangeClient, UdpStackExchangeClient.
We can allow the object creation of the interface through a factory, like StackExchangeClientFactory.Create(), or we can wrap it up in another class like StackExchangeClient that internally does the same thing, but simply proxies.
In the second instance, clients can write new StackExchangeClient() which feels much more natural to me. So my question is, when do I choose one or the other? What are some of the considerations that I should be taking in?
I've thought hard about it and I can't choose between one style or the other, but clearly some parts of the .NET framework use factories, and some parts don't, even when there are multiple underlying implementations of its interface.
Thank you!


TF-IDF Scores:
allow: 0.1198
ask: 0.1129
called: 0.1073
choose: 0.2580
class: 0.1543
clearly: 0.1290
correct: 0.1129
create: 0.0827
factory: 0.2703
framework: 0.1050
guess: 0.1290
hard: 0.1129
implementations: 0.3720
instance: 0.1161
interface: 0.4110
know: 0.0712
library: 0.1240
like: 0.1070
multiple: 0.2055
natural: 0.1352
net: 0.1050
new: 0.0748
object: 0.0871
parts: 0.2703
place: 0.1100
private: 0.1198
problems: 0.0988
question: 0.1633
say: 0.0871
second: 0.1028
simply: 0.1007
slightly: 0.1290
style: 0.1290
sure: 0.1007
thing: 0.1007
thought: 0.1290
trying: 0.1073
use: 0.1170
wrapper: 0.1290
write: 0.0871

Termine con il punteggio TF-IDF più alto: interface (0.4110)

Best Answer:
Use a wrapping class when the interface is private, i.e. the user can't create their own new derived classes. This is usually a pretty questionable design.
Otherwise, make the interface and derived classes public.
Don't use a factory method unless it has some language-required advantage, e.g. generic type deduction, which you can see in Tuple.Create.


TF-IDF Scores:
advantage: 0.2359
class: 0.1347
classes: 0.3587
create: 0.2886
design: 0.1520
factory: 0.2359
generic: 0.2252
interface: 0.3587
language: 0.1347
make: 0.1254
method: 0.1461
new: 0.1305
pretty: 0.1694
private: 0.2091
public: 0.2026
required: 0.2091
type: 0.1637
unless: 0.2164
use: 0.2043
user: 0.1611
usually: 0.1725
wrapping: 0.2359

Termine con il punteggio TF-IDF più alto: classes (0.3587)

----------------------------------------------------------------------------------------------------

Question 267406:
Given are two sorted arrays a, b of type T with size n and m. I am looking for an algorithm that merges the two arrays into a new array (of maximum size n+m). 
If you have a cheap comparison operation, this is pretty simple. Just take from the array with the lowest first element until one or both arrays are completely traversed, then add the remaining elements. Something like this https://stackoverflow.com/questions/5958169/how-to-merge-two-sorted-arrays-into-a-sorted-array
However, the situation changes when comparing two elements is much more expensive than copying an element from the source array to the target array. For example you might have an array of large arbitrary precision integers, or strings, where a comparison can be quite expensive. Just assume that creating arrays and copying elements is free, and the only thing that costs is comparing elements.
In this case, you want to merge the two arrays with a minimum number of element comparisons. Here are some examples where you should be able to do much better than the simple merge algorithm:
a = [1,2,3,4, ... 1000]
b = [1001,1002,1003,1004, ... 2000]

Or
a = [1,2,3,4, ... 1000]
b = [0,100,200, ... 1000]

There are some cases where the simple merge algorithm will be optimal, like
a = [1,3,5,7,9,....,999]
b = [2,4,6,8,10,....,1000]

So the algorithm should ideally gracefully degrade and perform a maximum of n+m-1 comparisons in case the arrays are interleaved, or at least not be significantly worse.
One thing that should do pretty well for lists with a large size difference would be to use binary search to insert the elements of the smaller array into the larger array. But that won't degrade gracefully in case both lists are of the same size and interleaved.
The only thing available for the elements is a (total) ordering function, so any scheme that makes comparisons cheaper is not possible.
Any ideas?
I have come up with this bit in Scala. I believe it is optimal regarding the number of comparisons, but it is beyond my ability to prove it. At least it is much simpler than the things I have found in the literature.
And since the original posting, I wrote a blog post about how this works.


TF-IDF Scores:
10: 0.0601
100: 0.0694
ability: 0.0694
able: 0.0575
add: 0.0534
algorithm: 0.2527
array: 0.5053
assume: 0.0756
available: 0.0670
believe: 0.0694
better: 0.0463
bit: 0.0575
blog: 0.0670
case: 0.1462
cases: 0.0517
changes: 0.0650
com: 0.0615
come: 0.0587
comparison: 0.1513
completely: 0.0722
costs: 0.0756
creating: 0.0543
difference: 0.0670
element: 0.2082
elements: 0.4022
example: 0.0427
examples: 0.0615
free: 0.0670
function: 0.0543
given: 0.0587
https: 0.0650
large: 0.1175
larger: 0.0694
like: 0.0599
lists: 0.1444
looking: 0.0601
makes: 0.0468
maximum: 0.1513
minimum: 0.0756
new: 0.0418
number: 0.1033
operation: 0.0722
original: 0.0722
perform: 0.0670
possible: 0.0525
post: 0.0722
pretty: 0.1086
prove: 0.0722
questions: 0.0564
quite: 0.0564
regarding: 0.0756
scala: 0.0722
search: 0.0694
simple: 0.1846
situation: 0.0694
size: 0.2527
smaller: 0.0722
source: 0.0587
stackoverflow: 0.0650
strings: 0.0756
target: 0.0722
thing: 0.1691
things: 0.0446
total: 0.0756
type: 0.0525
use: 0.0327
want: 0.0395
works: 0.0564
worse: 0.0756
wrote: 0.0694

Termine con il punteggio TF-IDF più alto: array (0.5053)

Best Answer:
The normal merge sort algorithm - merge step with normally apply n + m -1 comparisons, where one list is of size n and and the other list is of size m. Using this algorithm is the most simplest approach to combine two sorted lists.
If the comparisons are too expensive you could do two things - either you minimize the number of comparisons or you minimize the cost of comparisons.
Let's focus on the minimization of the cost of comparison. You and only you can decide whether the data you are comparing can be quantized or not. If you can quantize them, which is a form of implementing a hash method, which is keeping the ordering. E.g. if your Data is compared by Name, Then the first tname, ... you can take the first to Chars of the name "Klaehn, Ruediger" and reduce/quantize your data element to "Kl.Ru", if you compare it to "Packer, The" you preserve the ordering "Pa.Th" - you can now apply a cheaper comparison algorithm, comparing the reduced values. But if you find another "Kl.Ru", you now have a near value, and you might now switch to a more expensive approach comparing these elements.
If you can extract this quantized value from your data, faster than comparing it, this is the first thing you do, you compare the quantized or hashed value first. Please keep in mind, that this value needs to be computed only once, so you can compute it on creating the data element.
I also mentioned another way, to minimize your comparisons.
I had a look into the classic book TAOCP- Volume 3-Sorting and Searching, (pp.197-207, section 5.3.2) which has full 10 pages on this topic. I found two references to algorithms which are faster than n+m-1 comparisons.
First there is the Hwang-Lin merge algorithm and the second an improvement by Glenn K Manacher - both are cited by TAOCP as well as an algorithm by Christen, which approaches the lower bound of needed comparisons, on special conditions on the length n and m of the lists.
The algorithm of Manacher was presented in Journal of the ACM Vol. 26 Number 3 on pages 434-440: "Significant Improvements to the "Hwan-Lin" Merging Algorithm". the list with m items and the list with n items can be of different length, but they must also be odered by the numbers of elements they contain m<=n
The Hwang-Lin algorithm breaks the lists to merge, apart to smaller lists and sorts the lists by comparing the first element of each sublist, and to decide whether some elements in the sublist need to be compared or not. If the first list is smaller than the second list, then the chance is high, that consecutive elements of the longer list can be transferred into the resulting list without comparison. If the first element of the small ist is greater than the first element of the splitted larger list, all elements in front of sublist can be copied without comparison. 
Average case analysis of the merging alorithm of Hwang and Lin (Vega, Frieze, Santha) in Section 2 you can find a pseudocode of the HL-Algorithm. Which is a lot better than my description. And you can see why there are fewer comparisons - the algorithm uses a binary search, to find the index, where to insert the element from the shorter list.
If the lists are not interleaved like in your last example, you should have a remaining smaller and a remaining larger list in most cases. This is when the the HL-algorithm starts to perform better.


TF-IDF Scores:
10: 0.0424
algorithm: 0.4904
algorithms: 0.0534
analysis: 0.0510
apart: 0.0510
apply: 0.0980
approach: 0.0767
approaches: 0.0459
average: 0.0534
better: 0.0653
book: 0.0473
breaks: 0.0534
case: 0.0344
cases: 0.0365
chance: 0.0510
combine: 0.0534
comparison: 0.2135
contain: 0.0534
cost: 0.0980
creating: 0.0383
data: 0.1613
decide: 0.0796
different: 0.0344
element: 0.2939
elements: 0.2365
example: 0.0302
extract: 0.0534
faster: 0.1068
fewer: 0.0510
focus: 0.0510
form: 0.0424
hash: 0.0534
high: 0.0490
implementing: 0.0490
improvements: 0.0510
items: 0.0946
keeping: 0.0510
larger: 0.0980
let: 0.0424
like: 0.0211
list: 0.3950
lists: 0.3058
longer: 0.0490
look: 0.0390
lot: 0.0371
mentioned: 0.0534
method: 0.0331
mind: 0.0510
minimize: 0.1602
near: 0.0534
need: 0.0289
needed: 0.0434
needs: 0.0398
normal: 0.0490
normally: 0.0534
number: 0.0729
numbers: 0.0510
perform: 0.0473
reduce: 0.0490
references: 0.0510
resulting: 0.0534
search: 0.0490
second: 0.0812
section: 0.1068
significant: 0.0490
size: 0.0892
small: 0.0434
smaller: 0.1529
special: 0.0473
starts: 0.0490
step: 0.0490
thing: 0.0398
things: 0.0315
topic: 0.0510
uses: 0.0365
using: 0.0276
value: 0.1737
values: 0.0459
way: 0.0269

Termine con il punteggio TF-IDF più alto: algorithm (0.4904)

----------------------------------------------------------------------------------------------------

Question 267420:
In my school management system I have this partial  class diagram:

1- In one use case student want to see his schedule of classes in week. this is what i suppose to do:
get student object from session and call method getSchedule() on that and it will give me schedule(this method calls StudentCourse, Course for getting schedule).
Is this good place to put getSchedule() method or I should place it elsewhere?
..................................................
2- In another use class student's parent want to see his child class schedule, I plan to do something like this:
Because I have some use cases that parent want to see some other student information(course mark...), I create interface StudentParentInterface that have method getSchedule() and other methods and student implement StudentParentInterface, then parent has reference to StudentParentInterface not student obj directly.
parent call getSchedule() method on StudentParentInterface, is this correct?


TF-IDF Scores:
calls: 0.0937
case: 0.0703
cases: 0.0745
class: 0.1867
classes: 0.0829
correct: 0.0911
course: 0.1873
create: 0.0667
directly: 0.0911
getting: 0.0887
good: 0.0636
implement: 0.0847
information: 0.0783
interface: 0.0829
like: 0.0432
management: 0.0937
method: 0.3377
methods: 0.0783
object: 0.0703
parent: 0.4362
partial: 0.1090
place: 0.1775
reference: 0.0966
school: 0.1090
student: 0.6246
suppose: 0.1001
use: 0.1416
want: 0.1707
week: 0.1041

Termine con il punteggio TF-IDF più alto: student (0.6246)

Best Answer:
As said in the comments on the OP, I don't think an interfacing class class makes sense in this instance since there is a direct relationship between Students and Parents.
Think about the relationships of the concepts outside of the system. Does every student have a schedule?
By my limited knowledge I'd say it sounds like it. It also sounds like you'll want parents to possibly have something student.getGrades(). So your you'll probably have multiple parents to one student. The student wouldn't need to be aware of the parent but the parent needs to be aware of the student so each Parent object will have a Student property and would probably call getSchedule() and getGrades() etc.


TF-IDF Scores:
aware: 0.2448
class: 0.1398
comments: 0.0996
concepts: 0.1169
direct: 0.1169
instance: 0.1052
knowledge: 0.1085
like: 0.0969
limited: 0.1169
makes: 0.0758
multiple: 0.0931
need: 0.0664
needs: 0.0912
object: 0.0789
outside: 0.1052
parent: 0.3673
possibly: 0.1022
probably: 0.1758
property: 0.1085
relationship: 0.1085
said: 0.0972
say: 0.0789
sense: 0.0931
sounds: 0.2045
student: 0.7012
students: 0.1224
think: 0.1278
want: 0.0639

Termine con il punteggio TF-IDF più alto: student (0.7012)

----------------------------------------------------------------------------------------------------

Question 267442:
Recently ive been consumed by creating my own simple CPU architecture that at some point could be easily implemented in hardware (No FPGA, but actual Logic Gate circuits). Naturally to fulfill this requirement i went with a simple 4 Bit CPU, with a 4kB program space and 256 Byte RAM. 
It supports all the fundamental operations such as ADD, Subtract, AND, LOAD, STORE etc. Before i start committing this to hardware i want to develop a moderately powerful software stack that could compile the a C/ C like language for the architecture, so the cpu could be programmed using a high level language. Currently i have written a working assembler in VB.NET, but now im stuck on how to approach the final goal of a working compiler. 
Specifically i have the following questions: 
What should be my next step, and how should i approach writing a compiler?
Even though a 4 Bit CPU is simple, it is not very useful as it cannot handle large calculations at once, thus my final goal would be abstract this inability by developing a software stack that to the user would be like programming a 16 bit (or larger) CPU. Currently i manually write assembly that can span larger numbers over multiple registers and perform calculations between them, but ultimately what part of the software stack deals with handling numbers and calculations which are greater than the size of the physical registers?
What part of the software stack deals with Subroutine calling etc?
Please let me know if i need to clarify anything. 


TF-IDF Scores:
actual: 0.0927
add: 0.0738
approach: 0.1502
architecture: 0.2091
bit: 0.2385
calling: 0.0959
compile: 0.0959
compiler: 0.1853
creating: 0.0751
currently: 0.1996
develop: 0.0998
developing: 0.0851
easily: 0.0831
final: 0.1996
following: 0.0812
goal: 0.2091
handle: 0.0831
handling: 0.1046
high: 0.0959
implemented: 0.0927
know: 0.0551
language: 0.1194
large: 0.0812
larger: 0.1919
let: 0.0831
level: 0.0873
like: 0.0828
load: 0.0927
logic: 0.0851
multiple: 0.0795
need: 0.0567
net: 0.0812
numbers: 0.1996
operations: 0.0873
perform: 0.0927
point: 0.0751
powerful: 0.0998
program: 0.0714
programming: 0.0578
questions: 0.0779
recently: 0.0927
requirement: 0.1046
simple: 0.2552
size: 0.0873
software: 0.2952
space: 0.0898
specifically: 0.0998
stack: 0.3403
start: 0.0714
step: 0.0959
store: 0.0898
ultimately: 0.0998
useful: 0.0831
user: 0.0714
using: 0.0541
want: 0.0546
went: 0.1046
working: 0.1407
write: 0.0674
writing: 0.0898
written: 0.0873

Termine con il punteggio TF-IDF più alto: stack (0.3403)

Best Answer:
LLVM backend is the primary sane way of doing this. If you lower LLVM IR to assembly or microcode, you can roll from there and just use the numerous LLVM frontends to convert higher languages like C++ into LLVM IR.
In other words, LLVM was explicitly designed to support this scenario.
The full stack goes like this:

Frontend (e.g. Clang for C and C++) - source code -> LLVM IR
Optimizer (LLVM) - LLVM IR -> LLVM IR 
Backend (you) - LLVM IR -> assembly/microcode/whatever

The first part is provided for you on a per-language basis. So for C and C++, you can use Clang, for D you can use LDC, etc. The second part is provided by LLVM- they provide a large number of target-independent optimization routines and some target-aware ones. Finally, you provide a translation service from LLVM IR to your architecture-specific code.
Note that LLVM IR makes a few guarantees, because they are targetted at real platforms. For example, they assume IEEE754 floating-point support and 8-bit bytes as well as various types of pointer support. You will need to support all of these anyway if you want to compile languages like C to target your architecture in general. If you are willing to restrict the source language a bit beyond normal you can get away without implementing all of these features- for example, if the C code doesn't use floats, in principle there's no reason why the frontend should emit float-using LLVM IR code.
LLVM IR is a common middle-ground that you can compile any language to target, and then from there, can be lowered for any CPU. Basically, all you need to do is support the primitives, and then provide an LLVM backend to convert from LLVM IR to your assembly. LLVM and language frontends will do all the rest.


TF-IDF Scores:
architecture: 0.2015
assume: 0.1008
aware: 0.1008
away: 0.0893
basically: 0.0924
basis: 0.0962
bit: 0.1532
code: 0.1596
common: 0.0800
compile: 0.1849
designed: 0.0962
example: 0.1138
explicitly: 0.0962
features: 0.0866
finally: 0.1008
general: 0.0820
goes: 0.0893
higher: 0.0800
implementing: 0.0924
independent: 0.1008
language: 0.2301
languages: 0.1447
large: 0.0782
like: 0.1197
makes: 0.0624
need: 0.1092
normal: 0.0924
note: 0.0841
number: 0.0688
ones: 0.0893
optimization: 0.0866
point: 0.0723
pointer: 0.0962
primary: 0.0924
principle: 0.0962
provide: 0.2298
provided: 0.1786
real: 0.0782
reason: 0.0751
rest: 0.0924
routines: 0.1008
scenario: 0.0962
second: 0.0766
service: 0.0893
source: 0.1565
specific: 0.0782
stack: 0.0820
support: 0.4001
target: 0.3847
types: 0.0841
use: 0.1745
using: 0.0521
various: 0.0962
want: 0.0526
way: 0.0507
willing: 0.1008
words: 0.0893

Termine con il punteggio TF-IDF più alto: support (0.4001)

----------------------------------------------------------------------------------------------------

Question 267445:
I'm currently revisiting some code I wrote in sass when I was learning it and I came upon a particular issue. I was able to write the code in 2 ways, with the first being the more readable code and the second being the shortest code when compiled to css. I was wondering whether it's a good thing to sacrifice some readability for smaller compiled file sizes.
In the current example, option 1 takes up about 60% less characters compiled in css. At 12 colums, the first option uses ~750 less characters than the second option. This is actually pretty significant.
The example is pretty straightforward, but when extending the code readability of the sass file can become more complicated. Is it worth sacrificing this for the smaller compiled file?
Option 1
// Create all columns
@for $i from 1 through $column_amount {
  .col-#{$i}-lg, .col-#{$i}-md, .col-#{$i}-sm {
    width: $i * $col-size;
  }
}

// At medium screen and below set all large columns to 100%
@media all and (max-width: $screen-medium-max) {
  @for $i from 1 through $column_amount {
    .col-#{$i}-lg {
      width: 100%;
    }
  }
}

// At small screen and below set all medium columns to 100%
@media all and (max-width: $screen-small-max) {
  @for $i from 1 through $column_amount {
    .col-#{$i}-md {
      width: 100%;
    }
  }
}

Option 2
// Creating the columns
@for $i from 1 through $column_amount {
  .col-#{$i}-lg, .col-#{$i}-md, .col-#{$i}-sm {
    width: $i * $col-size;
  }

  // At medium screen and below set all large columns to 100%
  @media all and (max-width: $screen-medium-max) {
    .col-#{$i}-lg {
      width: 100%;
    }
  }

  // At small screen and below set all medium columns to 100%
  @media all and (max-width: $screen-small-max) {
    .col-#{$i}-md {
      width: 100%;
    }
  }
}

If any extension exists that does this for me, it'd be nice to know about it, but it won't answer the question


TF-IDF Scores:
100: 0.4229
able: 0.0438
actually: 0.0421
answer: 0.0366
came: 0.0576
characters: 0.0990
code: 0.1140
complicated: 0.0529
create: 0.0352
creating: 0.0414
current: 0.0447
currently: 0.0550
example: 0.0651
exists: 0.0550
file: 0.1288
good: 0.0336
issue: 0.0481
know: 0.0303
large: 0.0895
learning: 0.0481
nice: 0.0495
option: 0.2405
particular: 0.0438
pretty: 0.0827
question: 0.0348
readability: 0.1100
readable: 0.0550
screen: 0.4609
second: 0.0876
set: 0.1655
significant: 0.0529
size: 0.0962
small: 0.1875
smaller: 0.1100
takes: 0.0407
thing: 0.0429
uses: 0.0394
ways: 0.0458
width: 0.5761
wondering: 0.0529
worth: 0.0511
write: 0.0371
wrote: 0.0529

Termine con il punteggio TF-IDF più alto: width (0.5761)

Best Answer:
The level of optimization that you describe can be a useful consideration in the final stages of the project:
your project is finished, meets the requirements,
everything is working well,
and you would like to squeeze a few extra bits of performance out of it without changing any other aspect.
If you are at this stage,
and the performance gain is believed to improve the success of the project,
then by all means do it.
If you are not at this stage yet,
then spend your time and effort on something else that's higher priority.
Until your project is mostly done,
it may still go through changes, sometimes even big changes.
This piece of code that you would optimize might get refactored and possibly even eliminated from the final product.


TF-IDF Scores:
big: 0.1517
changes: 0.2840
changing: 0.1517
code: 0.0654
effort: 0.1578
extra: 0.1465
final: 0.3156
finished: 0.1653
gain: 0.1578
higher: 0.1313
level: 0.1380
like: 0.0654
means: 0.1284
optimization: 0.1420
optimize: 0.1517
performance: 0.2840
piece: 0.1578
possibly: 0.1380
product: 0.1420
project: 0.4260
refactored: 0.1653
requirements: 0.1257
spend: 0.1653
squeeze: 0.1653
stage: 0.3306
time: 0.0879
useful: 0.1313
working: 0.1112

Termine con il punteggio TF-IDF più alto: project (0.4260)

----------------------------------------------------------------------------------------------------

Question 267456:
I have to implement the AI for Abalone game and I'm wondering what is the best way to represent the board logic using Java without wasting too much resources in all checks and updates routines involved.
Is better use various lists? A matrix of Cell objects? 
Any suggestion?



TF-IDF Scores:
best: 0.2140
better: 0.1648
board: 0.2472
cell: 0.2694
game: 0.2472
implement: 0.2092
involved: 0.2694
java: 0.1840
lists: 0.2572
logic: 0.2192
objects: 0.1970
represent: 0.2250
resources: 0.2472
routines: 0.2694
suggestion: 0.2572
use: 0.1166
using: 0.1393
various: 0.2572
way: 0.1356
wondering: 0.2472

Termine con il punteggio TF-IDF più alto: cell (0.2694)

Best Answer:
1) since the board has a fixed-size that you're just going to be feeding into an AI anyway, you could just represent it as a one-dimensional array with the right number of cells, where each cell represents a space on the board. Mapping that one-dimensional array to the screen for presentation might be a little weird, but it's a problem you only have to solve once.
The same would apply to validating moves; you could either create an adjacency matrix that tells which cells are adjacent to others, or come up with logic to determine adjacency. Either way, it would be a one-time cost.
2) Notice that every hex grid is also a two-axis grid, except that the axes are 60 or 120 degress from each other, instead of 90 degrees like grids where X and Y are perpendicular. (Old hex-tile boardgames used this trick to label the hexes 1, 2, 3 in one direction, and AA, BB, CC in the other, skewed, direction.)
I've looked at source code for computer implementations of board games that use (2), and they provided routines like "find a line between hexes" or "find the distance between hexes." That was a long time ago, so the details are lost to time, but I remember it wasn't too hard.
(It was more integer math rather than the Pythagorean stuff. ;))


TF-IDF Scores:
apply: 0.1421
array: 0.2587
board: 0.4264
cell: 0.1549
code: 0.0613
come: 0.1203
computer: 0.1373
cost: 0.1421
create: 0.0948
details: 0.1260
determine: 0.1549
going: 0.1178
grid: 0.3098
hard: 0.1294
implementations: 0.1421
instead: 0.1112
like: 0.1227
line: 0.1260
little: 0.1230
logic: 0.1260
long: 0.1133
lost: 0.1479
number: 0.1058
old: 0.1421
problem: 0.0925
provided: 0.1373
remember: 0.1421
represent: 0.1294
right: 0.1154
routines: 0.1549
screen: 0.1549
size: 0.1294
solve: 0.1294
source: 0.1203
space: 0.1331
stuff: 0.1331
time: 0.2471
use: 0.0671
used: 0.0948
way: 0.0780
weird: 0.1549

Termine con il punteggio TF-IDF più alto: board (0.4264)

----------------------------------------------------------------------------------------------------

Question 267459:
With some platforms, like LinkedIn, you can see a list of all sessions where you are logged in, and you can even log them out on a distance.

How would you implement something like that? I'm not talking about specific code, but more about general flow.
I am using ASP.NET myself, but I think a general approach would be more useful for others.
Right now I'm thinking about something like this:

User logs in, validate email/password combination
Generate GUID, save to database together with UserId and Browser information.
Put Cookie in a serverside-read-only cookie.
When user wants to sign out from a distance, we remove the GUID in the database.

One of the security issues here would be that the GUID can get intercepted, and an attacker could use this to login.
So how to do this properly?


TF-IDF Scores:
approach: 0.1446
browser: 0.2014
code: 0.0797
combination: 0.2014
database: 0.3063
email: 0.1923
flow: 0.1923
general: 0.3278
generate: 0.1923
implement: 0.1564
information: 0.1446
issues: 0.1848
like: 0.2392
list: 0.1355
net: 0.1564
read: 0.1532
remove: 0.1682
right: 0.1501
save: 0.1923
security: 0.1923
sessions: 0.2014
specific: 0.1564
think: 0.1051
thinking: 0.1600
use: 0.0872
useful: 0.1600
user: 0.2752
using: 0.1041
wants: 0.1730

Termine con il punteggio TF-IDF più alto: general (0.3278)

Best Answer:
Every session is going to have some authorization artifact it uses to track sessions. (In web applications, usually this is a token in a cookie, although it doesn't have to be in a cookie.)
When your application grants those authorization artifacts, you can keep a link back to a user, and then manage them as a one-to-many relationship -- one user has many tokens. Then you provide all the usual operations like list all, filter/search, delete, etc.
Usually, when a service or framework grants a new authorization artifact, it just looses track of the old ones. So there's an implicit one-to-many (one user, many sessions), except that the other sessions are just lost and eventually cleaned up. But you can track them explicitly if you keep a link to the user account.


TF-IDF Scores:
account: 0.1340
application: 0.1220
applications: 0.1295
eventually: 0.1395
explicitly: 0.1395
filter: 0.1395
framework: 0.1134
going: 0.1111
like: 0.0578
link: 0.2922
list: 0.0983
lost: 0.1395
manage: 0.1340
new: 0.0808
old: 0.1340
ones: 0.1295
operations: 0.1220
provide: 0.1111
relationship: 0.1295
search: 0.1340
service: 0.1295
sessions: 0.4382
token: 0.1461
track: 0.3884
user: 0.3992
uses: 0.0998
usual: 0.1461
usually: 0.2136
web: 0.1031

Termine con il punteggio TF-IDF più alto: sessions (0.4382)

----------------------------------------------------------------------------------------------------

Question 267469:
The tutorials I find to setup OS-X for web developer programming (installing x-code ruby js cocoapods sql c asm etc) leave out if it should be done from an admin account, or standard (managed) user.
Some methods I've seen used: Setup dev environment from admin account, then change admin to managed user. Or install dev environment from managed user, using sudo or otherwise editing settings to get things to install.
What's the consensus for using Terminal from a managed & parental controlled account? What's the correct procedural way to setup a fresh 10.10 install? Thanks.


TF-IDF Scores:
10: 0.2522
account: 0.4370
change: 0.1102
code: 0.0628
correct: 0.1326
developer: 0.1207
environment: 0.2913
js: 0.1587
leave: 0.1326
methods: 0.1140
os: 0.1587
procedural: 0.1587
programming: 0.0878
ruby: 0.1407
seen: 0.1233
setup: 0.4762
sql: 0.1515
standard: 0.1364
thanks: 0.1587
things: 0.0937
used: 0.0971
user: 0.3253
using: 0.1641
way: 0.0799
web: 0.1120

Termine con il punteggio TF-IDF più alto: setup (0.4762)

Best Answer:
I don't work with Ruby, but I work with Django/Python and I think the same principles apply.
Don't install stuff system-wide. To give you an idea, these are different methods for installing Python packages, from worst to best:

sudo pip install django: install Django system-wide. Don't do this.
pip install --user django: install Django for current user only. Better, but not great.
virtualenv --distribute myproject; . myproject/bin/activate; pip install django: create a virtualenv and install Django in there. Best. Multiple web projects can exist, each using different versions of Django, different versions of dependencies, as needed

You get the idea. The equivalent must exist for Ruby on Rails too.
As much as possible, install everything in user space.
Some things won't really be practical this way, 
for example a MySQL database or Apache web server.
It depends on how much modularity you need.
If you will never ever need isolated MySQL servers running,
then you can just install one and isolate uses by separating MySQL user accounts.
The most professional option is probably to work in sandboxes,
using software such as Vagrant or Docker.


TF-IDF Scores:
apply: 0.1262
best: 0.2186
better: 0.0842
create: 0.0842
current: 0.1068
database: 0.1046
depends: 0.1262
different: 0.2659
equivalent: 0.1262
example: 0.0777
exist: 0.2752
great: 0.1119
idea: 0.2137
methods: 0.0988
multiple: 0.1046
need: 0.1492
needed: 0.1119
option: 0.1149
possible: 0.0955
probably: 0.0988
projects: 0.1182
python: 0.2186
really: 0.0874
ruby: 0.2438
running: 0.1313
server: 0.1068
servers: 0.1376
software: 0.0971
space: 0.1182
stuff: 0.1182
things: 0.0812
think: 0.0718
user: 0.3759
uses: 0.0940
using: 0.1423
versions: 0.2752
way: 0.0692
web: 0.1942
work: 0.2356

Termine con il punteggio TF-IDF più alto: user (0.3759)

----------------------------------------------------------------------------------------------------

Question 267484:
So OOP is about breaking down functionality, making each class responsible for one thing etc. But let's take the example where an object is using another object. First thing that comes to mind "composition, of course!".
I have 2 questions:
Question 1:
Suppose you have a Shop that is loading products from a file using a ProductsLoader, which in term uses a ProductsFileReader. You design the API so that the code is simple and readable and specialized. Therefore, you are able to do this:
    std::shared_ptr<Shop> shop = std::shared_ptr<Shop> (new Shop());
    shop->LoadProducts();
    // other code

In LoadProducts you do this:
    m_productsLoader.LoadAllProducts();
    std::shared_ptr<Products> products = m_productsLoader.GetAllProducts();
    this->setProducts(products);

In LoadAllProducts() you do this:
    prodFileReader.OpenProductsFile();
    prodFileReader.LoadDescriptionsFromFile();
    prodFileReader.CloseProductsFile();

    // create products from descriptions
    std::shared_ptr<Descriptions> descriptions = prodFileReader.GetProductsDescriptions();
    this->createProductsFromDescriptions(descriptions);

And now here is the question: Do you keep ProductsLoader m_productsLoader as a Shop member? The same for ProductsFileReader: should it be a member of ProductsLoader? The alternative for this is creating these objects on the stack: when your functions are using one of them, you just declare, initialize etc them in the function and they get destructed when the function exits. Does this defy the purpose of OOP?
Question 2:
Let's say you decided to keep them as members. How do you know wheter you should keep the whole object as a member, or you should keep only a pointer to it (and, of course, in the constructor, instantiate the member and assign the pointer). Whether you access the member with the dot opperator . or arrow ->, it will perform the same functionality.


TF-IDF Scores:
able: 0.0788
access: 0.0788
alternative: 0.1036
api: 0.0989
breaking: 0.0989
class: 0.0591
code: 0.0820
comes: 0.1036
constructor: 0.0865
course: 0.1780
create: 0.0634
creating: 0.0744
declare: 0.1036
design: 0.0667
example: 0.0585
file: 0.0772
function: 0.1488
functionality: 0.1780
functions: 0.0843
instantiate: 0.1036
know: 0.0546
let: 0.1645
making: 0.0823
member: 0.4325
members: 0.0950
mind: 0.0989
new: 0.0573
object: 0.2002
objects: 0.0757
oop: 0.1836
perform: 0.0918
pointer: 0.1978
products: 0.5179
purpose: 0.0843
question: 0.1878
questions: 0.0772
readable: 0.0989
responsible: 0.0989
say: 0.0667
simple: 0.0843
stack: 0.0843
suppose: 0.0950
thing: 0.1544
uses: 0.0708
using: 0.1607

Termine con il punteggio TF-IDF più alto: products (0.5179)

Best Answer:
The subject you're asking about is called modeling, and it's as much an art as a science.  But the first step of OO modeling is to forget about the mechanics of the language and think about the properties of the things you're modeling.
A class named ProductsLoader is suspect to begin with.  Names like that indicate that you're thinking procedurally instead of in an OO way.  Instead, the Product class should have functions to produce instances and collections of itself from files or streams or whatever.
So back to your question, but substituting Product for ProductsLoader as the example.  How to decide whether Product (or a collection of them) should be a member of Shop?  Well, do shops have products in them?  That's the kind of question that should guide your decisions in OO modeling, not how the particular language you're using allocates things.


TF-IDF Scores:
asking: 0.1528
begin: 0.1779
called: 0.1413
class: 0.2031
collection: 0.1698
decide: 0.1326
decisions: 0.1779
example: 0.1005
files: 0.1779
forget: 0.1577
functions: 0.1448
guide: 0.1698
instances: 0.1698
instead: 0.2555
kind: 0.1486
language: 0.2031
like: 0.0704
member: 0.1486
names: 0.1698
particular: 0.1353
product: 0.4585
products: 0.1779
properties: 0.1577
question: 0.2150
step: 0.1632
suspect: 0.1698
things: 0.2100
think: 0.0928
thinking: 0.1413
using: 0.0920
way: 0.0895

Termine con il punteggio TF-IDF più alto: product (0.4585)

----------------------------------------------------------------------------------------------------

Question 267486:
I am a desktop developer moving to web development. The guys who I am working with use procedural PHP, and coming from an event driven, objectified perspective (using WPF and C#.Net) I am completely lost in what seems like the Wild West of development.
Are there any language/framework combinations that allow some semblance of state between the client and server and 'persists' the objects? Is there a way to create a definition of an object that is synonymous between the client and the server?  
Is there anything that incorporates testing and UI components as well?
I realize this is a somewhat broad and biased question, however it is one that I have not found any definitive answers for. Any advice and guidance would be thoroughly appreciated!


TF-IDF Scores:
allow: 0.1713
answers: 0.1773
client: 0.3145
coming: 0.1933
completely: 0.1845
components: 0.1660
create: 0.1182
definition: 0.1773
desktop: 0.1845
developer: 0.1469
development: 0.2525
driven: 0.1713
event: 0.1845
framework: 0.1501
language: 0.1103
like: 0.0765
lost: 0.1845
net: 0.1501
object: 0.1245
objects: 0.1413
php: 0.1713
procedural: 0.1933
question: 0.1168
realize: 0.1713
server: 0.3002
somewhat: 0.1933
state: 0.1614
testing: 0.1614
ui: 0.1713
use: 0.0837
using: 0.0999
way: 0.0973
web: 0.1364
working: 0.1300

Termine con il punteggio TF-IDF più alto: client (0.3145)

Best Answer:
Your best bet is to first learn JavaScript without any frameworks. It works both in the client and server side (as Node.js). JavaScript is Event Driven by itself so you won't face much issue here.
Since you are coming from a C# background and your team uses PHP, I would highly recommend the Dojo Framework. It works both on the client and server side or it can work on the client side and has integration with Zend PHP on the server side.
There are Widgets in Dojo inside the Dijit package, which are basically classes used for implementing UI (Controls in the C# World). Integrating with Zend has some interesting perks includidng the persistent state you are talking about.
Otherwise you could go for vanilla frameworks like jQuery and sync data with your PHP server using AJAX Calls.


TF-IDF Scores:
background: 0.1262
basically: 0.1306
best: 0.1131
calls: 0.1223
classes: 0.1082
client: 0.3475
coming: 0.1424
data: 0.0860
driven: 0.1262
event: 0.1359
framework: 0.1105
frameworks: 0.2612
implementing: 0.1306
inside: 0.1223
integration: 0.1306
interesting: 0.1158
issue: 0.1189
javascript: 0.2523
js: 0.1424
learn: 0.1061
like: 0.0564
php: 0.3785
recommend: 0.1424
server: 0.4422
state: 0.1189
team: 0.1158
ui: 0.1262
used: 0.0871
uses: 0.0972
using: 0.0736
work: 0.0813
works: 0.2122
world: 0.1131

Termine con il punteggio TF-IDF più alto: server (0.4422)

----------------------------------------------------------------------------------------------------

Question 267488:
I often wondered why C Language is taught as the basis of programming languages everywhere. There are a lot of modern languages like Java, Python etc. which makes the syntax and programming easier. Why are we still holding the C Language up in the front as the basics of programming languages?


TF-IDF Scores:
basis: 0.2538
easier: 0.2112
java: 0.1816
language: 0.3036
languages: 0.5728
like: 0.1053
lot: 0.1846
makes: 0.1647
programming: 0.4412
python: 0.2112
syntax: 0.2356
taught: 0.2659

Termine con il punteggio TF-IDF più alto: languages (0.5728)

Best Answer:
It's not taught as the basis of Programming Languages. It's taught as the basis of how the machine works.
A programming language displays some facade to the programmer. Some abstraction. In functional languages it is functions. In logic languages it is logic. In OOP languages it is objects. In C it is the machine.
C, while hiding away the implementation details of the hardware on which it runs (register names, memory management, etc), gives the user the impression it deals with a machine. A computer. This gives students better appreciation of how the computer works. Some universities don't see "how the computer works" a necessary knowledge (it isn't), so they don't teach C.


TF-IDF Scores:
abstraction: 0.1465
away: 0.1299
basis: 0.2798
better: 0.0896
computer: 0.3896
details: 0.1192
functional: 0.1192
functions: 0.1192
gives: 0.2597
implementation: 0.1092
knowledge: 0.1299
language: 0.0837
languages: 0.4209
logic: 0.2385
management: 0.1259
names: 0.1399
necessary: 0.1299
objects: 0.1072
oop: 0.1299
programmer: 0.1092
programming: 0.1621
students: 0.1465
taught: 0.2931
user: 0.1001
works: 0.3276

Termine con il punteggio TF-IDF più alto: languages (0.4209)

----------------------------------------------------------------------------------------------------

Question 267489:
Will it be difficult in developing a programming language which is much more closer to our language ?
It was just to know the view of programmers across the globe towards the natural programming language.Thanks for giving me your views on this . 


TF-IDF Scores:
developing: 0.2584
difficult: 0.2415
giving: 0.2914
know: 0.1673
language: 0.5439
natural: 0.3176
programmers: 0.2367
programming: 0.3514
thanks: 0.3176
view: 0.2914

Termine con il punteggio TF-IDF più alto: language (0.5439)

Best Answer:
What do you mean by "closely related"? What problem is this langugae going to solve?
Do you believe that by making a programming language look like a human language, i.e. using many keywords and little interpunction in its syntax, programming will be easier? That is not hard to do at all, but futile. It has been tried many times, most prominently with SQL and COBOL. Such languages are often disliked by programmers for their verbosity, and they do not help people to learn programming more easily.
What makes programming difficult is not dealing with syntax consisting of weird symbols, but the task of translating the requirements into unambiguous, detailed instructions, and dealing what all the special cases that nobody thought of when formulating the requirements.
Or do you envision the ability to use free-form natural language to instruct a computer? That, too, has been tried for a long time, and it's one of the hardest unsolved problems in artificial intelligence, because it would not be a programming language at all, lacking formal syntax and semantics. Basically, you need a compiler or interpreter that is as intelligent as a human. In fact, this is pretty much the job human programmers do.


TF-IDF Scores:
ability: 0.1196
basically: 0.1196
believe: 0.1196
cases: 0.0890
cobol: 0.1244
compiler: 0.1155
computer: 0.1155
dealing: 0.2392
difficult: 0.0991
easier: 0.1035
easily: 0.1035
fact: 0.1120
form: 0.1035
free: 0.1155
going: 0.0991
hard: 0.1089
help: 0.0920
job: 0.0991
language: 0.2976
languages: 0.0936
learn: 0.0971
like: 0.0516
little: 0.1035
long: 0.0953
look: 0.0953
makes: 0.0807
making: 0.1035
mean: 0.1196
natural: 0.1304
need: 0.0707
people: 0.0807
pretty: 0.0936
problem: 0.0778
problems: 0.0953
programmers: 0.1943
programming: 0.3605
related: 0.1120
requirements: 0.1982
semantics: 0.1304
solve: 0.1089
special: 0.1155
sql: 0.1244
syntax: 0.3466
task: 0.1012
thought: 0.1244
time: 0.0693
times: 0.0991
tried: 0.2392
use: 0.0564
using: 0.0674
weird: 0.1304

Termine con il punteggio TF-IDF più alto: programming (0.3605)

----------------------------------------------------------------------------------------------------

Question 267495:
I have an algorithm problem. I'll simplify the issue, because most of what I'm dealing with has nothing to do with the algorithm I need.
Basically, I have a list of objects that each have properties. Let's say for the sake of simplicity that this was a simple struct or another simple data type containing a string ID and an array of strings that are its properties. The properties can be things like "tool", "weapon", "food", etc.
What I need to do is turn this list of objects into a tree, where the most common properties go on top, and the least common go on the bottom. It's a bit more complex than that, actually. For example, let's say that I have:

Four objects with only the "weapon" property.
Six objects with a "tool" and "weapon" property.
Two items with a "food" and "fruit" property.
One item with a "tool" property.

If I were to turn this into the tree that I want, it'd look like this:

weapon (as there are ten items that have the weapon property)

tool (as there are six items with the tool and weapon properties)

food

fruit

tool

It's simple to do by hand, but I can't seem to wrap my head around putting this into program form. Any help?


TF-IDF Scores:
actually: 0.0656
algorithm: 0.1499
array: 0.0749
basically: 0.0823
bit: 0.0682
common: 0.1425
complex: 0.0823
data: 0.0542
dealing: 0.0823
example: 0.0507
form: 0.0713
hand: 0.0713
head: 0.0857
help: 0.0633
id: 0.0857
issue: 0.0749
items: 0.2385
let: 0.1425
like: 0.0710
list: 0.1207
look: 0.0656
need: 0.0973
objects: 0.2624
problem: 0.0536
program: 0.0613
properties: 0.3976
property: 0.3976
say: 0.1156
simple: 0.2190
string: 0.0749
strings: 0.0897
things: 0.0530
tool: 0.5139
turn: 0.1794
type: 0.0623
want: 0.0468

Termine con il punteggio TF-IDF più alto: tool (0.5139)

Best Answer:
You can implement thus recursively:

Find the most common property in the set of objects.
Make this property a (new) root of the tree.
Divide the set in a subset of objects that have the property and a subset of objects that don't have the property.
Recurse: create a tree of the subset of objects that have the property (removing this property from all objects) and set that tree as a subtree of the newly created root.
Repeat steps 1..5 with the other subset (the objects that didn't have the selected property) until the set its empty.



TF-IDF Scores:
common: 0.0950
create: 0.0732
created: 0.0974
implement: 0.0929
make: 0.0636
new: 0.0662
objects: 0.5250
property: 0.7423
set: 0.3437
steps: 0.1197

Termine con il punteggio TF-IDF più alto: property (0.7423)

----------------------------------------------------------------------------------------------------

Question 267516:
I recently stumbled upon a special Sudoku variant and am now struggling to effectively solve it programatically.
Consider the following initial 6x6 grid:

The rules
The red question mark is supposed to represent our secret digit. The secret digit behaves like a normal digit. That is, it has an actual value between 1 and 6, but this value isn't revealed to the player. In this game type, if we create a collision, the newly placed digit would become a neutral element that can be seen as a joker, not colliding with any other digit. For instance, if the secret digit actually was a 6 and we placed a 6 in its row, it would become a neutral element (and we would therewith also know what the secret digit is). We can generate a maximum of one neutral element (meaning that we can only create one collision), a second collision would render the grid unsolved.
Side note: Naturally, this interactive game type doesn't make sense to be printed on a piece of paper; it would e.g. require a client-server infrastructure for the secret not to be revealed to the player.
Analysis
Since the secret digit follows the basic rules, we can deduce that it can't be a 4 in the example grid, but every other digit could be possible. We can also see that there isn't a unique solution; in fact, there usually are hundreds of possible solutions. In a 6x6 initial grid, there is always one secret digit and 6 digits that are pretty randomly placed in the grid (without colliding with each other). This means, the secret could be exposed right off the bet, but we will dismiss the trivial case since it's not fun at all :)
Solving strategy
The most promising strategy would be to find out the secret digit as quickly as possible. That is, we would place digits in its row, column or box until either every possibility is exhausted, or we create a collision. As soon as we know what the secret is, we can solve the puzzle like a normal one (simply ignoring the neutral element if present).
The problem
I want to write an algorithm that finds the secret digit without creating an unsolvable board.
I wrote a rather blunt program which starts by identifying the fields in the secret's row, column and box with the fewest blockers. It then inserts digits in those fields, in an order from fewest blockers to most blockers until the secret can be deduced by collision or exhaustion. In the example grid, it would do something like this:

The blue digits would be placed in ascending order (starting with 1).
My current alogrithm produces an unsolvable board about 20% of the time, which is unacceptable to me. And that's why I'm asking the question:
What would be a smarter approach, minimizing or even eliminating the possibility of creating an unsolvable puzzle?
P.S.: I appreciate every type of answer; theoretical prose, pseudo-code or real code in a popular language is all fine, I simply want to get the gist of which fields/digits to select for the starting strategy.


TF-IDF Scores:
20: 0.0788
actual: 0.0698
actually: 0.0576
algorithm: 0.0658
analysis: 0.0752
answer: 0.0501
approach: 0.0566
asking: 0.0677
board: 0.1446
case: 0.0508
client: 0.0641
code: 0.0624
column: 0.1576
consider: 0.0698
create: 0.1446
creating: 0.1132
current: 0.0612
element: 0.2892
example: 0.0890
fact: 0.0677
fields: 0.1877
following: 0.0612
fun: 0.0788
game: 0.1446
generate: 0.0752
grid: 0.4727
initial: 0.1504
instance: 0.0677
interactive: 0.0788
know: 0.0830
language: 0.0450
like: 0.0936
make: 0.0419
maximum: 0.0788
means: 0.0612
normal: 0.1446
note: 0.0658
order: 0.1446
piece: 0.0752
place: 0.0641
popular: 0.0752
possibility: 0.1576
possible: 0.1641
present: 0.0752
pretty: 0.0566
problem: 0.0470
program: 0.0538
question: 0.0952
quickly: 0.0752
real: 0.0612
recently: 0.0698
render: 0.0788
represent: 0.0658
require: 0.0641
right: 0.0587
rules: 0.1504
second: 0.0599
seen: 0.0612
sense: 0.0599
server: 0.0612
simply: 0.1174
solution: 0.0566
solutions: 0.0752
solve: 0.1316
solving: 0.0752
soon: 0.0752
special: 0.0698
starting: 0.1504
starts: 0.0723
strategy: 0.2095
supposed: 0.0698
time: 0.0419
trivial: 0.0677
type: 0.1641
unique: 0.0788
usually: 0.0576
value: 0.1282
want: 0.0822
write: 0.0508
wrote: 0.0723

Termine con il punteggio TF-IDF più alto: grid (0.4727)

Best Answer:
I don't think i understood the WildCard concept to well. Maybe some images of sample configurations on the board would help?
There are already well established Sudoku Solving Algorithms that exist. Some like
Backtracking.
Keep placing numbers one by one until you reach an unsolvable position, then retrace your last step and continue.
Constraint Solving
Each cell has many constraint because of the row, the column and the group of cells. Map out all the constraints of each cell and begin solving the cell where the answer is unique for that contraint. Keep udating the other contraints as numbers are added.
You can find more here
Since there are well established algorithms, one strategy to tackle this problem is to modify the above strategies to include this. Eg: this cell would impose no constraint in its rows, columns and the bigger cell.
I will try to edit with pseudo code for a constraint based solution if I have time.


TF-IDF Scores:
added: 0.1030
algorithms: 0.2532
answer: 0.0805
based: 0.0926
begin: 0.1266
bigger: 0.1266
board: 0.1161
cell: 0.6329
code: 0.0501
column: 0.1266
concept: 0.1122
continue: 0.1266
edit: 0.1087
exist: 0.1266
group: 0.1208
help: 0.0893
include: 0.1087
like: 0.0501
map: 0.1266
maybe: 0.1030
modify: 0.1208
numbers: 0.2417
problem: 0.0756
reach: 0.1266
sample: 0.1266
solution: 0.0909
solving: 0.3625
step: 0.1161
strategies: 0.1266
strategy: 0.1122
think: 0.0660
time: 0.0673
try: 0.0909
unique: 0.1266

Termine con il punteggio TF-IDF più alto: cell (0.6329)

----------------------------------------------------------------------------------------------------

Question 267534:
When programming for android, whenever I use an AsyncTask the doInBackground method looks like this.
 protected String doInBackground(String... args)

But when using the arguments anywhere in that block I can access them like a normal String array for example in my program
        @Override
    protected String doInBackground(String... args)
    {
        String details = "";
        try
        {
            details = facade.getRecipeDetails(args[0]);
        }
        catch(Exception ex)
        {
            ex.printStackTrace();
        }
        return details;
    }

Which works fine and I have no problem dealing with it. But I'm wondering why they use (String . . . args) instead of a normal array of Strings. Is it just because in the calling method you can just write something like:
 new AsyncHandler.execute("argument1","argument2","argument3",...)  

instead of creating a new array to pass the arguments? Though we could write
new AsyncHandler().execute(new String[]{"Argument1","Argument2"});

which is a bit more verbose.
Are (String ...) and String[] synonymous in how they work, but the argument passing is just easier using the former because there is no need to create an array? As far as I can tell, the former also gets translated to a string array in the background so would they both compile to the same code and it's just 'syntactic sugar'?


TF-IDF Scores:
access: 0.0589
android: 0.0665
args: 0.3099
argument: 0.0739
arguments: 0.1373
array: 0.3234
background: 0.0686
bit: 0.0589
calling: 0.0711
catch: 0.0775
code: 0.0307
compile: 0.0711
create: 0.0474
creating: 0.0556
dealing: 0.0711
details: 0.1891
easier: 0.0615
example: 0.0437
exception: 0.0775
execute: 0.1331
far: 0.0711
gets: 0.0711
instead: 0.1112
like: 0.0920
looks: 0.0647
method: 0.0959
need: 0.0420
new: 0.1714
normal: 0.1422
pass: 0.0647
passing: 0.0711
problem: 0.0463
program: 0.0529
programming: 0.0428
return: 0.0547
string: 0.7116
strings: 0.0775
tell: 0.0711
try: 0.0556
use: 0.0671
using: 0.0801
wondering: 0.0711
work: 0.0442
works: 0.0577
write: 0.0998

Termine con il punteggio TF-IDF più alto: string (0.7116)

Best Answer:
(String ...) is an array of parameters of type String, where as String[] is a single parameter. 
Now here String[] can full fill the same purpose here but (String ...) provides more readability and easiness to use.
It also provides an option that we can pass multiple array of String rather than a single one using String[]. 


TF-IDF Scores:
array: 0.2414
multiple: 0.1099
option: 0.1207
parameters: 0.1326
pass: 0.1207
provides: 0.2483
purpose: 0.1176
readability: 0.1380
single: 0.2352
string: 0.8448
type: 0.1003
use: 0.0626
using: 0.0747

Termine con il punteggio TF-IDF più alto: string (0.8448)

----------------------------------------------------------------------------------------------------

Question 267535:
We have a large project written in PHP. It almost exclusively uses imperative operations, as in example 1. Should we refactor our existing code to use functional operations? Do you think that the code in example 2 is easier to maintain? 
Example 1 - imperative 
 $cookieString = '';
 foreach($cookieArray as $cookieName => $cookieValue) {
   if($cookieString != '') {
     $cookieString .= '; ';
   }
   $cookieString .= $cookieName.'='.$cookieValue;
 }
 return $cookieString;

Example 2 - functional
 return KeyedStream::of($cookieArray)
                 ->mapEntriesToStream(function($cookieName, $cookieValue) {
                   return $cookieName.'='.$cookieValue;
                 })
                 ->joinToString('; ');
}



TF-IDF Scores:
code: 0.1661
easier: 0.1667
example: 0.4740
existing: 0.1802
function: 0.1507
functional: 0.3414
large: 0.1629
maintain: 0.2003
operations: 0.3504
php: 0.1859
project: 0.1352
refactor: 0.1925
return: 0.4442
think: 0.1095
use: 0.0908
uses: 0.1433
written: 0.1752

Termine con il punteggio TF-IDF più alto: example (0.4740)

Best Answer:
Ask yourself honestly why you want to refactor. That's really important. then think what you're doing at your company - are you hired to write nice code, or to create good product.
I think too many developers get so caught up in the minutiae of the codebase that they forget what they're supposed to be doing - which is making something useful out of it. Its like a bricklayer worrying if he should change the clay mixture in his bricks when he's building a wall! (no brickie does that - they build the wall, then go and build more walls. Walls are important, the bricks only so as they make walls happen)
So question what your true motive is here. Is your code so difficult to understand that changing things is too costly? Is your code so rubbish that you cannot understand it to change anything? If the answer is no, then spend your efforts doing something useful.


TF-IDF Scores:
answer: 0.1145
ask: 0.1505
build: 0.2862
building: 0.1653
caught: 0.1720
change: 0.2502
changing: 0.1653
code: 0.2140
company: 0.1720
create: 0.1102
developers: 0.1399
difficult: 0.1370
forget: 0.1597
good: 0.1052
happen: 0.1720
important: 0.2686
like: 0.0713
make: 0.0958
making: 0.1431
nice: 0.1548
product: 0.1548
question: 0.1089
really: 0.1145
refactor: 0.1653
spend: 0.1802
supposed: 0.1597
things: 0.1064
think: 0.1880
true: 0.1597
understand: 0.2635
useful: 0.2862
want: 0.0940
worrying: 0.1802
write: 0.1161

Termine con il punteggio TF-IDF più alto: build (0.2862)

----------------------------------------------------------------------------------------------------

Question 267540:
In my new project, I decided to try with TDD. And in very beginning I encountered a problem. First thing that I want to do in my application is to give ability to read data from data source. For this purpose, I want to use repository pattern. 
And now:

If test are for real implementation of repository interface, I will be testing class that has access to database, and I know that I should avoid that. 
If test are for not real implementation of repository pattern, I Will be testing well... just mock. There will be no any piece of production code tested in those unit tests.

I'm thinking about this from two days and still cannot come up with any reasonable solution. What I should do?


TF-IDF Scores:
ability: 0.1623
access: 0.1345
application: 0.1477
avoid: 0.1519
class: 0.1010
code: 0.0700
come: 0.1374
data: 0.2138
database: 0.1345
days: 0.1688
implementation: 0.2636
interface: 0.1345
know: 0.0932
new: 0.0978
pattern: 0.2747
piece: 0.1688
problem: 0.1056
production: 0.1769
project: 0.1140
purpose: 0.1439
read: 0.1345
real: 0.2747
reasonable: 0.1769
solution: 0.1270
source: 0.1374
tdd: 0.1567
test: 0.2587
tested: 0.1769
testing: 0.2954
tests: 0.1318
thing: 0.1318
thinking: 0.1405
try: 0.1270
unit: 0.1345
use: 0.0766
want: 0.1846

Termine con il punteggio TF-IDF più alto: testing (0.2954)

Best Answer:

Don't test trivial or obvious repository methods.
If the methods are trivial CRUD operations, all you're really testing is whether parameters are mapped correctly.  If you have integration tests, such errors will become immediately apparent anyway.
This is the same principle that applies to trivial properties, like this one:
public property SomeProperty
{
    get { return _someProperty; }
    set { _someProperty = value; }
}

You don't test it, because there's nothing to test.  There's no validation or other logic in the property that needs to be verified.
If you still want to test those methods...
Mocks are the way to do it.  Remember, these are Unit Tests.  You don't test the database with unit tests; that's what Integration Tests are for.

More Information
The Full Stack, Part 3: Building a Repository using TDD (start watching at about 16 minutes in).


TF-IDF Scores:
building: 0.1188
correctly: 0.1295
database: 0.0985
errors: 0.1113
immediately: 0.1236
information: 0.0930
integration: 0.2377
like: 0.0513
logic: 0.1054
methods: 0.2790
minutes: 0.1295
needs: 0.0965
operations: 0.1082
parameters: 0.1188
principle: 0.1236
properties: 0.1148
property: 0.2296
public: 0.1113
really: 0.0823
remember: 0.1188
return: 0.0914
set: 0.0930
stack: 0.1054
start: 0.0885
tdd: 0.1148
test: 0.4735
testing: 0.1082
tests: 0.3861
trivial: 0.3338
unit: 0.1969
using: 0.0670
value: 0.1054
want: 0.0676
way: 0.0652

Termine con il punteggio TF-IDF più alto: test (0.4735)

----------------------------------------------------------------------------------------------------

