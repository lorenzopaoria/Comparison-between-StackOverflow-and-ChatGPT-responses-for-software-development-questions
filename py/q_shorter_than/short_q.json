[
    {
        "ID": "1",
        "Question": "A coworker of mine believes that any use of in-code comments (ie, not javadoc style method or class comments) is a code smell.  What do you think? ",
        "Best answer": "Only if the comment describes what the code is doing. If I wanted to know what was happening in a method or block, I would read the code. I would hope, anyway, that any developers working on a given project were at least familiar enough with the development language to read what is written and understand what it is doing. In some cases of extreme optimization, you might be using techniques that makes it difficult for someone to follow what your code is doing. In these cases, comments can and should be used to not only explain why you have such optimizations, but what the code is doing. A good rule of thumb would be to have someone else (or multiple other people) familiar with the implementation language and project look at your code - if they can't understand both the why and the how, then you should comment both the why and the how. However, what's not clear in the code is why you have done something. If you take an approach that might not be obvious to others, you should have a comment that explains why you made the decisions that you did. I would suspect that you might not even realize that a comment is needed until after something like a code review, where people want to know why you did X instead of Y - you can capture your answer in the code for everyone else who looks at it in the future. The most important thing, though, is to change your comments when you change your code. If you change an algorithm, be sure to update the comments with why you went with algorithm X over Y. Stale comments are an even bigger code smell. "
    },
    {
        "ID": "4",
        "Question": "When starting a project for a company that's not primarily a programming company, one of the expectations is that there's a finished product at the end free of all bugs and does everything needed right away. However, that's rarely the case.  What are some ways to manage expectations and explain to non-programmers how software development differs from other types of product development? ",
        "Best answer": "Pretty much everybody with a computer has encountered the concept of \"bugs\" these days, so you might start there.  \"What's the most annoying way an application has ever failed on you?  Multiply that by ten, and you'll have our users' experience if we don't devote enough resources to testing and maintenance.\" And don't underestimate the value of establishing a good working relationship with the non-programmers.  If you can establish that your judgment may be trusted, they'll take you seriously when you sound the alarm that X is going to fail spectacularly if you don't do Y pronto, even if they don't completely understand your reasoning. "
    },
    {
        "ID": "9",
        "Question": "Sometimes, the things I have to do for my job are interesting and engaging.  Sometimes, they aren't.  Occasionally, they really aren't. Do you have any particular strategies or tricks for dealing with those dull stretches when your brain would rather be doing anything other than what you're supposed to be doing, particularly when the Internet and its boundless opportunities for interesting Slack beckon? ",
        "Best answer": "Increments. I will pick something that I can do, even if it's a small task (i.e. modify comments in code). Pretty soon, the perfectionist in me wants to do more and more stuff and I'm back rolling. "
    },
    {
        "ID": "18",
        "Question": "At first glance, I'd say a good programming team needs to understand the following matters:  The details of the core language / framework HTML, (asynchronous) javascript SQL / data model Usability / UI design Security Project management.  If this team is not complete: what is needed? ",
        "Best answer": "Customer (or an advocate of some sort).   Basically, someone that can say, \"Yes, you're building what I want and it's going to solve my problem.\" or that the team can go to when they have questions about how something is supposed to work.  That may or may not be the same person that is doing Project Management. Also, you're missing out on a QA person there.  You can't really depend on the developers to adequately test - they're usually too close to the code and the normal response for developers is to test happy path stuff, not doing weird crap like copy pasting War & Peace into a textbox and seeing what the application does. "
    },
    {
        "ID": "38",
        "Question": "Where waterfall commonly includes:  Requirements Functional design Technical design Build Test Review (Deploy)  And iterations across this list. If I forgot a step, let me know. ",
        "Best answer": "It depends on many factors, including:  The domain (eg, I'd spend more time on a defense contract's requirements than I would on a Twitter clone) The developers (if they have experience building similar systems with similar technology, for example, I might spend less time on the design). The customers (How likely the requirements are to change affects how long that phase will take) The criticality of the system (I'll spend more time testing the space shuttle's launch system than I will the StackExchange rep system).  I'd give you a rough breakdown of what percent of the total effort I'd give to each section, but it'd have a margin of error +/- 10% on each based on the above factors so it'd be kinda meaningless. "
    },
    {
        "ID": "39",
        "Question": "What's your favourite quote about programming? One quote per answer, and please check for duplicates before posting! ",
        "Best answer": " Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.    — Brian W. Kernighan "
    },
    {
        "ID": "42",
        "Question": "We've all had them, managers who have either come from sales or last looked at code 10 or more years ago but think they know how to write code. What can I do to give the impression that I'm grateful for their intervention, but keep it as short as possible so I can get on with my work? Or, should I be engaging more with the manager to educate them with modern coding techniques and practices? After all, a manager who understands these will be able to talk sensibly to clients and more senior management when discussing the project and its timescales. ",
        "Best answer": "I say, go ahead and try to engage and educate. If they're honestly trying to help you, the chance to learn something could be valuable to them.  If they're just shoving their nose in for ego or political reasons (\"See, I'm helping, I'm helping!\"), they'll likely get the notion you'll embarrass them if they keep this nonsense up -- or bore them to death with a wall of jargon they're only pretending to understand. And if you've got the dreaded egomaniac who truly thinks they're an expert at your job no matter what evidence you can bring to the contrary, then smile, nod, and make whatever trivial cosmetic changes will make them go the hell away.  And update your resume. "
    },
    {
        "ID": "44",
        "Question": "I am finishing my college degree in programming soon and I'm exploring the next steps to take to further my career. One option I've been considering is getting a certification or a series of certifications in the area of development I want to work in. Are these certifications worth the time and money? Do employers place a lot of value in them? ",
        "Best answer": "The main purpose of certifications is to make money for the certifying body. Having said that, I think certifications are more important the earlier on in your career you are. As a hiring manager, I never use certifications or the lack thereof to filter potential employees, but I do think some companies may look for these as proof that you know what you are doing. Personally, I want the job candidate to show me they can do something (which is a whole other question, I realize!) The more experience you have, the more you can prove by examples that you know what you are doing and the less important certifications become. "
    },
    {
        "ID": "57",
        "Question": "The coding standards for the code hosted in drupal.org suggest to use two spaces to indent the code; other sites suggest to use tabs to indent the code. What is the proper indentation character for everything, and in every situation? Please explain the answer you give. ",
        "Best answer": "Tabs Now, of course, consistency matters more than either one, and a good IDE makes the differences negligible.  That said, the point of this thread is to be a holy war, so: I prefer tabs:  They're a character specifically meant for indentation They allow developers with different preferences in indentation size to change how it's the code looks without changing the code (separation of data and presentation for the proverbial win!) It's impossible to half-indent something with tabs.  So when you copy code from some website that used 3 spaces into your 4-space indented file, you don't have to deal with misalignment.  "
    },
    {
        "ID": "73",
        "Question": "We often receive last minute requests from the business asking for an extra feature to be implemented.  The project manager is usually responsible for filtering out these requests as \"must haves\" or \"nice to have\", but there are cases where the business wants to squeeze all these features into a release.   Is there a good way to say NO to the business?  What steps can be taken to stop or minimize scope creep? ",
        "Best answer": "Ask them what they want you to drop so you'll have the time to squeeze this latest request in. I've not had to do this for a while, and when I did, I used it sparingly otherwise it loses it's potency. I found it most effective towards the end of the phase when you were tidying stuff up or doing the little improvements and tweaks you'd agreed on in the planning stage. "
    },
    {
        "ID": "94",
        "Question": "I realize there have been lots of discussions about this type of thing and they often devolve into dogma around whether you ask the \"100 logical pirates\" type of questions or whether you get them to write \"fizz buzz\".  I'm interested in what techniques and questions have been effective for you when interviewing potential developers for jobs.  One technique per answer so we can vote on them, please. ",
        "Best answer": "Besides real technical questions, and typically at the end of the interview I try to get a grasp of their level of interest in the industry and it's culture with questions like:  Have you seen anything recently programming-related that you found interesting and would like to recommend to other fellow programmers? A new language, tool, platform, technique, website? Can you name any well known person in our industry whose work you like or find inspiring and why? (developer, web site founder, author, speaker, etc) What are you reading now or what was the last software related book you read? What programming related sites do you frequent?  Although failing to answer these questions at all (sadly it happens very frequently) does not mean a 'no-hire' to me, they say a lot about the way a person approaches the software development profession. "
    },
    {
        "ID": "104",
        "Question": "We've often run across scenarios where the business will promise a client a new feature.  The business will promise that the feature be implemented in a specific way.  These technical details promised by the business are usually poor.  Unfortunately, client is now set and want this feature to be implemented in the way described by the business. In the end, the business just wants this feature to be completed without regard to quality and maintainability.  Is there a good way to push back?  How can we explain to the business that providing technical details before the requirements have been gathered is a bad idea? ",
        "Best answer": "That's an organizational issue.  If the higher-ups don't understand this, there's not much you can do.  Try to explain the issue to your non-technical bosses, but don't be surprised when you get nowhere. It's is a common problem for developers working in non-development companies that, for whatever reason, sell software. It's not a pleasant tactic, but you can just bludgeon them with evidence.  At the start of a project, write down exactly why it's going to fail (because technical details were poor) and email it to relevant people.  Keep emailing them throughout, and when the project eventually ends up a disaster with pissed off customers, cite those emails you sent at every opportunity.  It may generate some ill will, but there's really no good way to try to fix a systemic issue like that. "
    },
    {
        "ID": "134",
        "Question": "How do you bill your programming projects? Do you do it per hour? Per job?  Please include what kind of project you are doing in the answer. (Mobile, Web, Desktop, etc... You can be more specific if you want.) BONUS: If you'd like to give specific amounts in your answer, you may. ;-) ",
        "Best answer": "There's always going to be a struggle between you and the client over costs: you want to charge as much as you can from a client, and a client is going to want to get as much work for as little cost as possible. So, when you charge hourly, it leaves open to negotiation how many hours a project should take to complete. You may think it'll take 10 hours, but your client thinks you should do it in 5. By charging by project, there's very little open to negotiation: it costs $X, and the client can take it or leave it. "
    },
    {
        "ID": "135",
        "Question": "Who in the software engineering and software development fields uses Twitter to tweet about relevant happenings in the field? ",
        "Best answer": "I'll probably get flamed for this but... 140 characters is hardly the format to get any real pearls of programming wisdom.  Most (but not all) programming concepts/thoughts/ideas require more space to be articulated. I would follow the blogs of the list of programmers that everyone is suggesting. "
    },
    {
        "ID": "163",
        "Question": "Are there any great programming or software development books that are language agnostic?  Why should I read it? ",
        "Best answer": "The Pragmatic Programmer: From Journeyman to Master - Andrew Hunt and David Thomas This book is all about how to write code that works and is maintainable. A key concept is being practical. Everything in the book is boiled down to 70 tips that are easy to remember that help you deliver better, higher-quality software. "
    },
    {
        "ID": "177",
        "Question": "The Actor Model which is used by Erlang seems to be a very different way to do concurrent programming. What are your thoughts about the Actor Model? Will it be a popular solution for concurrency? ",
        "Best answer": "I presume you knows the concept. Well, I don't know very well yet. The short answer is that I believe in popularity of this model to concurrency in short and medium term. I always loved lambda and closures and I see actor like closures specially handled to power concurrency. Thus multi core processors bring to us a new paradigm to programming, concurrency is obligatory to achieve high performance. Actor model seems the ease path to exploit modern hardware. Sooner or later (i hope sooner) almost every mainstream language will support a better model to concurrency. IMHO Actor model so well implemented in Erlang should be the best candidate. One obstacle to Actor model gain popularity is the little impedance with OOP, the dominant paradigm now. But the first step is being given, the main languages are implementing some functional features which will clean the path to Actor model. I am reading a lot about this issue, I think it is very important to every programmer advance in his/her skills. Late Edit: Now I understand better the paradigma. So I can say it's better to a programming languague allow allow the problem be handled by libraries or eventually has a feature to facilitate the adoption of one model. Tie a language with just one model doesn't see a good ideia. "
    },
    {
        "ID": "192",
        "Question": "If I have some code that has 80% test coverage (all tests pass), is it fair to say that it's of higher quality than code with no test coverage?   Or is it fair to say it's more maintainable? ",
        "Best answer": "By one definition it's more maintainable, as any breaking change is more likely to be caught by the tests. However, the fact that code passes the unit tests doesn't mean it's intrinsically of higher quality. The code might still be badly formatted with irrelevant comments and inappropriate data structures, but it can still pass the tests. I know which code I'd prefer to maintain and extend. "
    },
    {
        "ID": "206",
        "Question": "Test driven development. I get it, like it. But writing tests does require overhead. So should TDD be used universally throughout the code base, or are there areas where TDD provides a high ROI and other areas where the ROI is so low that it is not worth following. ",
        "Best answer": "I'd say avoid TDD in places where the code is likely to change structurally a lot.  Ie, it's great to have a pile of tests for a method whose signature changes rarely but gets refactored internally more frequently, but it sucks to have to fix your tests every time a highly volatile interface changes dramatically. The apps I've been working on recently have been data-driven webapps built on a Gui->Presenter->BusinessLogic->Data Access Layer-based architecture.  My data access layer is tested like nobody's business.  The business logic layer is pretty well tested.  The Presenters are only tested in the more stable areas, and the GUI, which is changing hourly, has almost no tests. "
    },
    {
        "ID": "215",
        "Question": "Having taken a course in Operating Systems I'm interested in expanding my knowledge of the Linux kernel and practice working with a big system. What are some interesting but not overly difficult projects I can try my hand at?  EDIT: a bit of background on what I did do with the kernel.   Implemented a new scheduling policy Implemented User Threads and a corresponding mutex library (not really kernel hacking but contained kernel related theory)  ",
        "Best answer": "I've not done much work on kernels before (they scare me), but I've heard that http://kernelnewbies.org/ is a fantastic resource if you want to get involved in kernel work. As already mentioned SourceForge is a great place to look if you want to get involved in an open-source kernel-related project. Also, a similar question has been asked on Stack Overflow before, so you may want to look here. What are some interesting, small Linux kernel projects to help learn the source? "
    },
    {
        "ID": "220",
        "Question": "How would someone implement Agile process concepts as a solo developer?  Agile seems useful for getting applications developed at a faster pace, but it also seems very team oriented... ",
        "Best answer": " By doing test-driven development By developing in small sprints By having a lot of contact with the customer  I remember reading a thesis about Cowboy Development, that is essentially Agile for solo developers. The thesis can be read here: Cowboy: An Agile Programming Methodology For a Solo Programmer (PDF) "
    },
    {
        "ID": "221",
        "Question": " Possible Duplicate: Using “Foo” and “Bar” in examples   I know AT&T labs used them in their Unix days, but do they have even deeper histories? ",
        "Best answer": "From the Jargon file:  When ‘foo’ is used in connection with ‘bar’ it has generally traced to the WWII-era Army slang acronym FUBAR (‘Fucked Up Beyond All Repair’ or ‘Fucked Up Beyond All Recognition’), later modified to foobar. Early versions of the Jargon File interpreted this change as a post-war bowdlerization, but it it now seems more likely that FUBAR was itself a derivative of ‘foo’ perhaps influenced by German furchtbar (terrible) — ‘foobar’ may actually have been the original form. For, it seems, the word ‘foo’ itself had an immediate prewar history in comic strips and cartoons. The earliest documented uses were in the Smokey Stover comic strip published from about 1930 to about 1952. Bill Holman, the author of the strip, filled it with odd jokes and personal contrivances, including other nonsense phrases such as “Notary Sojac” and “1506 nix nix”. The word “foo” frequently appeared on license plates of cars, in nonsense sayings in the background of some frames (such as “He who foos last foos best” or “Many smoke but foo men chew”), and Holman had Smokey say “Where there's foo, there's fire”.  "
    },
    {
        "ID": "247",
        "Question": "Does learning COBOL still make sense? ",
        "Best answer": "I don't think so, unless you are already in the niche market where COBOL is still maintained. "
    },
    {
        "ID": "252",
        "Question": "There is a widely accepted opinion that Singleton is an anti-pattern. As usual, there are always exceptions to the rule. Can you explain why Singleton is a bad choice in general and give an example of some valid use cases for it? ",
        "Best answer": "The Singleton pattern is basically just a lazily initialized global variable.  Global variables are generally and rightly considered evil because they allow spooky action at a distance between seemingly unrelated parts of a program.  However, IMHO there is nothing wrong with global variables that are set once, from one place, as part of a program's initialization routine (for example, by reading a config file or command line arguments) and treated as constants thereafter.  Such use of global variables is different only in letter, not in spirit, from having a named constant declared at compile time. Similarly, my opinion of Singletons is that they're bad if and only if they are used to pass mutable state between seemingly unrelated parts of a program.  If they don't contain mutable state, or if the mutable state that they do contain is completely encapsulated so that users of the object don't have to know about it even in a multithreaded environment, then there's nothing wrong with them. "
    },
    {
        "ID": "262",
        "Question": "Will Java have the same importance it had in the past, or it will be less relevant than nowadays? ",
        "Best answer": "Java is relevant and will continue to be relevant for many years in the Enterprise computing world.   Whether it continues to be relevant in other areas depends a lot on what Oracle does.  If they inject some life (and resources) into ME, desktop applications and other areas, and if they press on with the evolution of the Java language, then Java will do well.   But if Oracle cuts back on R&D and/or tries to stomp other players in the Java space, there's a good chance that someone / some company will develop a better (and more open) Java-like language.  If Oracle win their lawsuit against Google, I predict that the next generation of the Android platform will have a new language, just like happened with C#.  If Google get the openness right ... then, the game is on! "
    },
    {
        "ID": "294",
        "Question": "I just started working a year ago, and I want to join an open source project for the same reasons as anyone else: help create something useful and develop my skills further. My problem is, I don't know how to find a project where I'll fit in. How can I find a beginner-friendly project?  What attributes should I be searching for?  What are warning signs that a project might not be the right fit?  Are there any tools out there to help match people with open source projects? There's a similar question here, but that question has to do with employment and is limited to PHP/Drupal. ",
        "Best answer": "My first open source contribution was for a library that I had previously used (and would've suffered greatly without) on a previous paid project. During my initial use I had spotted a bug in the code so I created a patch, joined the project, and submitted it for review. About 8 months later when I had some free time I decided that I would give back (and work on my development skills) by contributing more to the project. So I cloned the repository and started getting familiar with the codebase. After a few weeks of submitting minor patch fixes to the codebase and monitoring the feature requests, I picked up a feature request to add a pretty substantial module to the project. Since generating many individual patch fixes is pretty tedious for any significant development I cloned the repository to a branch on git hub and started punching away code. A few weeks and several thousand lines of code later the project leader and me worked through integrating and testing my fixes into the library in a way that worked consistently with the rest of the codebase. It was an invaluable process that I learned a lot from:   When I started I didn't know how to use Git, by the end I could proficiently create remote tracking branches and merge or rebase them into the master branch without breaking a sweat.  I started in VS 2008 and ended up migrating to Linux and Monodevelop to work on writing code (because VS is unicode retarded and line endings are such a pain in git). It turns out that theres not much you can't do in *nix that you can do in *dows. I had never really done any unit testing before, Nunit is a piece of cake to use and writing unit tests is pretty elementary stuff. I had to learn to swallow my tongue and listen as well as practice patience. There's no point in standing a firm ground on your position on an open source project because everybody involved is knowledgeable (probably more so than yourself) and capable of accepting/rejecting your ideas based on substance not delivery. It's extremely humbling and rewarding at the same time. Just having one other skilled developer's eyes on a large base of my code pointed out flaws in my style that I had never considered before (as well as I pointed out flaws in his code). For me, I learned that it's easier/better to define constants than it is to use a bunch of magical numbers with detailed commenting.  That particular project was based around generating and decoding networking packets on all levels of networking protocols. I have a personal interest in lower level networking so it was great to have discussions with another developer with shared interest and knowledge in the domain. If you want to just get your feet wet: find a project that you already use; clone the repository; and start seeing if you can fix some bugs and/or add some unit tests. It seems intimidating to look at someone else's codebase with fresh eyes but it's an extremely valuable skill to learn. Submit some patches. You can expect your code to be closely scrutinized at first. Don't worry about it, it's a normal part of the process to gain the trust of the project admin(s). After establishing a base of merit with the projects admin(s) start seeking more responsibilities such as, proposing new features, or asking to be assigned to implementing feature requests.  If you can't find an already existing project on one of the main open source repository networks (github, sourceforge, google code) think of an app that you'd really like to use that doesn't exist yet and start your own. Be prepared to be humbled and expect work to be rejected in favor of further revisions. The myth that anybody can add code to an open source project is completely false. There's always a gatekeeper between you and push access. The better your code, the less it will be scrutinized in the long run as you gain trust of the project admin(s). If it's your project, you'll be that gatekeeper. Update: I just thought about it and realized that I didn't bother to mention which project that a lot of my answer is referencing. For those who want to know, it's SharpPcap. The lead developer Chris Morgan is very professional and on point. He does a hell of a job managing the project and taught me a lot about what it takes to mature a OSS project. Due to personal time constraints I haven't been able to contribute code in over a year but I still try to give back by lurking on Stack Overflow and answering questions about SharpPcap occasionally. "
    },
    {
        "ID": "348",
        "Question": "Elite developers can be 10x more productive than an average developer.  Clearly it's easier to find an elite developer around the whole world than in a company's backyard.  If a company is not located in a programming hot spot, should they consider hiring people who work from home? ",
        "Best answer": "I have worked as, and managed staff in both situations, and combinations of both.  I've made the following observations:  Junior staff do not work remotely.  They require a good and personal working relationship with a mentor.  I find my junior staff would rather wait for me to be available than to ask the rather senior (and good) remote developer anything. Ensure anyone you consider for working remotely is effective when self-guided and doesn't go off on tangents. Remote staff can get isolated really easily and not feel part of a team unless special effort is made to be inclusive of them.  This isolation can lead to a misunderstanding of the specific business driver for a project, or to misinterpret events in a negative manner. Never get a contractor working remotely, unless they have the right incentive to perform. When working with a remote team member, make sure they get equitable access to resources, including source control, reference material, etc.  Don't make them jump through hoops to get work done. Arrange those face to face meetings as often as practical.  This encourages far better team collaboration as people are more comfortable with those they have met.  "
    },
    {
        "ID": "368",
        "Question": "For a long time in SO and in other places Java has the reputation of being slow. From jokes to many comments in questions and answers, people still believe Java is slow based solely on experience with it in the 90s. This is my issue: we have disproved (most) of the reasons that people believe Java is slow. Outside of small things, Java is pretty fast. So why is it that people still refuse to believe Java is fast now? Is it part of their mindset that anything thats not C/C++ is slow? Is it because people don't check over time? Is it because people are just biased? ",
        "Best answer": "It's the applications. As you note, we have proved, time and time again, that in contrived scenarios Java code can meet or even beat the performance of so-called \"performant\" languages like C, C++, Lisp, VB6, or JavaScript. And when presented with such evidence, most sane, open-minded opponents will hang their heads in shame and promise never again to spread such slander. ...but then, they fire up Eclipse, or NetBeans, or Guiffy, or enable the Java support in their browser, or try to run an app on their favorite feature phone. And they wait for it to become responsive... ...and wait...   ...and wait...     ...and wait...         ...and wait...             ...and...      ...what did I promise never to do again? Sorry, must have dozed off... "
    },
    {
        "ID": "404",
        "Question": "Joel Spolsky wrote a famous blog post \"Human Task Switches considered harmful\". While I agree with the premise and it seems like common sense, I'm wondering if there are any studies or white papers on this to calculate the overhead on task switches, or is the evidence merely anecdotal?  ",
        "Best answer": "The abstract of a study that says 'maybe' Another study [PDF] that says interruptions make things seem like they took longer. A study[PDF] that says interruptions increase resumption lag time, but that cues seen in the task before the interruption can speed recovery time. Task switching[PDF] takes a significant portion of our work week. More reading on the psychology of interruptions than you can shake a stick at. "
    },
    {
        "ID": "487",
        "Question": "If you were to design a programming language, how would you do it? What features would you put in? What would you leave out? Statically or dynamically typed? Strongly or weakly typed? Compiled or interpreted? Justify your answers. ",
        "Best answer": " I definitely think that functional programming languages will catch on, so my language will be functional. See Taming Effects with Functional Programming I think the CPUs soon will have hundreads of cores, and threads will he a hell to manage. So the Actor Model is a must instead of threads. See Erlang - software for a concurrent world I also think that OOP has failed, the communication between objects was assumed to be asynchronous. So I think we need message passing, with immutable messages. Send and Forget. As in the Actor model. See Object Oriented Programming: The Wrong Path? I think that it would be good to have static typing, so errors are catched earlier in the development cycle. But I would use type inference as in Haskell, so that the developer don't need to write the type everywhere in the code as in C, C# and Java. See Learn You A Haskell for Great Good I would also design a great UI library, with declarative layout, as in WPF and Android. But I would like to have it as in Functional Reactive Programming.  So my language would be like the concurrency in Erlang but with the typing as in Haskell and a GUI framework as in WPF.NET. "
    },
    {
        "ID": "492",
        "Question": "Did you learn to touch-type when you were already working as a programmer?  If so how did it affect your productivity?  Or are you still unable to touch type and do you think it holds you back? According to Steve Yegge it is essential, Personally I did not notice much difference, possibly because I was spending less than 25% of my work time actually typing (I was working on a large legacy project at the time and I was spending more time on reading and debugging existing code.) ",
        "Best answer": "Well, I said my piece on this here:  When you're a fast, efficient typist, you spend less time between thinking that thought and expressing it in code. Which means, if you're me at least, that you might actually get some of your ideas committed to screen before you completely lose your train of thought. Again.  Personally, I can't take slow typists seriously as programmers. When was the last time you saw  a hunt-and-peck pianist? "
    },
    {
        "ID": "500",
        "Question": "Rather than slavishly pair program all the time, we use pair programming selectively on our team. I think it works best in the following circumstances:  Ramping up brand new team members on a project (instead of letting them wade through documentation or code on their own). Having junior and senior people work together (helps to show some of the skills and tricks of the more experienced developers, plus it allows the old dogs to learn new tricks sometimes). When someone is trying to track down a defect, it often helps to pair with a fresh set of eyes.  When to use pair program and why? When to avoid pair programming? Why? ",
        "Best answer": "I have never worked in a \"Pair Programming\" setup and yet I can claim to have been a part of the three circumstances you've listed. The scenario you mention seems more \"regular programming\" with phases of helping / training thrown in. Did we not do all of this before \"pair programming\" came into being? Pair Programming, I'd assume would require a more committed approach where the process of sharing within a team doesn't stop the minute you tackle the immediate task or problem at hand. But then this is what I \"think\" not what I \"know\". Personally for Pair Programming I'd like to work in a team where I get a chance to learn and share my knowledge. An unbalanced team where everyone you work with is miles ahead of you, or then way below par can get quite uninteresting quite quickly. Also, I'd be afraid to work with people who are set in their beliefs and hard to convince. "
    },
    {
        "ID": "501",
        "Question": "No matter how much you love a programming language, there are always a few details in it that aren’t quite as nice as they could be. In this question, I would like to specifically focus on syntax elements. In a programming language that you use frequently (perhaps your favourite programming language, or perhaps the one you are forced to use at work), which syntax element do you find most unreadable, unclear, inconvenient or unpleasant? ",
        "Best answer": "Semicolon insertion in JavaScript. I haven't really been bitten by it often, but it's just such a phenomenally bad idea it makes my head spin.  Here's the rules (from ECMA-262 Section 7.9)  When the program contains a token that is not allowed by the formal grammar, then a semicolon is inserted if (a) there is a line break at that point, or (b) the unexpected token was a closing brace. When the end of a file is reached, if the program cannot be parsed otherwise, then a semicolon is inserted. When a \"restricted production\" is encountered and contains a line terminator in a place where the grammar contains the annotation \"[no LineTerminator here]\", then a semicolon is inserted.    Example: return 1; // returns 1  return 1; // returns undefined  "
    },
    {
        "ID": "502",
        "Question": "I think everyone has their own program or set of features beyond \"Hello World!\", that they use when trying out a new language. Mine is a guessing game: I'm thinking of a number 1-10, guess what it is! Guess: 3 Nope, too low! Guess: 7 Nope, too high! Guess: 5 Yes, You win! Play again (Y/N)? N  What do you write? ",
        "Best answer": "It usually goes like this:  Hello World Hello [user inputted name] A few problems from Project Euler A linked list A simple blog engine (either terminal or web-based, depending on what language) And from there I dive into a project that I want to work on (but don't care if the design gets mangled as I learn my way through a new language).  "
    },
    {
        "ID": "507",
        "Question": "I have seen this on the SO on many times. Whenever a question is vague and the question is asking some magical answer somebody or the other leaves a comment saying answer is 42. Even a book I am reading right now uses '42' as the number whenever it wants demonstrate some basic concept using an integer. So is there any history behind it or it is just a coincidence? ",
        "Best answer": "It's the answer to Life, The Universe, and Everything from Douglas Adams' Hitchhiker's Guide to the Galaxy. "
    },
    {
        "ID": "558",
        "Question": "I am a moderately capable web developer. I can put stuff where I want it to go and put some JQuery stuff in there if I need to. However, if I am making my own website (which I am starting to do) I have no idea how to design it. If someone was to sit next to me a point to the screen and say \"put this picture there, text there\" I can do that quite easily. But designing my own site with my choice of colours and text will look like a toddler has invented it. Does anyone know any websites/books I can look at or has anyone got any tips on the basics of non-toddler web design? ",
        "Best answer": "You have a few things to do. Tips: Learn to use Photoshop. (In particular, layer styles are excellent. Just note that they can be difficult effects to reimplement in CSS2) It goes a long way towards making good mockups.  Look at professionally designed sites. What sites have you been to that look nice to you?   Find sites that bother you and consider what could make it better. Look at product advertisements as well. Food packaging. Newspaper ads. You name it.  Also, once you start getting the hang of it, practice, practice, practice. Graphics takes time to develop as a skill, especially from a programmer who has coding to consider. (Gradients vs \"tileability\")  Tools: (Photoshop is a personal favorite. Paint.NET is a good Windows alternative, but is not quite as powerful.) Nathan Smith's 960 grid system. It has templates for many of the mainstream graphics programs. Check it out. References: Look at some of these sites: (I've seen more, I'll try to add as I come across them)  A List Apart John McCain BarackObama.com  Hayon2010.com (Okay, I made this one, but I think that it's nice. edit: I'd appreciate comments on it too. ;-D)  "
    },
    {
        "ID": "566",
        "Question": "goto is almost universally discouraged. Is using this statement ever worthwhile? ",
        "Best answer": "This has been discussed several times on Stack Overflow, and Chris Gillum summarized the possible uses of goto:  Cleanly exiting a function Often in a function, you may allocate resources and need to exit in multiple places.  Programmers can simplify their code by putting the resource cleanup code at the end of the function all all \"exit points\" of the function would goto the cleanup label.  This way, you don't have to write cleanup code at every \"exit point\" of the function. Exiting nested loops If you're in a nested loop and need to break out of all loops, a goto can make this much cleaner and simpler than break statements and if-checks. Low-level performance improvements This is only valid in perf-critical code, but goto statements execute very quickly and can give you a boost when moving through a function.  This is a double-edged sword, however, because a compiler typically cannot optimize code that contains gotos.  I'd argue, as many others would argue, that in all of these cases, the usage of goto is used as a means to get out of a corner one coded oneself into, and is generally a symptom of code that could be refactored. "
    },
    {
        "ID": "570",
        "Question": "All but the most trivial programs are filled with bugs and so anything that promises to remove them is extremely alluring. At the moment, correctness proofs are code are extremely esoteric, mainly because of the difficultly of learning this and the extra effort it takes to prove a program correct. Do you think that code proving will ever take off? ",
        "Best answer": "Not really in that sense, but pure functional programming is good in this domain. If you use Haskell, it's likely that your program is correct if the code compiles. Except from IO, a good type system is a good help. Also programming to contract can be helpful. See Microsoft Code Contracts "
    },
    {
        "ID": "604",
        "Question": "on a widescreen monitor one can easily see more than 80 characters at a time, without scrollbars. even linus torvalds sees the 80 character limit as outdated. so, is the 80 character limit still relevant in times of widescreen monitors? ",
        "Best answer": "If I keep my lines to less than about 100 characters, I can have two editor windows side-by-side on a widescreen monitor.  It's very useful to have both the class header file and implementation both visible at the same time, or have code on one side that calls into the code on the other.  And, if I keep the lines short, I don't need a horizontal scrollbar on my editor windows, which gives me more vertical space. 80 characters may be outdated, but there's some merit in keeping things within reason. "
    },
    {
        "ID": "616",
        "Question": "When I am in a code or design rut, I tend to find a non-dev coworker to discuss the problem with. It forces me to explain the problem in great detail and I'll usually find something I missed in the process. What are your \"unsticking\" methods? ",
        "Best answer": "Some of my tactics:  Explain the problem to someone, or even no one.  My girlfriend used to explain problems to a potato she kept. Work on something else for a bit (if opportunity allows)- some other functionality or even another project.  Get your ming off the current project.  A lot of times problems that seem impossible at 4:30pm seem trivial at 9:30 am the next day. Go to the pub (if possible).  Same principle as above. Beat your head against it.  This isn't often that productive for solving the problem, but at least for me, I tend to learn a lot.  If my gridview isn't auto-sorting, I'll try and read everything I can about the problem.  It'll still take me 3 hours to solve a stupid error on my part, but by the end, I'll have learned everything there is to know about gridviews and how they bind to data- I'll be able to solve any number of similar problems in the future. Get another input- preferably someone who knows at least something about the context of the project.  Most of my errors are stupid ones that only require a few minutes from a second set of eyes to solve where it would take me hours. Isolate the problem.  I keep a folder labeled \"proof of bugs\" where I keep a pile of project that each reproduce a specific issue outside the overall context of the large, complex project.  This can be a little time consuming, but it allows you to narrow down the cause of the issue independent of the bazillion interfering factors of a large project.  "
    },
    {
        "ID": "678",
        "Question": "I know some people are massive proponents of test driven development. I have used unit tests in the past, but only to test operations that can be tested easily or which I believe will quite possibly be correct. Complete or near complete code coverage sounds like it would take a lot of time.  What projects do you use test-driven development for? Do you only use it for projects above a certain size? Should I be using it or not? Convince me!  ",
        "Best answer": "Ok, some advantages to TDD:  It means you end up with more tests.  Everyone likes having tests, but few people like writing them.  Building test-writing into your development flow means you end up with more tests. Writing to a test forces you to think about the testability of your design, and testable design is almost always better design.  It's not entirely clear to me why this happens to be the case, but my experience and that of most TDD evangelists seems to bear it out. Here's a study saying that although TDD takes a bit longer to write, there's a good return on investment because you get higher quality code, and therefore fewer bugs to fix. It gives you confidence in refactoring.  It's a great feeling to be able to change one system without worrying about breaking everything else because it's pretty well covered by unit tests. You almost never get a repeat bug, since every one you find should get a test before it gets a fix.  You asked to be convinced, so these were benefits.  See this question for a more balanced view. "
    },
    {
        "ID": "729",
        "Question": "As programmers we have a lot of inputs:  Ebooks  Code snippets  Interesting emails  Documents Web articles  Blog posts StackOverflow questions Podcasts ...  Which tools do you use to store, organize, search and consult all of this stuff? Is there a silver bullet solution to handle this huge amount of data?  ",
        "Best answer": "I've started blogging about things I've learned.  Just a simple free blog, I keep it private, if it's worth sharing I'll spend some time to transform it into a post that's intelligible enough someone else can read it and walk away with something. You can tag ideas and search by grouping later too. Also helpful for creating an online identity for employment sake. "
    },
    {
        "ID": "739",
        "Question": "What is the recommended  User Account Control (UAC) setting when developing on Windows? Even on Win7 I find it annoying enough to turn it off (because it makes me more productive with it off) but sometimes I feel bad because I know I'll find more problems in my code if I leave it on. ",
        "Best answer": "The recommendation (even from Microsoft) is to leave it ON, and also to run your IDE unelevated whenever possible. First of all, it forces the programmer to live with the same \"annoyances\" a real world user will have (if you don't know it, would you program correctly around it?). Then, disabling UAC and working as an administrator is as bad as in Unix to work as root (decades of common wisdom will tell you why that's bad). "
    },
    {
        "ID": "745",
        "Question": "What methods do you use to stay awake and alert while working? Personally I drink coffee non stop throughout the day.  But I've also heard of this thing called exercise that should help too.  Does anyone else have tips and tricks to stay more awake and alert while working?  Redbull? Maybe a magic pill that won't require me to sleep? ",
        "Best answer": "Caffeine is a major cause of the problem, not the solution.  It might seem to work in the short-term but it makes things worse overall by interfering with your sleep. If you don't sleep properly you will be tired and unfocused.  If you try to solve that with a high caffeine intake you won't sleep properly. Exercise, eat well, try to restrict the coffee to a couple of cups a day and don't work stupid long hours. "
    },
    {
        "ID": "750",
        "Question": "I'm freshly out of college, and starting university somewhere next week. We've seen unit tests, but we kinda not used them much; and everyone talks about them, so I figured maybe I should do some. The problem is, I don't know what to test. Should I test the common case? The edge case? How do I know that a function is adequately covered? I always have the terrible feeling that while a test will prove that a function works for a certain case, it's utterly useless to prove that the function works, period. ",
        "Best answer": "My personal philosophy has thusfar been:  Test the common case of everything you can.  This will tell you when that code breaks after you make some change (which is, in my opinion, the single greatest benefit of automated unit testing). Test the edge cases of a few unusually complex code that you think will probably have errors. Whenever you find a bug, write a test case to cover it before fixing it Add edge-case tests to less critical code whenever someone has time to kill.  "
    },
    {
        "ID": "756",
        "Question": "I'm trying to find places where I can hone my craft outside the context of school or work. Are there places online, or books available, where I can access lists of programming puzzles or challenges? ",
        "Best answer": "Moderator note: this is intended to be a canonical list; please check to see if your suggestion has already been added to the answer. If it hasn't, edit the answer to add yours, preferably with an explanation or reason why you're suggesting it. On Stack Exchange Pick a tag, follow the new questions posted, and try to solve them. If you find a good one, bookmark it for later use:  Stack Overflow Code Review Community Challenges Programming Puzzles and Code Golf Solve algorithmic and datatypes problems  Books  Algorithms for Interviews by Adnan Aziz Cracking the Coding Interview (6th Edition) by Gayle Laakmann Programming Challenges by Steven S. Skiena The Art of Computer Programming by Donald E. Knuth  Communities and Blogs  Algorithm Geeks Google Group CodeKata LessThanDot's Programmer Puzzles forum The Daily WTF's Bring Your Own Code series /r/dailyprogrammer  Game sites and ongoing contests  Codingame - fun games (solo and multiplayer) to practice your coding skills. Supports 25+ programming languages. CodeChef Code Combat - Javascript and Python solo and multiplayer games in the style of a strategy game. Hacker.org Challenge — \"The hacker.org challenges are a series of puzzles, tricks, tests, and brainteasers designed to probe the depths your hacking skills. To master this series you will need to crack cryptography, write clever code, and dissect the impenetrable; and in the process you will enrich your understanding of the world of hacking.\" Pex for fun — game from Microsoft research where you duel against other programmers Rankk — \"You start with the easy levels and progress to the intermediate and hard levels by solving the minimum number of required challenges at each level. The journey to the top is an arduous yet rewarding one. You need to be sufficiently determined and persevering to go far. Only a few are expected to reach the apex and attain Geb.\" TopCoder Google Code Jam—algorithmic puzzles  Language specific  4Clojure (Clojure) — \"4Clojure is a resource to help fledgling clojurians learn the language through interactive problems. The first few problems are easy enough that even someone with no prior experience should find the learning curve forgiving. See 'Help' for more information.\"  Prolog Problems (Prolog) — \"The purpose of this problem collection is to give you the opportunity to practice your skills in logic programming. Your goal should be to find the most elegant solution of the given problems. Efficiency is important, but logical clarity is even more crucial. Some of the (easy) problems can be trivially solved using built-in predicates. However, in these cases, you learn more if you try to find your own solution.\"  Python Challenge (Python) — \"Python Challenge is a game in which each level can be solved by a bit of (Python) programming.\"  Ruby Quiz (Ruby) - \"Ruby Quiz is a weekly programming challenge for Ruby programmers in the spirit of the Perl Quiz of the Week. A new Ruby Quiz is sent to the Ruby Talk mailing list each Friday.\"  IOCCC (C) - \"A contest to write the most obscure/obfuscated C program. (Fun to try to understand the previous year's entries, or to submit a new one.)\"  Underhanded C Contest (C) - \"contest to turn out code that is malicious, but passes a rigorous inspection, and looks like an honest mistake. (Try to understand previous year's entries, and learn to find similar mistakes in other people's code)\"  CheckiO - Python programming challenges. Custom \"Missions\" can be created by members.  109 Python Problems for CCPS 109 Python problems of various levels of difficulty, with an automated pseudorandom fuzz tester to verify that the functions are correct.   Online judges / automatic assessment  Codingbat has lots of coding challenges ranging from warm-ups to Harder recursion problems. It is available in Java and Python. Cyber-dojo has a nice variety of katas and supports a good selection of languages. It is intended to support doing deliberate practice of TDD, but could be used for personal development too. LeetCode Peking University JudgeOnline for ACIP/ICPC Sphere Online Judge University of Valladolid Online Judge Codewars — Training with code challenges. Rosalind algorithms and bioinformatics Quizful - interactive programming quizzes in \"Duolingo style\". This site looks fun and has a good set of questions, at least in Java. Plus, as they say, it has adaptive learning algorithm, that makes learning more effective. exercism - Challenges in more than 30 languages that will be evaluated automatically.  Problem lists and contest archives  ACM/ICPC Problem Index @ HIT — List of problems from the ACM International Collegiate Programming Contest Algorithmist — Includes lists of algorithms and other puzzle sites Career Cup — Collects community-subumitted interview questions from various tech companies Educational Computing Organization of Ontairo's past computer programming puzzles Engineering Puzzles at Facebook — Puzzles provided for the purposes of evaluating potential hires Google Code Jam contest archives Ninth Annual ICFP Programming Contest Task archive Ponder this at IBM Research — Puzzles provided for the purposes of evaluating potential hires Programming Praxis Project Euler Rosetta Code TopCoder Match List International Olympiad in Informatics - yearly contents for teams of students. (previous year's problem sets)  Security oriented  Smashthestack gera's insecure programming challenges  "
    },
    {
        "ID": "778",
        "Question": "What question have you found especially valuable in interviewing software developers?  What is it about the question that has made it particularly useful? I'm looking for a particular question you like to ask, not just an interviewing approach like \"make them write code\". ",
        "Best answer": "Take a look at this sample code and tell me how you'd improve it. "
    },
    {
        "ID": "779",
        "Question": "It doesn't have to be programming or software development related, but just asked during an interview for an IT related job. I know some \"left field\" questions are meant to see how the candidate copes with unexpected and novel situations, but here I'm looking for a question that appeared to be completely unrelated to the job they were interviewing you for, or something that made you think \"what useful information could they possibly get from my answer to that question?\". ",
        "Best answer": " Where do you see yourself in 5 years?  Do they really think people are dumb enough to say that they want to do something completely different? Or don't want to work for them? I guess it can be useful as an indicator of who not to hire but it's so stupid easy to fake that you can't use it as an indicator of who to hire in any way if they answer correctly. "
    },
    {
        "ID": "811",
        "Question": "Literate programming has good ideals. Why do you think that this isn't mainstream? It is because it has failed to deliver? ",
        "Best answer": "I first saw it in a book of Knuth's writings, and thought it looked neat.  Then I tried to use the literary programming display to comprehend what was going on in the program, and found it harder than it looked.  It may have been that I was too used to going through program listings, but it seemed confusing. Then I looked at the source code, and that turned me off then and there.  I'd have to learn to write programs in an entirely new way, with less correspondence between the program text and what the compiler saw, and saw no corresponding benefit. In addition, people can write long and convincing arguments that the code is doing X when it's actually doing Y, and I've run into my share of misleading comments.  I developed a fondness for reading the code to see what it's doing fairly early.  Literate programming is the antithesis of that. "
    },
    {
        "ID": "843",
        "Question": "I was instructed by my project manager that frequent deployment in PROD or to test server should be avoided. But I don't understand why? We roll our testing copy to PROD on every sprint end but suddenly client would ask a simple change to the existing application which would require a re-deployment. When every thing was well tested and QA approved. why should we avoid frequent deployment? How it was done universally? ",
        "Best answer": "If you are talking about a hosted web application, the users don't get a say-so in when they get upgrades. That is, they are forced to upgrade each time you do a push to production. If your changes dramatically change the system rules or UI, you should definitely consider bundling your releases and doing it less frequently. It is very frustrating to users to have to continually re-learn how to use the tools they rely on and violates the UI principle of making them feel they are in control of their computer/software. "
    },
    {
        "ID": "866",
        "Question": "I know this is obviously not true for some games, minesweeper, card games, etc.  But what about any game involving simulating the real world environment.  Obviously these games have some form of a physics engineer powering the graphics.  For someone like me who personally did not enjoy physics but loves video games, do I have a chance at ever getting involved in the development cycle of a video game such as this while disliking physics?  ",
        "Best answer": "There are many aspects to game programing and you don't need to be an expert at all of them.  If you're on a bigger team you may not even be doing the core game programming but just network communication for example.  For core game programming I would think that above a sound physics understanding you would need a strong mathematical background.  Having a strong mathematical background will allow you to do things like modelling transformations, clippings, keyframe animation, ray tracing, image processing, texture mapping, etc. Having a strong physics background may help you with coming up with new computer graphics methods, but it is not required if you want to become a game programmer.  "
    },
    {
        "ID": "870",
        "Question": "One per answer please. I'll add my favourite as an answer. ",
        "Best answer": " Code Complete by Steve McConnell. I don't even think it needs explanation. It's the definitive book on software construction. Incredibly well written and covers all aspects of the practical (programming) side of creating software.  "
    },
    {
        "ID": "937",
        "Question": "I know that they are implemented extremely unsafely in C/C++. Can't they be implemented in a safer way? Are the disadvantages of macros really bad enough to outweigh the massive power they provide? ",
        "Best answer": "I think the main reason is that macros are lexical. This has several consequences:  The compiler has no way of checking that a macro is semantically closed, i.e. that it represents a “unit of meaning” like a function does. (Consider #define TWO 1+1 — what does TWO*TWO equal? 3.) Macros are not typed like functions are. The compiler cannot check that the parameters and return type make sense. It can only check the expanded expression that uses the macro. If the code doesn’t compile, the compiler has no way of knowing whether the error is in the macro itself or the place where the macro is used. The compiler will either report the wrong place half of the time, or it has to report both even though one of them is probably fine. (Consider #define min(x,y) (((x)<(y))?(x):(y)): What should the compiler do if the types of x and y don’t match or don’t implement operator<?) Automated tools cannot work with them in semantically useful ways. In particular, you can’t have things like IntelliSense for macros that work like functions but expand to an expression. (Again, the min example.) The side-effects of a macro are not as explicit as they are with functions, causing potential confusion for the programmer. (Consider again the min example: in a function call, you know that the expression for x is evaluated only once, but here you can’t know without looking at the macro.)  Like I said, these are all consequences of the fact that macros are lexical. When you try to turn them into something more proper, you end up with functions and constants. "
    },
    {
        "ID": "940",
        "Question": "This is more a discussion question than an actual attempt to determine the \"best\", since that clearly varies by the needs of the organization. I'm more curious about the arguments in favor of different systems across categories (centralized vs distributed, open vs proprietary, etc). So, what do you think is the best version control system? ",
        "Best answer": "Mercurial Because of it's sophisticated ability to branch and merge code, it is the best I've used. The whole DVCS paradigm just makes so much sense. I've not used Git, but I suppose that it qualifies as well.  "
    },
    {
        "ID": "966",
        "Question": "There are a lot of questions about what programming books should be on the programmer's bookshelf. How about non-programming related books that can help you become a better programmer or developer? It would also be interesting to know why they would help. My first choice would be Sun Tzu's \"Art of War\" (however cliché), because it made it obvious that the success of any project depends on the strength of its weakest link (and warfare is a big project). ",
        "Best answer": "The Design of Everyday Things by Donald Norman  "
    },
    {
        "ID": "991",
        "Question": "What are the first 5 things you do before starting a new project? Do you always spend a day researching new frameworks? Or, using similar or competing products? ",
        "Best answer": "This is pretty project-dependent.  Is this a project I'm starting with the intent of selling, or a project for a specific customer?  Also, what constitutes \"starting\"? Is that before or after requirements gathering? A rough list, though:  Get a context for the project.  That is, figure out what your customer or potential user is trying to accomplish and why.  If you're building a hotel registration system, what's wrong with OTS options, for example. Gather requirements.  Meet with stakeholders.  Meet with users.  Meet with anyone who has a say in the project, if you can.  Look at existing solutions that this project will replace, either that the customer is using or that exist in the market place.  From there, write it all down in a non-technical language as you can- a good reqs doc should describe what's to be done but not how to do it.  Then discuss this doc with the customer and iterate until they agree with it.  This step can be less formal for smaller projects (possibly even entirely verbal). Start making technical decisions.  Pick languages, frameworks, ORMs, databases, etc that best solve the problem, whether this means sticking with something you know or learning something new. Analyze the risks for this project.  If this is a government contract, you probably want a 100 page leather-bound risk report.  If it's a 3-man 4-month project, you might be fine with some notes in a text file or a spreadsheet.  Either way, you want to figure out what can go wrong with the project, how likely it is to happen, how much it'll hurt, and what you are going to do to prepare for it, handle it, and/or mitigate it's effects after the fact.  A common one, for example, is \"One of the devs gets hit by a bus, quits, gets sick, etc.\"  So you might mitigate that by pair programming to share knowledge, using good source control practices to keep code centralized, etc.  Overall, the process of sitting and thinking about what could go wrong and being prepared for the possibilities is more important than actually writing out all the contingency plans. Set up the technology.  It's the sort of thing that no one wants to do once you're in the thick of actually coding, so set up your repo, your build server, your build system, your wikis, your bug tracker, or whatever you intend to use for your project.  "
    },
    {
        "ID": "1007",
        "Question": "Tester and blogger Lanette Creamer recently posted this question on Twitter:  If you are a professional software developer who works with testers, think of the best testers you know. What traits do they have in common?  I thought it would make an excellent question for here. My thoughts are:  They want to remove ambiguity from requirements even if it means asking awkward questions. They create new features by seeing the way software \"should\" work, rather than just how it's documented. They demonstrate honesty and integrity and encourage but not demand it from those around them. In other words, they model behavior.  What are the traits of the best testers you've worked with? ",
        "Best answer": "Some of the best testers I've worked with really understand how the users are going to use the software.  They understand what business function the software is supposed to play and how that software will effect the user's role/job/function.  It makes for a successful project when the tester has as much knowledge of the business as the developer and the business owner. "
    },
    {
        "ID": "1009",
        "Question": "I'd like to sell my software on the 'net but am not sure how to do the whole Merchant setup.  I have access to Commerce Server 2009, and I want to seem professional so a plain old PayPal account is out. What do I need to know/do to sell a few things using ASP.NET, accept credit cards, and what not?  ",
        "Best answer": "Definately use a 3rd party vendor at first.  There's a lot of shareware and software sales services that will handle the whole process of purchase and download.  Then once you get sales going and have an idea of what type of revenue you are generating, you might look at implementing a store of your own on your site.  What you dont want to do is bite off too much to chew at one time.  Releasing a new product is tough enough, you dont want to compound that by having to learn all about credit card processing & sales/vat taxes, and maintaining your own store.  Nor do you want to invest a large amount of time up front doing all that if it turns out no one is buying your software. "
    },
    {
        "ID": "1025",
        "Question": "I'm considering learning iPhone development and Objective C but don't want to avoid developing something for the most saturated markets and app categories. What categories should I avoid?  Are there too many dating applications, or should I just stick to coming up with a creative game or two? ",
        "Best answer": "The iOS market has way to many apps in general. Try to make an iPad app. There are less iPad apps out than iPhone/iPod touch.  Alternatively, try to make something for a particular (local) business. That way you are guaranteed to get paid (by the business) and you get an app out there that is unique. Games are always good, provided that the gameplay attracts people. Like the speakers at the WWDC 2010 said, watch play testers as they do their thing. It helps a lot with your game development. "
    },
    {
        "ID": "1058",
        "Question": "I'm not exactly sure when to use Enterprise Library, and when not to... and that is making me not learn it at all.  I feel that I have enough of a reason to start learning then perhaps one day I'll use it. Are there times when I should use EntLib? When shouldn't I use it?   ",
        "Best answer": "I've used EntLib for many years (since they were indiviual App Blocks).  I've found that at times it can be pretty heavy as far as the size of the components, especially if you only need one block and it needs to be downloaded.  Often I'll use the Data and Logging components together and that feels like enough functionality to justify the size.  If your app is strictly on the server side then this really isn't too much of an issue.  One of the things that is nice about it is that if you need more than one block you don't have to go to multiple implementations from multiple vendors that are configured in different ways.  They also provide a tool to help with the configuration (that's a plus and a minus, a plus that they make it easy, a minus that they NEED a tool to help configure it). I've had the pleasure of being invinted to a couple of Patterns and Practices workshops where I was working side by side with the team members who wrote EntLib.  The intent in creating EntLib was to implement Microsoft's Best Practices in common components that everyone needs that are not part of the base Framework.  They are very stable, provide very good performance and very good flexibility. I would start by using some of the easier blocks, like Data and Logging.  They're not too hard to configure and get started with.  Then once you understand those it will be a bit easier to move on to some of the other blocks.  I have not found a situation where you shouldn't use them, other than when you don't need them. "
    },
    {
        "ID": "1059",
        "Question": "I have often heard it said that objects have not delivered in terms of code reuse. Do you agree? If you believe that they haven't, why not? ",
        "Best answer": "No, not necessarily. Objects deliver better semantics, organization of code/functionality and, possibly, ease-of-use. Well designed libraries deliver on the promise of code reuse, not objects per se. "
    },
    {
        "ID": "1060",
        "Question": "Aspect oriented programming promises to deal with cross cutting concerns, but I'm not completely sold on it yet. Have there been any other attempts to deal with this problem? ",
        "Best answer": "When possible, you can encapsulate cross-cutting concerns into separate modules that are then used throughout the app via dependency injection.  This allows you to somewhat decouple the cross-cutting concern implementation from it's use throughout the code. This doesn't always work elegantly, though.  That's the reason people are trying to address the issue with things like AOP. "
    },
    {
        "ID": "1063",
        "Question": "I have often wondered if it would be possible to write a programming language that would work as a conversation. I would tell the computer that I want to store coordinates and it would ask what representation I would use. I would then ask to find the shortest path between points and it would ask if I want to use Djkstra's, brute force or use Floyd's? What research has been done towards producing a system like this? ",
        "Best answer": "I think such a language would need an artificial intelligence in place, or at least a system that can learn. The problem is that humans don't know what they want. Also, even writing in classical imperative language we still make logical errors. Imagine trying telling a non-intelligent software what he has to do. "
    },
    {
        "ID": "1065",
        "Question": "I'm comparing different STS's for claims based authentication and am trying when it's appropriate to use each one.   It appears that ADFSv2 should be used in all Windows Environments.  Ping and Siteminder are more for the Unix side... although a sales rep said Ping was better for Windows, I didn't really understand \"why\" Any comparative information is much appreciated! ",
        "Best answer": "We are in the middle of doing SSO where I'm at right now.  We couldn't get Site Minder to let us pay for a developer license; they literally didn't return the numerous calls we made begging to use their software (one of our clients was using it and we figured it would be the easiest path). We went with Ping Identity's Pingfederate product (or is it the other way around)? The documentation isn't amazing, but it's working for us.  When you can get past first-level support, they have been very helpful and getting us going.  Your application will be dependent upon their APIs, but your application will also support numerous open standards for SSO.  They also have consulting available to do the heavy lifting if you have the budget. "
    },
    {
        "ID": "1090",
        "Question": "Language shortcuts can often be used to make code more concise. For example, ternary and null coalescing operators can reduce the amount of code, but arguably to the detriment of readability: In C#: Person newGuy = new Person(); if (boss == null) {     newGuy.Boss = GetDefaultBoss(); } else {     newGuy.Boss = boss; }  is functionally equivalent to: Person newGuy = new Person(); newGuy.Boss = boss ?? GetDefaultBoss();  but obviously a lot more verbose. Where do you draw the line when it comes to conciseness vs readability? ",
        "Best answer": "Both. Your first example is certainly more verbose, and arguably more explicit... but it also requires me to scan five lines instead of one. Worse, it deemphasizes its purpose - assigning a value to newGuy.Boss. Your second example may cost me a second if I'm unfamiliar with the null coalescing operator, but there can be no doubt as to its purpose, and if I'm scanning through a larger routine looking for the source of a value, it will be much easier for me to pick this one out. Now, contrast this: if (boss == null) {     newGuy.Boss = GetDefaultBoss();     newGuy.IsTemp = true;     newGuy.AddTask(\"orientation\"); } else {     newGuy.Boss = boss;     newGuy.IsTemp = false; }  ...with: newGuy.Boss = boss ?? GetDefaultBoss(); newGuy.IsTemp = boss == null; if ( boss == null ) newGuy.AddTask(\"orientation\");  The latter example is again much shorter, but now it obscures its purpose by making tasks triggered by the same test appear to be distinct. Here, I feel the verbosity of the former is justified. "
    },
    {
        "ID": "1095",
        "Question": "I used ad-hoc MUML (made-up modeling language) to design and explain system fairly frequently.  It looks similar to UML and tends to be pretty well understood. However, I've had a professor or two that harped on the use of strict, formal UML, as close to the spec as possible.  I always suspected that strict UML wasn't really as common as they claimed.  So, how 'bout it- how often do you actually draw out complete diagrams that use all the proper line endings, multiplicity, member type symbols, etc? ",
        "Best answer": "Never. Heck, it's been years since I last created any UML. Line diagrams on whiteboards and scraps of paper don't count. In fact, we just removed the sole UML question from the guide we use during interviews, because none of us really cared about the answers. "
    },
    {
        "ID": "1180",
        "Question": "I've been in workplaces where, at the start of a project, the \"Should we use VB.Net or C#\" question has been raised. Granted, it's probably less common to have to make that decision now than it was in the early days of .Net, particularly given the trend towards language convergence, but it can still be a heated debate. So, between VB.Net and C#, Which language do you prefer and why? ",
        "Best answer": "I prefer C# over VB.NET because  it's easier to find programmers/jobs:    it's easier to find help:   (from stackoverflow) "
    },
    {
        "ID": "1189",
        "Question": "By now I work with asp.net and C#. I have done a decent work in Java as well. I am planning my career in such a way I should be language-agnostic someday. What are the things that I need to learn?  First would OOP paradigms as its speaks about the Class design. Are there any others? ",
        "Best answer": "To be language agnostic you need to have experience in all of the common styles and types of languages.  An imperative language (You tell it what to do, step by step. Eg - C) A declarative language (You tell it your goal, it figures out what to do. Eg - SQL/HTML/Prolog)  Also:  A functional language (Functions are key, avoiding state and side effects are the goals. Eg - Haskell/OCaml/Lisp/F#) An object oriented language (Architecture where objects encapsulate related data and the methods that act on them). Eg - Java/C#)  Some typing styles:  A statically typed language (Data types are defined and checked at compile time. Eg - C#) A dynamically typed language (Data types are checked at runtime. Eg - Python/Javascript) Experience of strong vs. weak typing is also useful.  Some different runtime styles:  Something compiled (Eg - C++) Something interpreted (Eg - PHP) Something Managed (Eg - C#/Java)  Lower level stuff:  Something fairly low level (Eg - C) Some dialect of assembly (Eg - NASM)  On top of that I would say you need experience of some concurrent programming and something event driven. You should probably also make sure you know something about the various domains such as web programming (client & server), rich client development/desktop, games. You might also want to learn about embedded programming, or dedicated hardware (like games consoles), and mobile development is becoming an increasingly relevant domain. Others have also mentioned that it's worth getting some experience of Generic programming and Meta programming approaches. When you learn these paradigms avoid just learning the syntax and writing in your old style. I've seen many C# devs write JavaScript as if it's statically typed. Don't do this, try to learn the language paradigms and embrace them. If you've done all of this, the differences between languages will become largely syntactical so switching will become a fairly simple exercise of learning some new syntax. Don't forget though that modern programming is almost always dependant on a framework, so familiarising yourself with the common and popular frameworks for each language you learn is also critical. Knowing C# is irrelevant without .net.  "
    },
    {
        "ID": "1200",
        "Question": "Coming from a procedural/OO programming background, I tend to write Scheme programs in a procedural fashion. I would be intersted in learning Scheme or Lisp in a functional way from the ground up, to kind of reset my programmer's mind. Is there a tutorial or book out there that's the de-facto standard for describing best practices, design methodologies, and other helpful information on functional programming concepts? What about that book makes it special? ",
        "Best answer": "Use it. If you do functional programming daily, maybe smaller applications or exercises from books, then you will be better on it. I have used it since the first programming lecture in university. At the beginning it was very hard, because it is so different, but now I prefer it to imperative programming. If you are looking for a good book, I would recommend Real World Functional Programming: With Examples in F# and C# by Tomas Petricek and Jon Skeet "
    },
    {
        "ID": "1217",
        "Question": "I think we’ve all seen this. Beginners ask questions on Stack Overflow that follow the basic outline...  I’m trying to do (very vague description of the goal) but it doesn’t work/I get an error/exception. Please help!  Isn’t it bizarre that so many of them seem to consider it unnecessary to paste the error message? I wonder what the psychology of this is. What is it about error messages that makes people initially assume that they are useless and not worth paying any attention to? The answer I’m looking for is not “they don’t understand the error message”. That doesn’t explain why they wouldn’t consider telling anyone else who might understand it. ",
        "Best answer": "I think the real reason is that ordinary computer users, even if they should go on to become programmers, are conditioned to believe they can't do anything about errors. Think about it. What do non-programmer types do when they encounter a cryptic error message*? They might read it, but nine times out of ten they'll simply dismiss it and try again. Only if it consistently fails will they look it up. Therefore, when beginning to learn how to program, people don't immediately realise that the error they're getting contains useful information on how to fix it; and yea, though compiler errors can be nigh unreadable even to the trained professional (I'm looking at you, C++ template metaprogramming), at least they provide a general starting point, and once you've seen the same error a couple of times, you'll always know what you've done to cause it. *Honestly, though, most error messages look to Joe Average like \"Error X2412: Unable to establish frobnicatory interplatforming dongledash: please verify bandersnatch settings or contact your system administrator.\" "
    },
    {
        "ID": "1224",
        "Question": "I've never found the ideal way to perform code reviews and yet often my customers require them. Each customer seems to do them in a different way and I've never felt satisfied in any of them.  What has been the most effective way for you to perform code reviews? For example:  Is one person regarded as the gatekeeper for quality and reviews the code, or do the team own the standard?   Do you do review code as a team exercise using a projector? Is it done in person, via email or using a tool?  Do you eschew reviews and use things like pair programming and collective code ownership to ensure code quality?  ",
        "Best answer": "I like code reviews, though they can be a pain.  The reason I like them is that they get more eyes on the code and a different perspective.  I believe that even with pair programming, code should be reviewed.  It's easy enough for two people working on the same code to collectively make the same mistake that a different set of eyes may not miss. If done as a group with a projector, it really should be reviewed individually before the meeting.  Otherwise, it is just an annoying waste of time.   I've only done code reviews via email and in a group.  Generally speaking, I don't think they should be done in person.  You feel a little more pressure to rush through the code with someone looking over your shoulder.  I do believe that a tool designed for code reviewing would be a good asset, as it can help with some of the mundane aspects and it should make it easier to flag problem bits of code then it is via email. The problem with having one person do all code reviews is that it can be a bottleneck.  With well documented and designed coding standards it should not be necessary.  Depending on the environment/release-schedule it may be a good idea to always have someone as a standby code reviewer. I do believe that code ownership is a good idea as this person can make it their priority to understand that code and potentially play a gatekeeper role. "
    },
    {
        "ID": "1262",
        "Question": "I'm considering whether I should start using VIM again instead of an IDE. What are the most useful features of VIM that aren't standard in an IDE? ",
        "Best answer": "I don't think its necessarily the advanced features of VIM that make it so powerful. Its the fact that you never have to take your hands off the keyboard to do anything. Finding something in a huge file is as simple as a couple of keystrokes. Opening and closing multiple files in the same window is incredibly fast as well. While it may not seem intuitive at first, its well worth your time. Even if you don't use it as your standard IDE (I generally use Visual Studio or Eclipse, for example), you'll find your self using VIM to quickly open and edit files because it becomes way faster than waiting for the IDE to load. Invest the time to learn how to use VIM well and you'll never regret it. I'd say its comparable to learning to touch-type. "
    },
    {
        "ID": "1280",
        "Question": "What best practices should be undertaken for a website that needs to \"scale out\" to handle capacity?  This is especially relevant now that people are considering the cloud, but may be missing out on the fundamentals. I'm interested in hearing about anything you consider a best practice from development-level tasks, to infrastructure, to management. ",
        "Best answer": "Design for Concurrency That is, as you're coding, plan around having multiple threads going.  Plan the shared state (often just the db).  Plan for multiple processes. Plan for physical distribution. This allows you to distribute your system across multiple machines, and across multiple processes with load balancing.  It allows you to have redundant processes running in case of failure, and in case you need to modify the system in-place, you don't have to kill all service to do so. "
    },
    {
        "ID": "1323",
        "Question": "I recently saw that Microsoft released a coding standards document (All-In-One Code Framework Coding Standards) and it got me thinking...  The company that I work for has no formal coding standards at all.  There are only a few developers and we have been together long enough to have evolved into similar styles and its never been an issue. Does the company you work for have a documented coding standards?  If no, why not?  Does having a standard make a difference?  Is it worth writing a standard from scratch or should you adopt another standard as your own (ie. make Microsoft's standards yours)? ",
        "Best answer": "It's important for a team to have a single coding standard for each language to avoid several problems:  A lack of standards can make your code unreadable. Disagreement over standards can cause check-in wars between developers. Seeing different standards in the same class can be extremely irritating.  I'm a big fan of what Uncle Bob has to say about standards:   Let them evolve during the first few iterations. Let them be team specific instead of company specific. Don't write them down if you can avoid it. Rather, let the code be   the way the standards are captured. Don't legislate good design. (e.g. don't tell people not to use goto) Make sure everyone knows that the standard is about communication, and   nothing else. After the first few iterations, get the team together to decide.   "
    },
    {
        "ID": "1338",
        "Question": "Have you ever had to work to coding standards that:  Greatly decreased your productivity? Were originally included for good reasons but were kept long after the original concern became irrelevant? Were in a list so long that it was impossible to remember them all? Made you think the author was just trying to leave their mark rather than encouraging good coding practice? You had no idea why they were included?  If so, what is your least favorite rule and why?  Some examples here ",
        "Best answer": "Had a professor once who demanded we have at least one comment for each line of code. //Set x to 3 var x = 3;  //if x is greater than 2 if(x>2){      //Print x     Print(x); }  It was pretty ridiculous. "
    },
    {
        "ID": "1376",
        "Question": "I have a tester that while testing will have an error occur (ok so far), but then he frequently reports it right away.  We (the developers) then later find that the tester has not tried to reproduce the issue and (when asked) cannot find a way to make it happen again. Now these are still bugs, I don't want to ignore them.  But without repro steps I am kind of stuck.  Sometimes there is a stack trace (though frequently it is not useful because this is compact framework and there are no line numbers).  But when there is one I can take the stack trace and crack open the code and start guessing, but that does not lead to testable \"fixes\". What do you do in scenarios like this? ",
        "Best answer": "A bug without context is not a bug, it's a fluke. The problem could be your code, it could be a third party library, it could be the hardware, or it could be solar radiation causing a single bit to flip on it's own. If you can't reproduce it with at least some regularity (even if only \"it happens once every 10 or 20 times I do X\"), it's not much better than your tester telling you \"Something somewhere went wrong somehow - fix it\". You may have to explain to your tester that his job is not to just generate input until something breaks. If it were, you could replace him with a random number generator. Part of his job is to identify bugs, which entails identifying how to produce them. "
    },
    {
        "ID": "1380",
        "Question": "We are starting a push for code coverage here at my work, and it has got me to thinking.... How much code coverage is enough? When do you get to the point of diminishing returns on code coverage?  What is the sweet spot between good coverage and not enough?  Does it vary by the type of project your are making (ie WPF, WCF, Mobile, ASP.NET)  (These are C# classes we are writing.) ",
        "Best answer": "I'm of the opinion that code coverage alone is a poor metric.  It's easy to produce tons of useless tests that cover the code, but don't adequately check the output, or don't test edge cases, for example.  Covering code just means it doesn't throw an exception, not that it's right.  You need quality tests- the quantity isn't that important. "
    },
    {
        "ID": "1474",
        "Question": "I've read Peopleware in 2009. It was one of the best book I ever read. But this book is a little old. I'd like to know, in your opinion, what is and what is not relevant in this book? ",
        "Best answer": "It's been a while since I read it, but I don't remember anything in the book that wasn't relevant to someone. What stood out the most was the discussion of process improvement using CMM and CMMI, and no mention of agile processes (although the second edition was printed in 1999, which is a few years before the Manifesto for Agile Software Development and agile development went mainstream). But the book is about people, and people haven't changed that much since the first printing of the book in 1987. "
    },
    {
        "ID": "1483",
        "Question": "I've heard it said (by coworkers) that everyone \"codes in English\" regardless of where they're from. I find that difficult to believe, however I wouldn't be surprised if, for most programming languages, the supported character set is relatively narrow. Have you ever worked in a country where English is not the primary language? If so, what did their code look like? ",
        "Best answer": "I'm from Canada, but live in the States now. It took me a while to get used to writing boolean variables with an \"Is\" prefix, instead of the \"Eh\" suffix that Canadians use when programming. For example: MyObj.IsVisible  MyObj.VisibleEh  "
    },
    {
        "ID": "1533",
        "Question": "If you're developer (Senior or Lead Developer) and you'd rather stay with code/design than pursue a management career, what are the available career paths at your company, or any you've heard of? How far can you go? Is it possible to continue being a geek until you bite the dust or is that too naive? Are people like Uncle Bob for example still considered developers, as they claim? ",
        "Best answer": "At my company, the management and individual contributor tracks are separate and mostly parallel.  Individual contributors can rise very high in the company (up to Technical Fellow) without being a people manager.  It helps to partially avoid the Peter Principle, though never completely. "
    },
    {
        "ID": "1588",
        "Question": "Use of desktops are decreasing day by day in daily life but for coding purpose are there any reasons for using desktop over laptop?  ",
        "Best answer": "Assuming you have an external monitor and keyboard to connect to your laptop the difference is small.  It is always better to work in a desktop like setting (bigger screen realestate, more ergonomic environment), but you can't take your work with you without a laptop. So if portability is important, get a laptop and a good external screen and keyboard to connect it to. Otherwise you might as well stay with a desktop.  "
    },
    {
        "ID": "1620",
        "Question": "I am excited about the changes in PHP 6 previewed in PHP 5.3+. However, I wonder why it takes so long to release PHP 6? Books about it have been published since 2008, and announcements on it since 2007, but I am yet to hear about an alpha or a beta. Why does it take so long to release it? Or is that the way it goes with all languages when they transition to a major release where I guess it takes around 4-5 years to release? ",
        "Best answer": "The release timetable is not unusual for languages, and it's not even that unusual for PHP: 5.0 was released in 2004, but 4.0 was released in 2000.  Compare this to the last stable releases for C (2000), Fortran (2003), or C++ (2003). One other thing to keep in mind is that 5.3 was a major release in all but name. It adds a lot of stuff that was originally destined for PHP 6. Due to development problems with unicode support (a major part of PHP 6), it was decided to release what was stable at the time as a 5.x branch. "
    },
    {
        "ID": "1701",
        "Question": "I am currently reading the recently published Being Geek by Michael \"Rands\" Lopp and I can't get enough of it.  Is there any other career guidance books aimed directly or indirectly at programmers that are worth reading? ",
        "Best answer": " Code complete  The Pragmatic Programmer   "
    },
    {
        "ID": "1745",
        "Question": "To put it another way... What is the most commonly held and frustrating misunderstanding about programming, you have encountered? Which widespread and longstanding myths/misconceptions do you find hard for programmers to dispel/correct. Please, explain why this is a myth. ",
        "Best answer": "That because you're a programmer, you know how to fix [person]'s virus ridden machine. "
    },
    {
        "ID": "1752",
        "Question": "In fact this question is about cautions to be taken to enhance quality user experience and reduce avoidable support calls. ",
        "Best answer": "A lack of proper input validation is one of those things which tends to lead quite quickly to users doing \"bad\" things with your application, when it should really be handled by the programmer. I've seen legacy apps where users have been trained to:  not enter apostrophes in names not enter any symbol other than a-z0-9, ensure there are no spaces before or after the text they've entered check that a correctly formatted email address is being entered in to the email field, otherwise subsequent mailings to that user will use whatever's in the field and will fail make sure \"http://\" is put before web addresses  etc etc All of the above issues are ones which should be handled by an application developer. When your input validation is essentially \"make sure the user knows what format this field should be in and trust what they've entered is right\", then unexpected things are bound to find their way in to the app. Aside from the obvious security implications, users make mistakes. As programmers we often produce our best products by bending over backwards to make sure that the user can't get it wrong, no matter how hard they try! "
    },
    {
        "ID": "1785",
        "Question": "Please, stay on technical issues, avoid behavior, cultural, career or political issues. ",
        "Best answer": " The bug is in your code, not the compiler or the runtime libraries. If you see a bug that cannot possibly happen, check that you have correctly built and deployed your program.  (Especially if you are using a complicated IDE or build framework that tries to hide the messy details from you ... or if your build involves lots of manual steps.) Concurrent / multi-threaded programs are hard to write and harder to properly test.  It is best to delegate as much as you can to concurrency libraries and frameworks. Writing the documentation is part of your job as a programmer.  Don't leave it for \"someone else\" to do.  EDIT Yes, my point #1 is overstated.  Even the best engineered application platforms do have their share of bugs, and some of the less well engineered ones are rife with them.  But even so, you should always suspect your code first, and only start blaming compiler / library bugs when you have clear evidence that your code is not at fault.   Back in the days when I did C / C++ development, I remember cases where supposed optimizer \"bugs\" turned out to be a due to me / some other programmer having done things that the language spec says have undefined results.  This applies even for supposedly safe languages like Java; e.g. take a long hard look at the Java memory model (JLS chapter 17). "
    },
    {
        "ID": "1849",
        "Question": "If you've always loved unit testing, good for you! But for the unfortunate ones who weren't born with a liking for it, how have you managed to make this task more enjoyable ?  This is not a \"what is the right way to unit test\" question. I simply want to know little personal tricks that reduce the boredom (dare I say) of writing unit tests. ",
        "Best answer": "Firstly, I agree with you - if you are writing your unit tests on already completed code, or you are manually unit testing your code, I find that extremely boring too. I find there are two ways of unit testing for me that really make it enjoyable:  By using Test Driven Development (TDD) - writing the tests first allows me to think about the next piece of functionality or behaviour that I need in my code. I find driving towards my end goal in tiny steps and seeing tangible progress towards that goal every few minutes extremely rewarding and enjoyable. When there are bugs, rather than going straight to the debugger, it's a fun challenge to figure out a way to write a failing unit test that reproduces the bug. It's extremely satisfying to finally figure out the circumstances that make your code fail, then fix it and watch the bar turn green for the new failing test (and stay green for all of your existing tests).  "
    },
    {
        "ID": "1877",
        "Question": "As an example, say there's an interface that contains a table/grid of information that is periodically updated.  The table is meant to represent an event that has happened, perhaps the date and time of a stock price change. The actual frequency of these events could be dozens of events per second.  This is obviously too much information for a user to process/understand, so I'm trying to find out how much information a user COULD process in a given amount of time so that we can throttle the data and come up with an alternate display. I know some studies have been done on this, but I can't seem to find an authoritative source. ",
        "Best answer": "There is research into this topic but it will give you a complex answer.  You can increase how much a person can take in from a UI if you use different sensory modalities rather than just one.  For example using sights and sounds you may be able to pump more information into a user than using just sight or just sound.  There are also findings that suggest that if your user has to really process or think about the inputs there are more significant bottlenecks that are more difficult to avoid even if you cross sensory modalities.  Training helps.  Expert users can process more but in the typical cases you will run into limits. But to get down to your question of how fast you can change the display in particular table:  You can look into the Psychology literature on the topic of \"Attentional Blink\"  and \"Psychological Refractory Period (PRP)\"  but the general advice that I can give you from that is don't push faster than changes every 500ms for a single watched location.  Typical users can need that much time to process even simple single location changing input.  If you're doing it continuously 500ms is a speedy but perhaps roughly workable rate.  You may be able to push down to 250ms but this will depend on what percentage of your users you're willing to put off.  Also if your users are having to scan multiple locations for possible changes you may have to slow down even from a 500ms change rate.  This doesn't necessarily mean 1000ms if you have two locations.  It's not a linear relationship but the answer for that is going to be more complex and depend a lot more on what your UI looks like exactly. Wikipedia: Attentional Blink "
    },
    {
        "ID": "1885",
        "Question": "As programmers I think we are the most inclined to use new technologies and things that are not so mainstream. I absolutely love OpenId's ability to log in with credentials you already have, but I always use a provider that I already use and that is the fastest to log in, like google. God knows I'd never used it if i had to type in the whole \"https://www.google.com/accounts/o8/id\" I like to click on the google button and then just say yes (the first time, then its just clicking the button). Does any of you ever uses the Generic \"Enter your own provider\" OpenId? Do you think its worth to even offer it to more casual end users? ",
        "Best answer": "Yes. I set up delegation on my own site, so I just use one of my own URLs. Easy to remember, and doesn't tie me to a provider. "
    },
    {
        "ID": "1890",
        "Question": "What is the best practice, most commonly accepted naming conventions for private variables in C#?  private int myInteger; private int MyInteger; private int mMyInteger; private int _myInteger; private int _MyInteger; Mysterious other option  Which do you use and why?  (My company is fairly new to C# and I would like to pick the most \"industry accepted\" method to try and get into our coding standard.) ",
        "Best answer": "The MSDN class design guidlines http://msdn.microsoft.com/en-us/library/ta31s3bc.aspx recommends option 1 - myInteger.  I have always used this style. I have a personal dislike for the _ character. "
    },
    {
        "ID": "1947",
        "Question": " Possible Duplicate: Really “wow” them in the interview   Let's say I appear for an interview. What questions could I expect and how do I prepare? ",
        "Best answer": "Programming Interviews Exposed is also helpful.  This classic book uncovers what   interviews are really like at   America's top software and computer   companies and provides you with the   tools to succeed in any situation. The   authors take you step-by-step through   new problems and complex brainteasers   they were asked during recent   technical interviews. 50 interview scenarios are presented   along with in-depth analysis of the   possible solutions. The   problem-solving process is clearly   illustrated so you'll be able to   easily apply what you've learned   during crunch time. You'll also find   expert tips on what questions to ask,   how to approach a problem, and how to   recover if you become stuck.  I've used it in preparing for my last round of interviews and while I didn't end up needing it, reading through it certainly made me feel more confident and prepared. The book also has a section on non-programming questions such as salary negotiation, which I found very helpful. "
    },
    {
        "ID": "1997",
        "Question": "People make mistakes, even in the real life... Which should we, geeky programmers, avoid? ",
        "Best answer": "Learn that what constitutes \"An acceptable degree of precision\" to you is \"Annoying goddamn nitpicking\" to most of the world. "
    },
    {
        "ID": "2051",
        "Question": "See title, but I am asking from a technical perspective, not   Take my 40 year old virgin niece on a date or you're fired.  ",
        "Best answer": "To market Neal Stephenson's sci-fi thriller Snow Crash, I was asked to write a \"benign\" computer virus. It would \"benignly\" pretend to take over the user's computer and replace the screen with snow, a.k.a., a \"snow crash.\" After a minute or so of snow, the snow would fade out and be replaced by an advertisement for the book. This would be \"benign,\" you see. The virus would spread through normal means, but nobody would mind because after taking over their computer \"you'd just get a fun ad and then be relieved that nothing bad happened to your computer.\" I was actually told to do this at a major worldwide corporation. I had to write a memo explaining all the laws this would break and all 17 bad things that could happen if they really made me implement this. "
    },
    {
        "ID": "2086",
        "Question": "When writing or using an algorithm, should the Big Oh complexity be mentioned? ",
        "Best answer": "If you can back it up with real analysis, then yes, absolutely. @Casebash test != analysis.  If it should always be documented then just start throwing  // this algorithm is O(n!) on every function.  I've worked with people who would say things like 'This function is O(1) because there are no loops', and then I would point to the call $(someHugeList).each(function(//... "
    },
    {
        "ID": "2185",
        "Question": "When should a project be released to alpha, beta and to the public? Is it a good idea to extend the alpha and beta phases when it is needed? When in a later phase (eg. beta), is it wise to go back to an early phase (eg. alpha) if it didn't work out? ",
        "Best answer": "The right time is when the product is ready for each stage. It's up to you and the customer to define \"ready\". This might be when a certain number of bugs have been found and fixed or how much documentation has been completed. It all depends on the application and what the customer is expecting. I'll ignore the alpha phase for now. A beta phase is usually when you think you're feature complete for this release and require feedback on the fine details of your application. This is often seen as public testing, but that depends on your application. A small scale application will be beta tested by a few select users, a large application (like Visual Studio, or Stack Overflow) will be beta tested by anybody and everybody willing to help. The official release is when you (and your customers/users) are confident that your product can do the job it's designed for. It might not have all it's features, but those you implemented for this release will be. Alpha testing is more nebulous. It means different things to different people. You might release an early version that not feature complete because you need more user feedback on one particular aspect. You might also need to get something \"out there\" to meet a specific demand and can't afford to wait. "
    },
    {
        "ID": "2192",
        "Question": "What things tend to slow a developer down? Please try to refrain from posting answers that:  are slow now but useful in the feature. (TDD, Refactoring, ...) list a distraction.  ",
        "Best answer": "Oh this ones easy:  Meetings More Meetings Meetings about the last meeting Meetings to prepare for the upcoming meeting Developing a power point presentation for a meeting Developing a power point presentation for a meeting discussing features that haven't been implemented, shouldn't be implemented, and for whatever reason that guy from sales will jump all over.  I can't predict what document you want displayed in the app based upon your current location without an internet connection or access to your hard-drive.  No really, just give up asking for it too.  "
    },
    {
        "ID": "2204",
        "Question": "What steps and measures can I take to prevent deep indentations in my code? ",
        "Best answer": "The best thing you can do is extract methods: int Step1(int state) {     if (state == 100)     {         return Step2(state);     }     else     {         return Step3(state);     } }  int Step2(int state) {     if (state != 100)     {         throw new InvalidStateException(2, state);     }      // .... }  "
    },
    {
        "ID": "2226",
        "Question": "In an earlier question, I asked for career advice for new software engineers who did well before and during college.  But what about people who weren't fortunate enough to go to MIT or Yale, for whatever reason?  What if you went to what Joel Spolsky calls a JavaSchool? What can/should JavaSchool alumni do to develop their skills and make up for the things they missed in college?  (Or, was Joel wrong about those schools being disadvantageous?) ",
        "Best answer": "Despite the claims made by Joel in that article- and he concedes the point himself- a lot of the subject areas that may be missed by a \"JavaSchool\" are not necessary of many jobs. I attended something that I suppose resembles a JavaSchool in that we spend most of our time focusing on high level languages like C# and Java, but that doesn't change the fact that \"Algorithms & Data Structures\" is still part of the required class list- not to mention all of the other theory-oriented classes. Granted not all \"JavaSchools\" are the same, but that isn't the point. In my opinion, more important than an understanding of some of the grittier development topics is being able to problem solve effectively when unique challenges arise. As software engineers we do the vast majority of our learning on the job and as such, two of the biggest aspects of our job description are being able to problem solve and being able to pick up unfamiliar concepts. If, during an interview, one is unable to make a discernible and logical attempt at solving a problem which is new to them, then their incompatibility for a given position will likely reveal itself. Obviously, when hiring someone for a position that requires constant exposure to and use of some intricate topic that may be missed by a JavaSchool, it is often the logical choice to go with someone who has a prior understanding, but lack of experience shouldn't always preclude job eligibility.  More than likely, the 50 year old Java guy at your company that has been there for as long as anyone can remember did not have any understanding of Java until his job (current or previous) asked him to learn it- and he did so. Strictly speaking, it's bad practice to fire \"the old guy\" so that a younger and more \"up-to-date\" candidate can take his place; that being said, if the job description for any employee young or old changes, it is the responsibility of that employee to get caught up or find a new job. Just because an individual (especially a programmer with past experience) doesn't understand some concept, doesn't mean they are unwilling or incapable of learning it. In fact, if they are unwilling to learn then they probably do not belong at any job- much less yours. It's fair to say that some \"JavaSchools\" are better than others, and that fact should certainly be considered when selecting a candidate for a position, but there are a lot more important personal traits than just where someone went to school. It is our aptitude to tackle a problem and find a solution that defines us as engineers, most everything else is secondary. "
    },
    {
        "ID": "2247",
        "Question": "How can I track that I'm developing software more or less productive than the previous days?  ",
        "Best answer": "There's a simple answer: you can't. And moreover, you shouldn't. You want to measure your own productivity, but you can generalize: how can you measure productivity of programmers? First of all you have to define what you mean for \"productivity\": amount of code produced? Amount of design (or specification) implemented? Number of issues fixed? Quality of produced code? (Yes, quality is a productivity counter, you can produce a lot of bad code or few good code, what has been more productive?). All these values can hardly be mapped to a daily base, and any attempt to track daily productivity is dangerous for the project, for the company, and for the programmer. My advice is to clearly define what you mean as \"productivity\", then define a measure unit, and apply it on a weekly and monthly base. "
    },
    {
        "ID": "2259",
        "Question": "Sometimes, one creates a exploratory prototype and forgets about structure in the directories... What are good tips on dividing the programming files over (several levels of) directories? ",
        "Best answer": "If your language is OOP and package based (Eg Java), then you should probably keep each package in its own folder (eg my/package/name) to keep with the convention. If your language isn't package based (Eg PHP), then organize by what each file does. Here's an example  Does this do utility functions? Goes in /util Is this a 3rd party plugin? Goes in /plugin Is this part of the admin panel? Goes in /admin, along with ALL supporting files Is this Javascript? Goes in /javascript Is this CSS? Goes in /css Is this a template? Goes in /templates/templateName etc  Language agnostic, Most people have a /src directory for all source files, a /lib directory for libraries, and a /bin or /dist directory for builds.  "
    },
    {
        "ID": "2329",
        "Question": "Google sometimes come up with irrelevant links, not everything is available on SO, there are cases where the local documentation is also annoying to look through... Are there other efficient ways you use to search? ",
        "Best answer": "Practise your Google-fu. Google is pretty awesome, but it's not magic. Sometimes you'll need to use search operators to get better answers, especially on some code phrases that can be difficult to search. Check out the Google Guide, for example. If I know where the answer is, I might use the site: operator, or if I need something citable I often use inurl:edu. Google Code is handy for finding examples, and I use it to search for APIs sometimes. "
    },
    {
        "ID": "2331",
        "Question": "Please, explain why and list which languages have the (mis)feature implemented As far you know. Post what you consider a harmful feature, not what you dislike. ",
        "Best answer": "Register Globals in PHP Information : http://php.net/manual/en/security.globals.php This is by far the worst feature to be ever implemented for readability reasons and security reasons. Basicly all the GET parameter received are transformed into variables. For example with this URL : /index.php?value=foobar You can do the following : <?php echo $value; // return foobar ?>  When you are reading code, it is very confusing to know where the variable comes from. Also if the feature is misused, it can lead to security hole. Here's a code example from php.net that shows how it can be misused : <?php // define $authorized = true only if user is authenticated if (authenticated_user()) {     $authorized = true; }  // Because we didn't first initialize $authorized as false, this might be // defined through register_globals, like from GET auth.php?authorized=1 // So, anyone can be seen as authenticated! if ($authorized) {     include \"/highly/sensitive/data.php\"; } ?>  "
    },
    {
        "ID": "2497",
        "Question": "How useful are infix operators in a programming language? Are they worth the extra complexity they provide? Can you provide any examples where infix operators are better suited to the problem that can't be handled by just overloading the normal operators? ",
        "Best answer": "I think infix operators stem from mathematics. This: 2 + 3 * 4  is more readable to most people, than (+ 2 (* 3 4))  because most people are familiar with mathematics. Interesting enough in Haskell you can hop between infix and prefix. This is using the same funtion \"(+)\": (+) 1 2 1 + 2  and this is using the same function \"elem\": elem 42 [1,2,42] 42 `elem` [1,2,42]  "
    },
    {
        "ID": "2654",
        "Question": "In response to This Question, I ask:   What are the best parts of your coding standard? What are the best practices that help with code quality, reliability, maintainability, readability, etc. Please include the language, the item from the standard, and the reason it improves your code. ",
        "Best answer": "Just one public class must be put in each file, no more. "
    },
    {
        "ID": "2700",
        "Question": "I have had a few that I am proud of and some of them were written by myself few years ago. It doesn't have to be necessarily buggy, just bad code.  ",
        "Best answer": "I don't know about being proud of the fix because it was so obvious, but the most horrible code I remember fixing was this. if (userName==\"John O'Reily\") { userName= \"John O''Reily\";} if (userName==\"Stacy O'Neil\") { userName= \"Stacy O''Neil\";} if (userName==\"Finnegan O'Connor\") { userName= \"Finnegan O''Connor\";} ... someSQL = \"SELECT * from Users where UserName='\" + userName + \"'\";  Apparently the previous developer just kept adding new lines every time a new (usually Irish) user started getting errors in the application. I'll leave it as an exercise for the class as to how it was fixed. "
    },
    {
        "ID": "2715",
        "Question": "Should curly braces be on their own line or not? What do you think about it? if (you.hasAnswer()) {     you.postAnswer(); } else {     you.doSomething(); }  or should it be if (you.hasAnswer()) {     you.postAnswer(); } else {     you.doSomething(); }  or even if (you.hasAnswer())     you.postAnswer(); else     you.doSomething();  Please be constructive! Explain why, share experiences, back it up with facts and references. ",
        "Best answer": "You should never do the 3rd method.  Skimping on braces might save you a few keystrokes the first time, but the next coder who comes along, adds something to your else clause without noticing the block is missing braces is going to be in for a lot of pain.  Write your code for other people.  "
    },
    {
        "ID": "2756",
        "Question": "Coding standards are common in any software development organization, but how important are they to follow?  I can understand the need for some consistency, but when dealing with simple things like the position of braces, line length, etc., I'm not sure excessively strict standards contribute much to software development. Isn't it more important that your code is readable, not that it conforms to a predefined standard?  It seems they're more like... guidelines anyway. ",
        "Best answer": "Asking everyone to 100% adhere to the same standard code formatting guideline is like asking everyone to collaborate separately on writing a 100 page paper with the same writing style.   Hopefully everyone will write the paper in English (or same language), but different styles will be apparent.  Some will write it well, others not.  Some will use contractions, some will spell the words out fully (example: it's verus it is).  Etc. I think you touched on the most important points:   It's a guideline Readability  If you want the code to adhere to the same formatting, like a paper to be in the same writing style, it'll need editing and revising.  The code will need to be cleaned up, reviewed, re-factored, etc. I've never been in a shop where I was completely happy with another developer's coding style or formatting (at minimal because it's not exactly like mine).  But I'll be content if I can read/understand it and if it's consistent.  Everything else is the sugar on the syntactic sugar. So to answer your question: somewhat important, but it's certainly not the end of the world if they don't. "
    },
    {
        "ID": "2776",
        "Question": "The Joel Test is a well known test for determining how good your team is. What do you think about the points? Do you disagree with any of them? Is there anything that you would add? ",
        "Best answer": "Jeff Atwood has The Programmer's Bill of Rights. From the post:   Every programmer shall have two monitors Every programmer shall have a fast PC Every programmer shall have their choice of mouse and keyboard Every programmer shall have a comfortable chair Every programmer shall have a fast internet connection Every programmer shall have quiet working conditions   This seems to have some items that I'd like to see on Joel's list.  Specifically in the area of hardware (dual monitor, fast PC, mouse/keyboard, comfortable chair, fast connection).   The only thing not mentioned is having a comfortable and adjustable desk. This could all be added by changing: Current #9: Do you use the best tools money can buy? to  Improved #9: Do you use the best tools and equipment money can buy? "
    },
    {
        "ID": "2777",
        "Question": "I have heard a lot of people mention Code Complete as a book worthwhile reading. Unfortunately, I am so busy that I don't have time to read it, so can anyone tell me what the key points of the book are? ",
        "Best answer": "Code Complete is about software craftsmanship; it is an advanced-beginner/intermediate-level book, written for the working programmer, but it would still be very useful to someone who's been programming for at least a year.   Thus the key points of Code Complete (2nd ed.) are nicely summarized in its Chapter 34, Themes in Software Craftsmanship.  As paraphrased from my notes:  Conquer Complexity: reduce the cognitive load on your mind via discipline, conventions, and abstraction. Pick Your Process: be conscious of quality from start (requirements) to finish (deployment) and beyond (maintenance). Write Programs for People First, Computers Second: code readability is hugely important for comprehensibility, review-ability, error-rate, error-correction, modifiability, and the consequent development time and quality. Program into Your Language, Not in it: think of the What? and Why? before the How? Focus Your Attention with the Help of Conventions: conventions manage complexity by providing structure where it's needed, so that the ultimate resource - your attention - can be effectively used. Program in Terms of the Problem Domain: work at the highest level of abstraction possible; top-level code should describe the problem being solved.  Distinguish OS level, programming language level, low-level implementation structures, low-level problem domain terms, and finally, high-level problem-domain terms that would make total sense to the (non-coder) user. Watch for Falling Rocks: as programming merges art and science, good judgement is vital, including heeding warning signs. Iterate, Repeatedly, Again and Again: iterate requirements, design, estimates, code, code tuning.  Thou Shalt Render Software and Religion Asunder: be eclectic and willing to experiment.  Don't be an inflexible zealot, it precludes curiosity and learning.  Go beyond having just a hammer in your toolbox.  But the most important take-aways are in Chapter 33, Personal Character: once you consciously seek to improve as a coder, you can and will.  The fastest way to do so is to take on the the attitudes of master coders (humility, curiosity, intellectual honesty, discipline, creativity), while also practicing their habits (many good habits are listed in the book, e.g. choosing good variable/value names).   Also, the book makes clear that the gap between average and excellent in software is immense; that fact alone should drive the conscientious coder to better himself. That's the short of it; the long version is in the book. :)  I can also send you my not-so-long, not-so-short notes if you want more details.  But the book is certainly money and time well-spent, even if the writing style is tiresome at times.   Beyond Code Complete, I'd highly recommend The Pragmatic Programmer.  It's for intermediate-level programmers, nicely-written and a great mix of high, medium, and low-level advice. "
    },
    {
        "ID": "2829",
        "Question": "I originally thought of creative commons when while reading a book about wordpress (professional wordpress), I learned that I should also specify that the product is provided   ... WITHOUT ANY WARRANTY; without even the   implied warranty of MERCHANTABILITY or   FITNESS FOR A PARTICULAR PURPOSE  and they recommend GNU GPL.  How do I write a license or select 1? btw, what does MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE mean actually? Isn't without warranty enough?  ",
        "Best answer": "For small bits of code, I generally release them under the X11 licence. The problem with the GPL is that it's far too complicated for code that you don't really care enough about to protect. If you really don't want people using your code in commercial products, you would need to monitor for infringement and fight it out in court, which isn't really worth the time or the effort for small, free, open-source projects.  Copyright (c)   Permission is hereby granted, free of charge, to any person obtaining a copy    of this software and associated documentation files (the \"Software\"), to deal    in the Software without restriction, including without limitation the rights    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell    copies of the Software, and to permit persons to whom the Software is    furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in    all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN    THE SOFTWARE.   EDIT: If the body of code is more substantial, and you feel that you've invested enough time in it that you would be willing to protect it, by all means use the GPL to protect it. "
    },
    {
        "ID": "2932",
        "Question": "When I say Free Software I mean it in the FSF terms. Free as in Free Speech, not as in Free Beer. Why is it a good idea for programmers to use and write Free Software? ",
        "Best answer": "There are literally scores of different reasons why someone might choose to distribute Free software: that's why there are scores of different F/OSS licenses. My favorite reason for going Free is from Linus Torvalds on why he chose and sticks with GPLv2:  Me, I just don't care about proprietary software. It's not \"evil\" or \"immoral,\" it just doesn't matter. I think that Open Source can do better, and I'm willing to put my money where my mouth is by working on Open Source, but it's not a crusade -- it's just a superior way of working together and generating code. It's superior because it's a lot more fun and because it makes cooperation much easier (no silly NDA's or artificial barriers to innovation like in a proprietary setting), and I think Open Source is the right thing to do the same way I believe science is better than alchemy. Like science, Open Source allows people to build on a solid base of previous knowledge, without some silly hiding. But I don't think you need to think that alchemy is \"evil.\" It's just pointless because you can obviously never do as well in a closed environment as you can with open scientific methods.  This goes to Eric S. Raymond's Linus's Law:  Given a large enough beta-tester and co-developer base, almost every problem will be characterized quickly and the fix obvious to someone. Or, less formally, \"Given enough eyeballs, all bugs are shallow.\"  "
    },
    {
        "ID": "2948",
        "Question": "How valuable (or not) do you think daily stand-up meetings are? If you're not familiar with it, this refers to a daily meeting that is part of Scrum adherents (and some other agile methodologies).  The idea is that you hold a daily meeting, timeboxed to 15 minutes, and in which everyone must stand (to encourage people to be to-the-point). In the meeting, you go around the room and each say: - What you did yesterday - What you plan to do today - Any blockers or impediments to your progress. Do you think this practice has value?  Has anyone worked at a place that's done it, and what did you think? ",
        "Best answer": "We had daily standups at my first job. Well, with all the co-ops/interns/temps, it was actually on the long side - usually around 30 minutes. But the idea of a short, timeboxed, daily meeting helped a lot just to know what other people were stuck on - and if it was something I was working on, I could reprioritize my tasks to finish what they needed to continue sooner. It also gave everyone a chance to know what everyone was working on so if someone had an emergency, everyone was at least aware of what was going on - reducing a truck factor is always a good thing. Honestly, every day might be a little extreme in some cases. But the idea of short, regular meetings for everyone to stay on the same page is a valuable addition to any process. "
    },
    {
        "ID": "2959",
        "Question": "One of the criteria of the Joel Test is daily builds. The idea is that if the build is broken, whoever broke it is around to fix it up. If the build cannot be fixed, everyone will have to check out an old version and work on that. I can understand how this can be pretty bad on centralised version control where it is important to avoid merging and branching as much as possible, but this only sounds like a minor nuisance for distributed version control. Do you agree with this? Are there other reasons why daily builds are important? ",
        "Best answer": "I think what's important to note here is that regular builds help catch errors sooner rather than later. It doesn't have to be daily, but often enough. Ideally, it can also run your unit tests. The goal is to find out when a build breaks before the final testing phase, to find them as soon as possible. Just set it up to build your main development branch(es). We use it at work (although we build hourly), and often when we forget to set-it up we find about problems just hours before releasing. "
    },
    {
        "ID": "3049",
        "Question": "I would like to do some web programming using functional programming. What decent web-frameworks exists for functional programming languages? ",
        "Best answer": "Compojure is an open source web framework for the Clojure programming language. http://en.wikibooks.org/wiki/Compojure "
    },
    {
        "ID": "3069",
        "Question": "If you browse the code golf questions on StackExchange, you notice a ton of non-standard but real world (Eg not brain-f*ck) languages like F#, Scala, R, J and Clojure. Visiting their websites, some of the languages look interesting solving problems in whatever language your already using. However there is coding in spare time, and coding for money. The closest thing we have to the truth on who uses a language is the TIOBE Index, which lists none of the above languages in the top 10-15. Which makes me wonder if I'll ever use them. Should I even bother learning some of the small niche languages? It doesn't seem I would be making money, and some will probably fail anyway. ",
        "Best answer": "The Sapir-Whorf Hypothesis.  It states, more or less, that what you can think of is limited by what you have the language to describe.  The consequence of this is that multi-lingual people are able to think in ways that single language speakers may not be able to. Many people (myself included) think this holds true to programming as well.  Learning Lisp, for example, teaches you a whole new way of thinking about problems that you can apply to C# or Java or Python.  The more language paradigms you've learnt, the more tools will be in your mental toolbox, regardless of what language you're actually using. "
    },
    {
        "ID": "3199",
        "Question": "Are different version naming conventions suited to different projects? What do you use and why? Personally, I prefer a build number in hexadecimal (e.g 11BCF), this should be incremented very regularly. And then for customers a simple 3 digit version number, i.e. 1.1.3. 1.2.3 (11BCF) <- Build number, should correspond with a revision in source control ^ ^ ^ | | | | | +--- Minor bugs, spelling mistakes, etc. | +----- Minor features, major bug fixes, etc. +------- Major version, UX changes, file format changes, etc.  ",
        "Best answer": "I tend to follow Jeff Atwood's opinion of the .NET convention of version numbering.  (Major version).(Minor version).(Revision number).(Build number)  More often than not, for personal projects, I find this to be overkill. The few times where I have worked on substantial projects like search engines in C# I've stuck to this convention and have been able to use it as an internal tracker effectively. "
    },
    {
        "ID": "3272",
        "Question": "How would you, as someone involved in the hiring process (manager,interviewer, etc) feel about a candidate that has changed jobs every 1-2 years? updateThanks for all the input everybody, some really great responses, and good info in every post.  I asked it because I'm currently at my 3 job in the last 5 years and I'm feeling like my position is going nowhere (like the position should have been contract in the first place, not full-time).   My only options here seem like transition to a different team doing something I'm not really interested in or look for new work, but I'm a little afraid my recent job history is all short stints. ",
        "Best answer": "It depends on the context:  In a startup culture (like Silicon Valley), one to two years is the lifetime of many companies, and it's expected you'd be switching your place of employment that often. If you're a contract worker, a contract may only be a short, set timespan. Everywhere else, one to two years is an unusually short stay at a company.  In any context, employers are generally looking for a person who's going to be in it for the long haul, whatever the long haul is for the company:  Startups are looking for someone who will last until the exit: acquisition, IPO, shuttering, etc. Contract hires should be able to successfully complete their contracts to term. Other companies are looking for an employee who will last long enough to make a return on the investment of hiring them: this can take several years.  It's a red-flag to potential employers if you're constantly leaving your job for personal reasons, even if you have perfectly valid reasons. I'd also note that having experience in one context isn't necessarily going to translate to another.  For example, if you're a life-long contract worker, it can look just as unappealing to a company looking to hire full-time employees as someone who went from regular job to regular job. Similarly, a person who stayed at a job for 10 years might be unappealing to a startup that wants people who are constantly looking for the next big thing. "
    },
    {
        "ID": "3277",
        "Question": "Today I found a GPLed project on SourceForge whose executables are spreading a virus. This fact has been pointed out several times in reviews of the project and the infected executable is still available for download. Apparently, older executables are not infected, so the project itself does not seem to be made with malicious purpose in mind.\r \r There is no preferred way to contact developers and forums for the project are dead.\r \r What should I do?",
        "Best answer": "If you can't get in touch with the developers, then contact SourceForge.  Report the problem, give them detailed information they can use to verify the issue, and they'll (probably) take it down.  They're a reputable site and I imagine they wouldn't want to be associated with malware. "
    },
    {
        "ID": "3317",
        "Question": "What's the difference in this terminology? Is one considered more professional than the other? ",
        "Best answer": "While the terms can be and often are interchangeable, I view a developer as someone who's involved in the whole process from requirements gathering, through specification and coding to testing and, yes, support. They might not be fully involved in all stages all of the time. A programmer is someone who just concentrates on the coding and has little involvement in the rest of the process. This may be their choice of course. As @sunpech points out in his comment most people writing software these days are (or should be) developers. You have to know much more than just how to code to write good software. "
    },
    {
        "ID": "3383",
        "Question": "Years ago, in my first real programming job, my boss encouraged me to keep a journal of my daily activities.  I still do so, although no longer a paper and hand-written one. Do you keep a journal, if so, what do you write in it, and how does it help you in your job?  Or, does it just take time that is not ever recovered? ",
        "Best answer": "I find an activity log helpful for several reasons:  I fully agree with Jon Sagara in that it helps answering the question \"what have you done past week (apart from sleeping)?\".  Additionally, it helps to keep track of the million interruptions, which are often forgotten but combined they take a lot of time. I also find it a great help for learning to estimate, as it gives you hard figures on how long things take (often longer than you'd think).  "
    },
    {
        "ID": "3425",
        "Question": "And what do you think about operator precedence? Would be harder programming in a language where the operations are executed in sequential order? Ex.: 2 + 3 * 4 == 20 2 + (3 * 4) == 14 OK, the Lisp family doesn't have precedence by definition. Let's gonna talk about procedural and object-oriented languages using this \"feature\". ",
        "Best answer": "Smalltalk. Everything's done with message sending, so 1 + 2 * 3 means \"send * with parameter 3 to the object returned by sending the message + with parameter 2 to the object 1\". That throws people (it threw me) because of how we usually write maths, but since I can never remember C's operator precedence I cope in the same manner in both languages - I use ()s to group terms: 1 + (2 * 3). "
    },
    {
        "ID": "3438",
        "Question": "It seems like in language holy wars, people constantly denigrate any feature they don't find particularly useful as being \"just syntactic sugar\".  The line between \"real features\" and \"syntactic sugar\" tends to get blurred in these debates.  What do you believe is a reasonable and unambiguous definition of syntactic sugar that avoids it being defined as any feature the speaker/writer doesn't find useful? ",
        "Best answer": "How about this: \"syntactic sugar is a convenience shorthand for some functionality that does not introduce any meaningful layer of abstraction.\" Take a->b, which, as you point out, is equivalent to (*a).b.  Does this notation allow you to consider the code it's in any useful, otherwise hidden manner?  No, so it's syntactic sugar. Now consider a[i] == *(a + i).  Think about any C program that uses arrays in any substantive way.  Can you imagine trying to comprehend it without the [] notation?  With multidimensional arrays?  It is meaningful to consider arrays as whole units, not as a reference to the start of a contiguous block of memory.  While it does help to know how arrays work in C if you're planning on doing complicated things with them, it is unproductive to always have to think \"I need to store the two bits of memory 2*i bytes to the right of the memory location referenced by a.\"  The whole point of an array is the ability to abstract away the process of storing a sequence as a coherent unit.  The [] notation facilitates this abstraction.  It's not syntactic sugar. This is not to imply that syntactic sugar is always bad thing.  Like many alliterations, it has become an epithet and pitted against \"real features.\"  But LISP and Scheme, for example, would be unreadable if not for the let shorthand (and others). The ternary operator, <pred> ? <cnsq> : <alt>, is another example.  Syntactic sugar can help to organize programs and remove redundant code, which may save in maintenance down the line.  Syntactic sugar may sometimes be preferable to piling on \"real features\" if it helps to remove syntactic barriers to programming. To quote R^5RS, \"Programming languages should be designed not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary.\"  IMHO, syntax can qualify as a weakness and restriction and so letting programmers get away from syntax can increase a language's expressivity. "
    },
    {
        "ID": "3519",
        "Question": "I am C++ developer with some good experience on it. When I try to learn a new language ( have tried Java, C#, python, perl till now) I usually pickup a book and try to read it. But the problem with this is that these books typically start with some very basic programming concepts such as loops, operators etc and it starts to get very boring soon. Also, I feel I would get only theoeritcal knowledge without any practical knowledge on writing the code. So my question is how do you tacke these situations? do you just skip the chapters if its explaining something basic? also, do you have some standard set of programs that you will try to write in every new programming language you try to learn? ",
        "Best answer": "Basically by writing code in that language. You need to have a good example application to study/modify otherwise you're starting off on the wrong foot and you might never recover. Years ago the company I worked for at the time decided to use Ada for their next product, but as all the developers used FORTRAN in the previous product we ended up creating FORTRAN constructs in Ada. We never really recovered from that. Having access to the documentation and Stack Overflow is essential otherwise you'll potentially miss the important features of the language. On that score find out who are the Gurus in the language and read their blogs, these will often discuss the new features of a language/framework and also the obscurer areas you'll never find by yourself. If you can't find out who they are ask here! In an ideal world I'd like to learn by myself for a while and then be evaluated, but I've never managed that yet. "
    },
    {
        "ID": "3558",
        "Question": "At some point in time, I just stopped coding for fun.  I used to go to work, finish my assignments and then upon arriving home I'd go and write stuff on the side for fun.  However, I now just go home and try to avoid the computer.  I'd rather read the paper, watch TV, go out to the bar, etc. Is this a bad sign?  I mean I still try to keep up on the latest trends, hit up the developer forums/blogs/etc but I haven't said, \"I want to learn language X - I wonder if I could write app Y in it\" Has this happened to anyone else? ",
        "Best answer": "This is a very common issue called burn-out. It happens to everyone that takes their work seriously. My advice is to take a few weeks off from coding and plan a long term project for fun. Then set aside at least 15 minutes each night to complete a part of the project. As long as you take it slow you'll be back in the game in no time. "
    },
    {
        "ID": "3645",
        "Question": "I am a computer science student and learning Java now a days.  I want to be a good developer/programmer.  I like reading books. I search on the internet for the related topics and study them. I refer to StackOverflow and other good programming websites daily but I code rarely. Is this a bad sign? If yes then what should I do to overcome this problem? ",
        "Best answer": "Experience trumps all, if you aren't getting experience then yes you definitely have a problem if you want to be a great programmer. Start on a new project or join another person's open source project.   Get some experience.  Write some code. "
    },
    {
        "ID": "3678",
        "Question": "I work with C# professionally and I write code like this all the time. private IEnumerable<Something> GetAlotOfSomething() {     if (somethingA.IsReady)         yield return somethingA;      if (somethingB.IsReady)         yield return somethingB;      if (somethingC.IsReady)         yield return somethingC;       // ... More complex logic }  var specialSomethings =      GetAlotOfSomething()     .Where(s => s.IsSpecial);   Then one day I have to write a bit of VB6 or JScript and I end up writing so much boilerplate just to get things done. Anyone thoughts? ",
        "Best answer": "Iterators (generators etc) are certainly great features that I use a lot.  I don't qualify them as necessary, but I will certainly choose languages that have them when I get a choice. "
    },
    {
        "ID": "3730",
        "Question": "What tools do they use? What processes? What rules do they have regarding code? How do they test their code? ",
        "Best answer": "I was searching a couple of weeks ago for some info about google development methodologies and found the following which I posted on my blog  Steve Y - Good Agile vs Bad Agile A summary of google methodologies from Steve Y's post Google Product Development/Management Process  I can't post more than one link at the moment, though, (stackexchange spam prevention apparently), so follow the link to my blog or google the above strings. Chris. "
    },
    {
        "ID": "3747",
        "Question": "We have a legacy classic ASP application that's been around since 2001.  It badly needs to be re-written, but it's working fine from an end user perspective. The reason I feel like a rewrite is necessary is that when we need to update it (which is admittedly not that often) then it takes forever to go through all the spaghetti code and fix problems.  Also, adding new features is also a pain since it was architect-ed and coded badly. I've run cost analysis for them on maintenance but they are willing to spend more for the small maintenance jobs than a rewrite.  Any suggestions on convincing them otherwise? ",
        "Best answer": "I believe there's two factors you should consider that you at least didn't cover in your Q. Let me define these as I use them, then I'll get onto the business of answering your Q.  Risk Opportunity cost  Risk is probably obvious: The chance that they pile a mountain of money into something that goes nowhere. Risk is compounded by what Brooks called \"Second System Effect\" and the rest of us call \"Gold Plating\". Every rebuild I've seen carries risk from people who add every feature they didn't add the first time around. Opportunity Cost in this context is the cost associated with you rewriting functionality that from the business perspective was working fine. It is Opportunity Cost because it means you don't have the opportunity to add features.  To sell something that is purely a refactor is hard because Risk and Opportunity Cost both have money attached to them from a decision making perspective. What I generally recommend is that instead of selling a rewrite of the system, you sell an \"improve as you go\" at a component level. It costs more because you have to build adapters/facades/proxies, but it's less risky and easier to sell. I've been there on the \"we need to rebuild it all\" and it just doesn't go well.  And here's the rub: Over time, all systems turn into garbage unless you are disciplined enough to keep them from doing so.  Which leaves me with this question back to you: If you can't sell them, or even your team, on doing the right thing day to day, what makes you think you can actually see a rewrite through? It really does take some serious introspection to answer that question honestly. Sometimes you've been handed a system from someone who had no clue. Sometimes you've been handed a system by someone who started with the best of intentions and on the right foot but got compromised by a poor corporate culture along the way. If you can't tell which it is, you need to find out soon! "
    },
    {
        "ID": "3766",
        "Question": "I mean seriously, how do you tackle a guy who even changes our variable names (even though they are reasonable) and sends back the code (after review) like 4 times? I know for sure I'm not that bad a developer! So many times, he enforces his ideals, which are not even best practices in the industry! I point out to him whatever link I can find on the internet trying to prove my point, but in the end he uses his authority to shut us out. Sick and tired. Frustrated. Do I have any way out other than quitting the job? ",
        "Best answer": "Quit and find another job. Doing something about your boss is a lost cause so you might as well just find a new job and hope that your new boss isn't a douche like your previous one. Also, judging by his character, I'm pretty sure that even his boss won't be able to do anything about his attitude problems. "
    },
    {
        "ID": "3851",
        "Question": "How would you consider that a programmer is bad at what he or she is doing? If possible... How should he/she improve? ",
        "Best answer": "When they fail to learn from their mistakes and from peer reviews. We are all green at some point; however, if you're not getting better or attempting to get better then you're a bad programmer. "
    },
    {
        "ID": "3884",
        "Question": "I learned about them in a Structured Programming course, but never saw them used thereafter either at the analysis phase or for documentation purposes. Not even for highly structured languages like Pascal (Delphi). Does any of you actually use Nassi-Shneiderman diagrams? If yes, what tools do you use to create/maintain them? edit: Or have you never heard of them? ",
        "Best answer": "Heard of Nassi-Shneiderman diagrams, although I don't use them myself.  I can't help posting a link to the rejection letter that Nassi and Shneiderman received from Communications of the ACM when they first proposed the diagram:  http://www.cs.umd.edu/hcil/members/bshneiderman/nsd/rejection_letter.html "
    },
    {
        "ID": "3918",
        "Question": "What should you do, if a co-worker is editing your code?   Without the purpose of adding functionality or fixing bugs, just to change how it looks... ",
        "Best answer": "Talk to them about it.  Go into the conversation with the attitude of \"They're not doing this to annoy me or because they have some form of obsessive-compulsive disorder; they're trying to make my code better.\" Because you could be wrong.  That could be a subtle bug fix and you just didn't spot it. Or, it could be that there's a coding standard you don't know about that you're violating, and they're just correcting it. Or, it could be that they're trying to annoy you, or they have some form of obsessive-compulsive disorder.  If that's the case, ask them nicely to stop, and if that doesn't work, take it up with your boss. But you'll never know unless you ask. "
    },
    {
        "ID": "3921",
        "Question": "For which issues is it right to edit the code written by a co-worker? For which issues is it wrong? ",
        "Best answer": "When it's right When the edit improves the functionality of the program or makes the code itself more readable / maintainable. When it's wrong When the edit harms the functionality of the program or serves no purpose apart from providing the editor with busywork. "
    },
    {
        "ID": "3956",
        "Question": "In Windows the default way is registry. This allow you to differentiate system-wide and per-user settings. In Unix you should use text files in the /etc folder for system-wide settings (what's the convention for per-user settings?). Many new programs (and especially those designed for being portable) use XML files.  What's the best way (and location) to store non-BLOB settings? Should we follow each system default or have a unified solution? And what's the best portable way?  ",
        "Best answer": " What's the best way (and location) to store non-BLOB settings?  On Windows, it seems acceptable to use the registry. In my opinion, the registry was a poorly-devised system, and instead a simple text file in the Users\\Username\\AppData directory should be preferred. This is easier to back up, less dangerous for users to modify, and easier to clean up. On Linux and most Unixes, The preferred location is /home/user/.config/appname for user-specific settings and /etc/ for global (system-wide) settings. The less-preferred (but acceptable) location for user settings is ~/.appname, but this is generally falling out of favor. These files should be user-editable, so a human-readable format is always preferred. I disagree with most people that XML is an acceptable format for storing non-blob data. It is, in my opinion, an overwrought and excessively complex format for what usually ends up being very small pieces of structured data. I prefer to see files in YAML, JSON, ASN.1, name=value pairs, or similar formats. Having too much syntax makes it too easy for a user to mess up and leave the file in an invalid format.  Should we follow each system default or have a unified solution?  That is entirely up to you, but keep some things in mind:  Platforms like *nix have strict limitations on which locations are writable. More strict than Windows. So:  The only place you should write to anything is in the user's home directory. Unless your application is a system service; in which case, all mutable data files should be written in /var/. Nonmutable data files should be kept in your app directory in /usr/share/ or /usr/local/share/ or /opt/ Configuration files in /etc/ should never be written to by the application when it is running, even if it has write access to them. /etc/ should be the repository for default behaviors and nothing else. Plan for your application to be installed in one of three places: /usr/local/, /opt/appname, or /home/username/appname. Blobs should be stored alongside other configuration files if they are to be changed. It is generally preferable to use a user-editable format, so something like SQLite or Berkeley DB is preferred (since there are command-line tools for each), but not required.  On Windows, your applications should only ever write in the User directory. The standardized location for data files is Users\\User\\AppData. Nowhere else seems acceptable. On Mac OS X, your application settings should be stored in ~/Library/Preferences along with all of the other applications' plist files. plist seems to be the preferred format, but you'll want to double-check with the Apple guidelines.   And what's the best portable way?  There is no \"best,\" to be honest. There are only platform-specific limitations and expectations. My recommendation is to stick with platform-specific means, even if it means writing more code. "
    },
    {
        "ID": "3967",
        "Question": "The jRails project is a drop in replacement for the Prototype/scriptalicious helpers already a part of the Rails framework. Are your experiences with this project positive? Does it do what it says on the tin?  Is it still being maintained or is this a bad choice if I want to do jQuery with RoR? ",
        "Best answer": " Is it still being maintained or is this a bad choice if I want to do jQuery with RoR?  Their website doesn't exist anymore, their Google Group has some spam and their code isn't updated. I guess this isn't maintained anymore and might be a bad choice for continuous development... "
    },
    {
        "ID": "4028",
        "Question": "As programmers, we often take incredible pride in our skills and hold very strong opinions about what is 'good' code and 'bad' code. At any given point in our careers, we've probably had some legacy system dropped in our laps, and thought 'My god, this code sucks!' because it didn't fit into our notion of what good code should be, despite the fact that it may have well been perfectly functional, maintainable code. How do you prepare yourself mentally when trying to get your head around another programmer's work?  ",
        "Best answer": "For any legacy code base, the correct way to prepare yourself mentally for dealing with it is to start by writing unit tests for it. Whether it sucks or not, you need to first have the confidence to be able to change it without breaking stuff! "
    },
    {
        "ID": "4142",
        "Question": "Often when stating a new project I'll require a \"quick 'n' dirty\" content management solution. Ideally something that can read my database schema and generated HTML forms. Previously I've used; phpMyEdit and phpMyAdmin but they are lacking is key areas. My wish list woulds be:  Database independent Foreign key aware Handles views as-well-as tables Generates modern HTML and CSS AJAX interface.  What's your swiss army knife when it comes to CMS on a project? ",
        "Best answer": "I think you're looking for \"scaffolding\", where the software generates views that allow users to maintain the data without you having to do much or any work.  If you must stick with PHP, then look at CakePHP. http://book.cakephp.org/view/105/Scaffolding But two quick suggestions for you. Look at this site: http://www.phpscaffold.com/ Second suggestion: Consider switching to Python/Django or Ruby on Rails.  Both of those are better than what PHP has to offer in terms of scaffolding.  There may be something in PHP somewhere that's as good, but I have not seen it.  CakePHP is the closest I know of. "
    },
    {
        "ID": "4180",
        "Question": " Possible Duplicate: Will high reputation in Stack Overflow help to get a good job?   Just curious, what Web2.0 websites do employers use (if any) to pre-screen potential employees? Does any employer actually refer to a user's online \"reputation\" to get a job? ",
        "Best answer": "I can tell you that there are certain employers who do care about your stack overflow reputation score, and will factor it into their hiring. How do I know? Because those employers made me implement -- and I really didn't want to -- a reputation sort on http://careers.stackoverflow.com. It is not the default sort, though, because I insisted that it not be. Anyway, we always tell employers the same thing, that they should look at the content and evaluate someone's merit based on more than a number; the number is just shorthand for a bunch of other factors. "
    },
    {
        "ID": "4200",
        "Question": "Why would you hire in-house over outsourcing in developing a product for your company? I can only think of a few but I'm not entirely sure if they're good enough reason. This is actually for a debate that I'm going to have in class. I'm more inclined on the outsourcing part but unfortunately, I was asked to switch to the in-house side of the debate. Any ideas? ",
        "Best answer": " An in-house team will be more responsive to your needs, since they're actually part of your company, so they have a better idea of what you want. An in-house team is easier to communicate with- nothing beats regular face-to-face contact. Your in-house team will have more domain-specific knowledge that an external team would have to learn. You're investing not just in the software, but in the expertise solving the types of software problems your company has.  Using your own developers builds up a stock of programmers who've dealt with those specific problems before.  (For counter-arguments, see Joel's take on it.) "
    },
    {
        "ID": "4272",
        "Question": "From time to time I have tried some monitors. My main work is coding (work, phd, etc). At work I have an LG Flatron L246WH which I highly recommend. However at home I have an LG W2363V with which I feel pretty uncomfortable when coding. Fonts, subpixels or whatever mess with my minds when using smooth fonts. Currently, what are the best monitors out there, to best fit our needs? ",
        "Best answer": "The main thing you want to know is the type of panel -- is it TN, VA, or IPS? http://www.codinghorror.com/blog/2007/11/not-all-lcd-panels-are-created-equal.html They all have strengths and weaknesses, but the TN has a lot of weaknesses and only one primary strength -- it's cheap. Apple, for example, has NEVER to my knowledge ever shipped a TN LCD. I strongly advise avoiding TN panels if you want to invest in an LCD you won't mind keeping for a few years. "
    },
    {
        "ID": "4296",
        "Question": "Has anybody's organization started the migration from Java to Scala? If yes, how do you do that? What can I do to encourage my colleagues to do the same? ",
        "Best answer": "Probably the easiest way is to first use Scala only for testing. In this case, you might even not have to tell your boss :-) If he asks, tell him \"that's just my private test case, it's so much easier and faster to use Scala for it\". Once you (and your organization) has enough experience with Scala you can start using it for the 'real' code. "
    },
    {
        "ID": "4325",
        "Question": "I have never had the opportunity to work from home on certain days, but I would definitely like to try it if I can.  What are the pros and cons? I'll list a few that I can think of. Pros:  You don't need to do any work.  (That's a JOKE) You can be a lot more productive.  No commute, relaxed, no meetings, no interruptions  Cons:  Less of a team effort. Other team members can get held up due to having to wait for information for an off-site member  Apologies if this has been asked before - I did a search but couldn't find a pros and cons discussion. Edit: It appears The Oatmeal has already covered this! :-) ",
        "Best answer": "Pro:  No commute. Unless you have annoying neighbours, your environment's as quiet as you like. If you have kids, you have the option of seeing them during the day. You decide when best to work: maybe you're a night owl. Maybe you want to time-shift your work day into the evening so you can spend more time with your children.  Con:  If you're the only person not colocated, you're left out. (\"Why's Foo not answering my mail?\" \"Dude, he resigned a WEEK ago. Didn't you hear? Oh. Noone thought to mail you!\") You have to bring your own discipline to the party. It's tough to explain to your children just why you aren't available to play Lego. Cabin fever, if you're prone to it. (I'm not.) Some people just need to get out their domestic environments. Unless you're disciplined with your time, you can easily start working outside your required hours.  "
    },
    {
        "ID": "4391",
        "Question": "I've programmed a bit of Haskell and Prolog as part of a couple of uni courses, but that's about it. And I've never seen it been used in industry (not that I've had much of working experience to begin with but I've never seen an ad where you are required to know them). So should we be using functional and/or logic programming languages more often? Are there any advantages or disadvantages for using or not using them? ",
        "Best answer": "I believe in using the right tool for the job. Both imperative and functional languages have their place and there's no need to push for using one kind more than the other. For the advantages/disadvantages, I don't think I could beat Eric Lippert's answer to the \"Why hasn't functional programming taken over yet?\" SO question. "
    },
    {
        "ID": "4442",
        "Question": "I have had the question posed at my work that, since we are planning to eventually move to Sharepoint 2010 for most of our Development, and since Sharepoint 2010 supports asp.net web parts, should we start moving all of our new development to be exclusively asp.net web parts? It was also asked how prism factors into all of this.  (not sure what that is) We are now a mostly client/server based location but are moving to an SOA framework (slowly though). Is this a good idea?  Is it better to have some apps in WPF and Winforms hitting the services or should we just go to web parts solely?  What are we going to miss out on if we make this move? ",
        "Best answer": "If you write the web parts and your service-architecture well, you'll end up with a very good solution that will have many of the upsides of a desktop application with all the benefits of integrating with your SharePoint.  Instead of using the traditional MVC I'd recommend a service-oriented approach with most of the work being done in Services and front end jQuery (or extjs if that's your thing). The problem is going to be integrating with your existing client/server architecture as a stopgap during SOA coding and deployment.  You lose very little, especially because your Winforms applications are going to require access to the service layer anyway to be functional (I'm making an assumption here, but from your description it sounds like it), so you can guarantee access to SharePoint (again, making some assumptions about your network configuration). All in all, having a one-stop shop in Sharepoint with all your functionality seamlessly integrated and in one place seems like a best-case scenario to the end users.  It is, admittedly, a little more difficult to code your front end in JS, especially if you're new to this kind of development.  The effort to learn and do it right pays off in spades, at least IME. Disclaimer:  That's all based on a lot of assumptions about your app and your environment based on your post and my knowledge of people in similar situations.  Your situation may be radically different in ways I just don't know about.  Good luck! "
    },
    {
        "ID": "4507",
        "Question": "Considering the fact that you don't have to get involved in setting up/buying a server or even buying a domain, do you think that fact alone is enough to choose one over the other? I don't necessarily want to work on Google App Engine, I just find it convenient when it comes to hosting/environment/etc. and wondering if that's a good enough reason to learn python. In any case, I'm not looking for a debate between python and ruby but more on Google App Engine and whether its value is enough to dictate the language you should learn. ",
        "Best answer": "If you want to develop for Google App Engine, you'd definitely want to learn Python (Java is also an option, but the people behind GAE seem to be Pythonistas). One thing to keep in mind is that writing something in Python doesn't mean you get Google App Engine for free. There are several people, including people at Google, who have had to \"port\" their projects to GAE (RSSmeme is another example) even though they're written in Python. This is because GAE has its own restrictions and specialized environment: for example, you don't access to things like MySQL, threading, or local file storage. The General FAQ for GAE touches upon several of these \"quirks\". "
    },
    {
        "ID": "4522",
        "Question": "I see a few developers that like to use virtual machines for web development.  Are there others that do this? If there are, why do you do it?  Are there any pros / cons to developing on a VM rather than in a non virtualised environment? I would think things are slower in a VM. ",
        "Best answer": "I use VMs for IE testing. I do have a dedicated Windows machine, but I lean towards using VMs for a few reasons:  It's a hassle to switch computers, even if it's right next to you It's extremely easy to rollback a VM to have a clean testing environment I'd rather use an environment users are actually going to use rather than kludges like IETester, and you generally can't run multiple versions of IE at the same time. It's cheaper to run multiple VM instances than it is to buy multiple testing computers VMs, at least the ones for Mac OS X, have gotten so good in the past couple of years that the \"slow\" stigma given to VMs is unwarranted.  "
    },
    {
        "ID": "4596",
        "Question": "We have an offshore development crew who has a bad habit of installing nonsense software on corporate desktops (which has nothing to do with their job function) and so are considering removing their local administrator rights. Is Local Administrator, or local Power User a requirement with VS2010?  How do you run without elevated rights?  What issues will you run into? ",
        "Best answer": "A programmer should work as a limited user with admin access. That is, the programmer should be the admin of the machine, but while working, he should always use a limited user account. If you need elevated rights to work, for anything but installing software, you're doing something very wrong. Worse, if you work as a power user or disable UAC prompts or the like, you're ignoring issues that will affect end-users of your software, forcing them to run with the same privileges you did. This is wrong. This is true, irrespective of the operating system you're on. Though Windows seems to be the only one where where it comes up. To clarify: When I say the developer should be a limited user, I mean that they should have full admin rights to the machine, but when they test their code, it should be done in a limited-user environment. For example, the developer could be operating the machine as an Admin-capable user, but runs all tests in a virtual machine or in a limited user account. On Linux, this means simply that the dev has sudo access; on Windows, this may mean an Administrator-level account with UAC and other security features fully enabled. "
    },
    {
        "ID": "4647",
        "Question": "There is a school of thought in linguistics that problem solving is very much tied to the syntax, semantics, grammar, and flexibility of one's own native spoken language. Working with various international development teams, I can clearly see a mental culture (if you will) in the codebase.  Programming language aside, the German coding is quite different from my colleagues in India.  As well, code is distinctly different in Middle America as it is in Coastal America (actually, IBM noticed this years ago). Do you notice with your international colleagues (from ANY country) that coding style and problem solving are in-line with native tongues? ",
        "Best answer": "Till now with my experience I have noticed that my native internationl fellow did the same job compared to the non-native. The issue arises when they tried to explain the concept or the requirement. Else I suppose the syntax name doesn't play much role until you read what excatly they do. Once a programmer acquires the knowledge of the syntax then it doesn't count what is the actual meaning of the word used for syntax. "
    },
    {
        "ID": "4662",
        "Question": "I want to know about Which language is best for long term career and How? Which language should I choose among Java and .NET Platform or Should I choose Oracle like DBMS Language (SQL/PLSQL)? I am confused? Detailed answer would be appreciated. ",
        "Best answer": "All of them. Both are solid technologies and they will stay in mainstream for long long time. Anyway the most characteristic of our career is change (evolution, new technologies introduction). You need learn new things forever. Technologies knowledge are not important to stay relevant on career, fundamentals, hard work, motivation and evolution is the key. "
    },
    {
        "ID": "4765",
        "Question": "Have you ever reached a point at your job when you just know it's time to move on?  When do you move to the point that you're willing to let go of the demons you know for the ones you don't know?  What was your deciding factor final straw so to speak when you finally faced the decision to find a new job?  ",
        "Best answer": "I had one job where I work up every morning wishing I was sick enough to go to the hospital so I wouldn't have to go to work.  At another job, I was working so many hours I was having trouble actually driving home at 2 or 3 am when I went home. Only job I ever quit without having another job, just physically couldn't take one more day and the final straw was when they asked me to do something unethical and illegal. Thanks to my exhaustion, I had a car accident in the parking lot the day I quit. Other signs it's time to move on:  You aren't sure if your paycheck will bounce or not You are part of a Death March The work is boring beyond belief You think someone is sabotaging you in terms of office politics  - you start getting fewer responsibilities and less interesting assignments and Joe is getting the credit for the things you did and you are starting to see emails blaming you for things that someone else did. You simply can't live with the corporate culture  "
    },
    {
        "ID": "4879",
        "Question": "Code needs to be written to file, on way or another. While all programmers should strive to write no more code than necessary, this \"small\" portion needs to be written nevertheless. What tips do you have for improving the code writing effort? Usage of IDEs? Different keyboards or character layouts? Minimal usage of mouse? Code generation tools? What else can you think of? ",
        "Best answer": "For me, an IDE with autocomplete is important. A programming language that requires less keystrokes would be nice (type less, read less) but keeping it understandable (unlike J). Keyboard layout: I don't think it's a problem. I switched the layout a few times (US/CH, PC/Mac), and after some time the brain adjusted. Code generation: I avoid them, except to generate getters, setter, and implement an interface. "
    },
    {
        "ID": "4889",
        "Question": "why not combine the best features of the all existent programming languages and fit it in a universal programming language? ",
        "Best answer": "For the same reason you don't use a Swiss army knife to carve a chicken...   The Swiss Army knife generally has a blade, as well as various tools, such as screwdrivers and can openers and many others. These attachments are stowed inside the handle of the knife through a pivot point mechanism... The design of the knife and its flexibility have both led to worldwide recognition...  "
    },
    {
        "ID": "4951",
        "Question": "What are the key differences between software engineers and programmers? ",
        "Best answer": "When hiring, we look for a distinction between someone who is going to be able to help us architect our system, define processes, create technical specifications, implement advanced refactoring, etc. and someone who is going to help us complete programming tasks off a checklist.  I believe you could call the former a Software Engineer and the latter a Programmer. "
    },
    {
        "ID": "5015",
        "Question": "I'm currently using Planning Poker to do our detailed estimates. This works great but relies upon a fairly detailed work breakdown. Often it takes 6-8 weeks to get a sufficiently detailed design and work breakdown. I've found the 6-8 weeks of analysis are often wasted as the estimate comes out so high it doesn't make economic sense to continue the project. I think providing a high-level estimate up front with a wide range might be better to weed out these shaky business cases. What tools and techniques exist for high-level initial estimates? Right now I just pick a previous project that \"feels\" the same and provide a -50%/+100% range. ",
        "Best answer": "If you are doing detailed planning poker sessions for all of the requirements up front, you are wasting a lot of time, as in my experience, detailed project requirements simply aren't that fixed, so you spend a lot of time estimating items that you never build, or are so greatly changed by the time you build them that the initial estimate is not valid. All estimates are guesses, but you can get better at estimating if you do it often and keep data about how accurate your estimates are. Estimation is best done at two levels, once initially on the project and another as an ongoing process within the project. First, when asked for a project estimate - estimate at the feature level, using your experience on previous projects. Keep the data on your previous initial estimates and see how you track against them. You can do this initial estimate similarly to planning poker, but don't break the work down into tasks. Simply give yourself some big buckets (increments of a half week or week for the features could work, but not much more granular than that) to estimate. If more than one team member is estimating, don't waste time on too much discussion at this point, just go with the most pessimistic estimate rather than getting down into the weeds. Second, as you work through your short project iterations (assuming that you do have short iterations), you pick the highest priority items and estimate them at the task level (and of course develop and deliver them). Once you've cycled through that first iteration you can see how accurate your detailed estimates are, as well as how they compare to your initial ballpark estimates. Now you can revise those initial estimates as you see how accurate they are, and once you have a few cycles under your belt you can give a confidence interval for the project completion date. The units for the ballpark estimate are a good communication tool for the precision of the estimate. Your initial units are in days or weeks, but your detailed estimates are in hours. "
    },
    {
        "ID": "5034",
        "Question": "I'd like to know at what point can be considerated an AI implementation?  I means, what is the minimal requeriment for that? Can you give a simple code example? ",
        "Best answer": "Any program in which the decisions made at time t are impacted by the outcome of decisions made at time t-1.  It learns. A very simple construct within the field of Neural Networks is a Perceptron.  It learns by adjusting weights given to different input values based on the accuracy of the result.  It is trained with a known set of good inputs.  Here is an article that covers the theory behind a single layer Perceptron network including an introduction to the the proof that networks of this type can solve specific types of problems:  If the exemplars used to train the perceptron are drawn from two linearly separable classes, then the perceptron algorithm converges and positions the decision surface in the form of a hyperplane between the two classes.  Here is a book chapter in PDF form that covers the topic.  Here is an Excel Spreadsheet that explains a bit more with a concrete example. And finally, here is a beautiful Javascript Example that you can watch learn.   "
    },
    {
        "ID": "5074",
        "Question": "What are the preferred use cases for the following sets of terms:  Log in / Log out Log on / Log off Sign in / Sign out Sign on / Sign off  From what I can guess, \"Logging in\" should be used for a long-lived session (like a website), whereas \"Sign in\" should be for something that you will be attending to (like IM or a financial transaction). I'm a little fuzzy here... ",
        "Best answer": "I've always used Login/Logout without the space.   I notice that Microsoft is preferential to Sign in/Sign out. "
    },
    {
        "ID": "5232",
        "Question": "I tend to understand things rather quickly, but after 2 years of programming in Python I still stumble across things (like Flask today) that amaze me. I look at the code, have no idea what's going on, and then feel very humbled. I feel like an absolute expert each time this happens, up until the moment it happens. Then, for about a 2 week period I feel like an absolute beginner.  Does this often happen, or does it indicated that I have so much more to learn before I can even be considered a \"good\" programmer? ",
        "Best answer": "You will never, ever, ever, ever, ever, in the entirety of your career, be in a position where you immediately understand every programming technology simply by looking at it.  There's just too much there.  Its the accumulation of research and knowlege of millions of individuals over many decades.  If you ever find yourself thinking you are at that point, seek a therapist to discuss your delusions. The trait you need most is the ability and willingness to learn.  If you have that, nothing will be beyond you. "
    },
    {
        "ID": "5341",
        "Question": "I've had a couple of times in the time I've working, moments when I get an error ocurring in just 1 computer and it often takes me hours or days to figure out because it is (or at least seems) an isolated incident as it is not being presented in any other instance of whatever I'm checking. How do you guys deal with this? I've often had to just change the computer per se (like formatting, or stuff like that) because I simply cannot replicat the issue. ",
        "Best answer": "You have to try to isolate what's different about that machine/environment to every other machine/environment where your application works. That will involve checking the state of your application by adding diagnostics, checking the state of the machine - which may involve remote logging or even physical access, and checking what the user is doing at every step of the way. I've had many problems that only repeated for one user or on one machine and it was only by understanding what they were doing and how they were doing it were we able to resolve things. "
    },
    {
        "ID": "5372",
        "Question": "Being a programmer is not a very healthy profession - long hours of sitting in front of a computer, with impending deadlines just over the cubicle. This takes a toll on the body and mind. So what tips do you have for programmers in order to stay healthy? ",
        "Best answer": " Join a gym that is close to work Walk/Bike to work Drink a lot of water at work (increase your water intake, and force you to take break to use the washroom, win-win situation)  "
    },
    {
        "ID": "5405",
        "Question": "When I get a new laptop, it usually takes me about two weeks to reinstall all my developer programs, utilities and tweak the O/S settings to how I like them.  I know there are utilities out there to backup/restore systems, but this is usually if it is on the same hardware.  What would you recommend? ",
        "Best answer": "Over the years I've come to this set of habits, which works well for me:  I stopped customizing so much. Before I used to tweak my desktop and Windows settings greatly. After a while I realized I grew dependent on these tweaks, and would get uncomfortable when working at a co-workers PC, on family members' PCs etc. Now I keep it down to just a few must-have changes, and generally keep my Windows and less important tools at default settings. I use multiple PCs, each dedicated to specific tasks. My work PC is a laptop, which I keep 'clean' for lack of a better word -- no private stuff, almost no games/multimedia/accessories, just my primary work tools. As such it rarely (actually, almost never) breaks, and I spend often keep the same Windows installation until it's time to replace the hardware (2-3 years). My home gaming PC on the other hand gets reinstalled far more frequently. But I don't care, it is easy to just reinstall and allow Steam to redownload all my games. Optional, use full-disk backup with system state. Actually I'm thinking about quitting this habit, because I haven't had to reload a system backup in ~3 years. But in the olden day Acronis Trueimage saved me a few times, by allowing me to just overwrite my full Windows + applications state with a known working backup. The built-in Windows Vista / 7 backup tool can AFAIK do something similar. Embrace Virtualization. I do all testing of new software in a VM, and I keep 'invasive' software (mostly enterprise server software) contained in VMs. I have my VMs on a external USB2 2.5\" HDD; it's not the fastest but it works for me.  "
    },
    {
        "ID": "5427",
        "Question": "Other than being annoyed at whitespace as syntax, I'm not a hater, I just don't get the fascination with Python. I appreciate the poetry of Perl, and have programmed beautiful web services in bash & korn, and shebang gnuplot.  I write documents in troff and don't mind REXX.  Didn't find tcl any more useful years ago, but what's the big stink about Python?  I see job listings and many candidates with this as a prize & trophy on their resumes.  I guess in reality, I'm trying to personally become sold on this, I just can't find a reason. ",
        "Best answer": "I've found Python to be the most natural programming language that I've ever written code in. I've coded in a lot of languages before and after Python, and to a greater or lesser extent, you have to fight the language to get it to do what you want. Python reduces this struggle massively. Eric S Raymond said it much better than I can in Why Python? As a related point, Python maintains its cleanness even while evolving rapidly. In most languages I've worked with, introduction of new language features introduces a lot of wrinkles. But with Python, even major language features (decorators come to mind) are added all the time, without feeling like ugly hacks. "
    },
    {
        "ID": "5466",
        "Question": "Sometimes I can't stand it when project managers ask me to estimate time to complete for various tasks.  An estimate is a guess, and guesses can be wrong.  Generally, bad requirements and documentation will lead to bad guesses. So I often wonder if the project managers were ever in my shoes trying to guess at how long task X and Y will take, and how difficult it is to assign a number to it based on what little is known and collected from the client. My question then is: Do good project managers need to have a programming background? Or maybe the question should be, do good project managers need to have been a good programmer before?  Is there any correlation? ",
        "Best answer": "Managing IT projects is definitely not the same as managing other types of projects. I once heard of a project manager with no IT experience. He ended up frustrating the programmers and basically scaring them away. On the other hand, a programmer that becomes a Project Manager may become a control freak, thinking he can fix things if (s)he can't get the programmers to do it properly (that has been my problem in similar situations) "
    },
    {
        "ID": "5473",
        "Question": "I was reading the wikipedia article on programming style and noticed something in an argument against vertically aligned code:  Reliance on mono-spaced font; tabular   formatting assumes that the editor   uses a fixed-width font. Most modern   code editors support proportional   fonts, and the programmer may prefer   to use a proportional font for   readability.  To be honest, I don't think I've ever met a programmer who preferred a proportional font.  Nor can I think of any really good reasons for using them.  Why would someone prefer a proportional font? ",
        "Best answer": "I used to use a proportional font, mostly because I find punctuation is actually easier to differentiate, but over time I've given up because nobody else does it and everybody unconsciously assumes mono spaced fonts (as the wikipedia article mentions, trying to do tabular formatting, ascii art in comments and so on). Plus, issues in Visual Studio, that Microsoft don't want to fix, basically make it impossible to use well-designed proportional fonts anyway. "
    },
    {
        "ID": "5490",
        "Question": "At my first workplace we were using Digital Standard MUMPS on a PDP 11-clone (TPA 440), then we've switched to Micronetics Standard MUMPS running on a Hewlett-Packard machine, HP-UX 9, around early 90's. Is still MUMPS alive? Are there anyone using it? If yes, please write some words about it: are you using it in character mode, does it acts as web server? etc. (I mean Caché, too.) If you've been used it, what was your feelings about it? Did you liked it? ",
        "Best answer": "Intersystems sell a MUMPS derivative : http://www.intersystems.com Some of the most interesting people in MUMPS are probably here : http://www.outoftheslipstream.com/ I started blogging about Cache (the MUMPS derivative) a couple of years ago : http://cachetastic.blogspot.com/ (but then changed jobs) Having been out of that world for a couple of years, my thinking is that the NoSQL movement is probably the best and worst thing to happen to MUMPS. Ultimately it's likely to both vindicate and kill it. Because somebody, at some point, is going to reinvent MUMPS's database and query structure almost identically, but with no connection to the MUMPS tradition. Then people will rave about this new storage system. But no-one will ever choose a MUMPS derivative again. For example, a month or two ago, I was talking with a colleague about using redis to cache a look-up of something in our Django application. We had a large number of records addressed by a triple of three keys, and needed to quickly get subsets matching one or two of these keys (but different combinations at different times). This is the kind of thing that MUMPS eats for breakfast. But we were finding it hard to squash into redis's key,val pair structure. Even with dictionaries. (Same would be true of memcached etc.) For the first time in my life, I found myself actually regretting that I couldn't write this module in Cache ObjectScript. Some more thoughts on Cache here : Good : http://cachetastic.blogspot.com/2008/07/ok-after-mentioning-some-bad-things.html Bad : http://cachetastic.blogspot.com/2008/07/some-mumps-dissing-and-more-positive.html "
    },
    {
        "ID": "5513",
        "Question": "In the past I have worked with designers, BAs and project managers, all who regularly produce project artifacts, yet very really do they understand the concept of versioning.  When I try to explain it to them (even in its most simple form of multiple differently named files) they seem to have some kind of mental block.  Why do you think this is? ",
        "Best answer": "This is because the human has difficulties projecting himself in time. Use the time machine analogy. Your life is versionned. Every day you have a new version of your life: new things and lost things. Hopefully more assets, less debts,... but more fat, less hairs, ... hopefully more knowledge, less doubts, .... Then you will have to explain branching ;) And there you hope they are fans of Fringe ;) "
    },
    {
        "ID": "5531",
        "Question": "I define defect as :  \"something within the application design or code which prevents it functioning as per requirements.\"  I'm looking for ideas about the causes of defects, eg the human factor, lack of testing, lack of prototyping, and possible ideas to mitigate these. ",
        "Best answer": "The prime cause of software defects is interpretation. The customer interpretation of a feature differs from the designer interpretation. The designer interpretation differs from the programmer interpretation. Most methodologies have invented ways to counter this effect. But in the end, we are only humans and we are not flawless. Besides, often there is a time pressure and most methodology magic is often skipped while under pressure. Testing can only detect the problems early. But even testers are human, and it is imposible to test 100%. If you want to release before the universe ends. "
    },
    {
        "ID": "5540",
        "Question": "How should code in version control be stored?  Developer friendly? so that programmer can quickly take the latest and able to run from his editor without doing many changes? (like config files pointing to dev DB..etc) or  Should it be production friendly? source should be in a manner which is easy to deploy on production environment and when developer takes the latest, he should perform changes as per his development needs. ",
        "Best answer": "Why choose ? It should be both. Your development environment should be configured so it's as easy as doing a checkout, open, build, run, debug (eg: no absolute path!). You can do that easily with compilation directives, configuration class + dependancy injection, or even tricks like the perso.config in ASP.NET Your automated build script should be customized enought to take care of specific production configuration, clean up, packaging etc. "
    },
    {
        "ID": "5560",
        "Question": "It's all the rage nowadays. \"Everyone\" recommends it. That in and of itself makes me suspicious. What are some disadvantages you have found when doing test-first (test-driven) development? I'm looking for personal experiences from knowledgeable practitioners--I can read the hypothetical musings of a hundred wannabes elsewhere on the internet. I ask not because I am looking to hate TDD, but because it is my job to improve software development process, and the more we can learn about the problems people encounter, the better chance we have of improving the process. ",
        "Best answer": "There are quite a few, but the advantages far outweigh the disadvantages. There's a steep learning curve. Many developers seem to expect that they can be efficient with test-first programming right from day one.  Unfortunately it takes a lot of time to gain experience and program at the same speed as before.  You can't get around it. To be more specific, it's very easy to get wrong.  You can very easily (with very good intentions) end up writing a whole bunch of tests which are either difficult to maintain or testing the wrong stuff.  It's difficult to give examples here - these kind of issues simply take experience to solve.  You need to have a good feel of separating concerns and designing for testability.  My best advice here would be to do pair-programming with someone who knows TDD really well. You do more coding up front. Test-first means you can't skip tests (which is good) and means you'll end up writing more code up front.  This means more time.  Again, you can't get around it.  You get rewarded with code that's easier to maintain, extend and generally less bugs, but it takes time. Can be a tough sell to managers. Software managers are generally only concerned with timelines.  If you switch to test-first programming and you're suddenly taking 2 weeks to complete a feature instead of one, they're not gonna like it.  This is definitely a battle worth fighting and many managers are enlightened enough to get it, but it can be a tough sell. Can be a tough sell to fellow developers. Since there's a steep learning curve not all developers like test-first programming.  In fact, I would guess that most developers don't like it at first.  You can do things like pair-programming to help them get up to speed, but it can be a tough sell. In the end, the advantages outweigh the disadvantages, but it doesn't help if you just ignore the disadvantages.  Knowing what you're dealing with right from the start helps you to negotiate some, if not all, of the disadvantages. "
    },
    {
        "ID": "5564",
        "Question": "Need a Free, Fast(development and runtime) and Reliable(transactions and locking) tool set for creating an enterprise application for SMBs. I'm thinking of an application framework + UI framework + DB which will help me in developing the software faster.  As it is known, business softwares need lot of similar UIs to be created.  My idea is ...to create a new form with N number of fields and connecting it to the database for basic CRUD operations within 30min to 1hr.  I got the taste of Intersystems Cache technology stack with an app framework on top of it. To be frank...it is amazing...  I'm looking out for something similar to this in opensource. Any suggestions? ",
        "Best answer": " What is the best toolset for living a   fullfilling life for suburban   professionals? Need a convenient, functional toolset   for living my life.  I'm thinking of a   moral code + religion + culture which   will help me life happier and better.  Ok I couldn't help myself.  You're asking for religion and any answer you get will be based more on personal preferences than one being actually \"better\" than another.   That being said, go with Ruby.  It's free, fully functional and comes with a lot of stuff, like Rails and an active community.  And, you get to look down on everyone else as a bonus. My background is in Java and .NET, but if I had to start from scratch at this moment, I'd probably learn Ruby. "
    },
    {
        "ID": "5597",
        "Question": "I've been doing design and programming for about as long as I can remember. If there's a programming problem, I can figure it out. (Though admittedly Stack Overflow has allowed me to skip the figuring out and get straight to the doing in many instances.) I've made games, esoteric programming languages, and widgets and gizmos galore. I'm currently working on a general-purpose programming language. There's nothing I do better than programming. Is a university education really more than just a formality? ",
        "Best answer": "Hooboy.  This is a tough position to be in; you have my sympathies. I'm biased towards getting a degree, most likely because 1) I have one (BS in Computer Science) and 2) I've often found the knowledge gained pursuing it to be very useful.  But it's hardly a pre-requisite for a successful career; the IT world is rich with people who kick ass, are acknowledged as kicking ass, and who technically don't have more than a high school diploma. The nice thing about a university degree is that you can put it on hold and come back to it later when life permits.  (Though the dangerous thing about the previous sentence is that it's a good way to simply quit without admitting to yourself you're quitting.)  You can test the waters and see what kind of job you could get by sending your resume out today and seeing what kind of nibbles you get; you haven't committed to anything until you actually say yes to a job offer. And it sounds like your school is a bad fit for you, regardless.  If you're so consistently bored with everything they're throwing at you, then you may need to find a school that will do a better job of giving you your money's worth and making you work for that degree.  Have you considered transferring somewhere better?  Edit:  Based on your comments elsewhere, given how much you love the high-level theoretic aspects of programming, have you considered that the best way to continue to explore that and get paid may be a career in academia?  Which would definitely require you to get your degree.  :-) "
    },
    {
        "ID": "5613",
        "Question": "With all of the frameworks available these days, ORMs, dependency injection (DI), Inversion of control (IoC), etc., I find that many programmers are losing or don't have the problem solving skills needed to solve difficult issues. Many times, I've seen unexpected behaviour creep into applications and the developers unable to really dig in and find the issues. It seems to me that deep understanding of what's going on under the hood is being lost. Don't get me wrong, I'm not suggesting these frameworks aren't good and haven't moved the industry forward, only asking if, as a unintended consequence, developers aren't gaining the knowledge and skill needed for deep understanding of systems. ",
        "Best answer": "This is an argument that pops up regularly, in many fields and in many forms. The general form of this argument is: Does having [x:tool/technology] make people worse at [y:function affected by x]? For example:  Does CAD software make for worse engineers? Do calculators in high school make students worse at math? Does social software stunt people's in-person social skills? Does accounting software produce worse accountants?  From memory, the ubiquitous answer is almost always: not really. You'll always have people that are good and bad at doing [y] but now they're just bad at a different facet of the skill.  A deeper understanding of the fundamentals with any job is going to help, no matter what you do - even jobs that are considered 'remedial'. Knowledge always helps. "
    },
    {
        "ID": "5705",
        "Question": "I've used Emacs quite a bit, and I'm comfortable with the most basic commands/shortcuts, but I know Emacs has a lot more to offer than what I'm using. What are some of the lesser known features of emacs that can help me become a more productive programmer? ",
        "Best answer": "Learn elisp.     It allows you to program any shortcut you can think of.  Any time you find yourself performing a multi-step process for something useful, you make a function out of it and bind it to a hotkey combo. It lets you experiment with functional programming - learning a new paradigm is a good way to expand your horizons.  "
    },
    {
        "ID": "5727",
        "Question": "Especially when writing 'standard' (non-HPC) applications, do you consider what sorting algorithm to pick, or just settle with quicksort (which is what most libraries just call sort)? To some extent it may be profitable in specific situations, but on the other hand proper optimization requires some time to analyse the problem and make benchmarks.  ",
        "Best answer": "In general, using the default methods unless there is a specific need to do something more exotic keeps everything a lot more readable/understandable down the road IMHO. If you experience (or in some cases, strongly suspect) that you have a performance problem that is the time to add complexity. On the other hand, if you are using a low enough language that there is not a built-in sort for the kind of objects you need to sort try to pick one or two that cover all your bases and implement those. "
    },
    {
        "ID": "5748",
        "Question": "I'm not talking about a diff tool.  I'm really looking to see if a project contains code that may have been \"refactored\" from another project.  It would be likely that function names, variable names and whatnot would be changed.  Conditionals might be reversed, etc. ",
        "Best answer": "You might be able to use the PMD tool to find what you are looking for.  It is meant to detect cut and paste within a code base but if you include the suspected origin project source it might help you see where code was copied from it. "
    },
    {
        "ID": "5898",
        "Question": "In another question, it was revealed that one of the pains with TDD is keeping the testing suite in sync with the codebase during and after refactoring. Now, I'm a big fan of refactoring. I'm not going to give it up to do TDD. But I've also experienced the problems of tests written in such a way that minor refactoring leads to lots of test failures. How do you avoid breaking tests when refactoring?   Do you write the tests 'better'? If so, what should you look for?  Do you avoid certain types of refactoring?  Are there test-refactoring tools?  Edit: I wrote a new question that asked what I meant to ask (but kept this one as an interesting variant). ",
        "Best answer": "What you're trying to do is not really refactoring.  With refactoring, by definition, you don't change what your software does, you change how it does it. Start with all green tests (all pass), then make modifications \"under the hood\" (e.g. move a method from a derived class to base, extract a method, or encapsulate a Composite with a Builder, etc.).  Your tests should still pass. What you're describing seems to be not refactoring, but a redesign, which also augments the functionality of your software under test.  TDD and refactoring (as I tried to define it here) are not in conflict.  You can still refactor (green-green) and apply TDD (red-green) to develope the \"delta\" functionality. "
    },
    {
        "ID": "5916",
        "Question": "Someone once said we should prefix all our methods with the  /// <summary> comment blocks (C#) but did not explain why. I started to use them and found they annoyed me quite a bit, so stopped using them except for libraries and static methods. They're bulky and I'm always forgetting to update them.  Is there any good reason to use /// <summary> comment blocks in your code? I normally use // comments all the time, it's just the /// <summary> blocks I was wondering about. ",
        "Best answer": " Use them as much as possible.  Yes, those are special comments that become the documentation for the method. The contents of <summary>, the parameter tags, etc. that are generated show up in intellisense when you or someone else is getting ready to call your method.  They can essentially see all the documentation for your method or class without having to go to the file itself to figure out what it does (or try to just read the method signature and hope for the best). "
    },
    {
        "ID": "6042",
        "Question": "I offered to do a little bit training in F# at my company and they seemed to show some interest. They are generally VB6 and C# programmers who don't follow programming with too much passion. That being said I feel like it is easier to write correct code when you think in a functional matter so they should definitely get some benefit out of it. Can anyone offer up some advice on how I should approach this? Ideas  Don't focus on the syntax, instead focus on how this language and the idioms it promotes can be used. Try and think of examples that are a pain to write in an imperative fashion but translates to elegant code when written in a declarative fashion.  ",
        "Best answer": "I would recommend:  the presentation Taming Effects with Functional Programming by Simon Peyton-Jones the book Real World Functional Programming: With Examples in F# and C# by Tomas Petricek and Jon Skeet  "
    },
    {
        "ID": "6045",
        "Question": "Some projects we run internally using are Scrum, while still being \"fixed everything\" to the customer.  We're experiencing mixed success on our part (the customer likes the visibility of the burndown chart). Can the types of projects we work be successfully executed using the agile methods? ",
        "Best answer": "I would like to pose a counter-question: Can fixed scope + fixed deadline + fixed price contract ever be made to work, period? The \"good/fast/cheap - pick two\" saying isn't just some silly engineering joke.  Every project manager worth his salt knows about the Project Management Triangle:  You're telling us that the cost, scope, and schedule are all fixed.  That leaves no room for maneuverability or error.  None.  You could choose to view \"Quality\" as an attribute, but it's not a \"real\" attribute, it's more like a meta-attribute that's derived from the other attributes (cost/scope/schedule). The problem is that this never happens in reality as long as your project is being planned and executed by humans.  Requirements and specifications never cover every edge case unless they've been drawn up in immense detail by qualified architects and designers, in which case the project is already half-done; and even then there's still the possibility of error. Unexpected costs will pop up leading to budget overruns.  A subscription expired.  A manufacturer discontinued their support for a product you're using and you have to find a new one.  An hourly contractor raised his rate under threat of departure.  Your entire team just went on strike, demanding a 10% raise and an extra week of vacation. Schedules slip.  Unforeseeable problems crop up; that charting component you've been using for 5 straight years isn't compatible with Windows 95, which your client is still using.  An obscure bug in 64-bit Windows causes serious UI glitches and you spend nearly a week tracking it down and developing a workaround (this actually happened to me).  Your senior developer got hit by a bus and you have to go recruit and train a new one.  Your estimated delivery date is always wrong.  Always. See Hofstadter's Law:  Hofstadter's Law: It always takes longer than you expect, even when you take into account Hofstadter's Law.   Agile methods are all about juggling around the cost, schedule, and scope.  Most of the time, they're specifically about juggling around the scope and sometimes the schedule, which is why you start with nebulous user stories and plan revisions instead of full versions.  Different methodologies use different terminology but it's all the same basic premise: Frequent releases and a rebalancing of the schedule and scope with each release. This makes no sense with a project that is (or claims to be) either fixed scope or fixed schedule. If one project attribute (cost/scope/schedule) were fixed, I would tell you that it might not be a good fit for agile methodologies. If two project attributes are fixed, then your project is definitely not a good fit for agile methodologies. If all three attributes are fixed, then your project is probably going to fail.  If it actually ships, then either the original schedule was massively fudged, or the client has managed to delude itself into thinking that you actually delivered what was promised. If this contract is still on the table, I urge you to reject it.  And if you've already accepted it, may God have mercy on your soul. "
    },
    {
        "ID": "6190",
        "Question": "I am planning to create a utility, which will query the database and store some information (on another table in the database). Its a multi-threaded utility and require to run for every 5 or 10 minutes/later may be thrice in a day. I see two options to achieve this in C#/DotNet programming.   creating windows service having timer approach inside it. a console program and schedule it using windows task scheduler.  Which one do you prefer and why?  ",
        "Best answer": "Services are either used for administrative purposes or to offer a service to multiple applications. Schedules are used for running a task multiple times which don't necessarily require extra permissions. "
    },
    {
        "ID": "6255",
        "Question": "Joel Spolsky said in one of his famous posts:  The single worst strategic mistake   that any software company can make:    rewrite the code from scratch.  Chad Fowler wrote:  You’ve seen the videos, the weblog   posts and the hype, and you’ve decided   you’re going to re-implement your   product in Rails (or Java, or .NET, or   Erlang, etc.). Beware. This is a longer, harder, more   failure-prone path than you expect.  Have you ever been involved in a BIG Rewrite? I'm interested in your experience about this tragic topic, and in particular, in any big rewrite that was completed succesfully (if any). ",
        "Best answer": "I've been involved in a few rewrites over my career and they were all disasters. I think they all fail for the same reasons  Vast underestimate of effort required:  Every time someone wants a rewrite, it's because the old system is using old technology and difficult to maintain.  What they fail to consider is that because of it's age, it may have 30-40 man years of development effort into it.  Thinking you can then rewrite the whole thing in 6 months with a team of 5 is silly. Lost knowledge:  The old system has been around so long, it does a lot of stuff, and is hooked into everything.  There is no up-to-date documentation, and no single point of authority that actually knows all the things the system does.  There will be pieces of knowledge with particular users in particular departments, and finding them all is difficult or impossible. Poor Management Decisions: The rewrites I've been involved in had a similar expectations from management: The new system should be 'done', and the old system could simply be turned off on a particular date, period.  No other option was acceptable.  I think they get this in their head, because they are spending all this money to hire new people for this huge project.  In reality, the better risk mitigation strategy is to rewrite the major functions of the old system, say tackle 50-75% of the old system for a first release, and then see how it works!  Because of #1 and #2 above, this would probably work out much better, as we find out some of the features that were missed, and what's needed to actually turn off the old system.  "
    },
    {
        "ID": "6394",
        "Question": "When drafting a project proposal, do you use any standard template?  What features/information should be included? What is nice to have included? What sort of boiler plate information should I shove in? Do you find any design pattern or concept particularly helpful? ",
        "Best answer": "Have you ever looked at the Volere Requirements Template?  While it contains a little too much detail for my taste, particularly for a proposal (it's better suited for detailed up front requirements specification), the section headings are a great checklist to make sure you've thought about all of the different moving parts before giving an estimate or creating a proposal document. Here they are:  PROJECT DRIVERS  The Purpose of the Product Client, Customer and other Stakeholders Users of the Product   PROJECT CONSTRAINTS  Mandated Constraints Naming Conventions and Definitions Relevant Facts and Assumptions   FUNCTIONAL REQUIREMENTS  The Scope of the Work The Scope of the Product Functional and Data Requirements   NON-FUNCTIONAL REQUIREMENTS  Look and Feel Requirements Usability Requirements Performance Requirements Operational Requirements Maintainability and Portability Requirements Security Requirements Cultural and Political Requirements Legal Requirements  PROJECT ISSUES  Open Issues Off-the-Shelf Solutions New Problems Tasks Cutover Risks Costs User Documentation and Training Waiting Room Ideas for Solutions   "
    },
    {
        "ID": "6395",
        "Question": "What tools and techniques do you use for exploring and learning an unknown code base?  I am thinking of tools like grep, ctags, unit-tests, functional test, class-diagram generators, call graphs, code metrics like sloccount, and so on. I'd be interested in your experiences, the helpers you used or wrote yourself and the size of the code base with which you worked.  I realize that becoming acquainted with a code base is a process that happens over time, and familiarity can mean anything from \"I'm able to summarize the code\" to \"I can refactor and shrink it to 30% of the size\". But how to even begin? ",
        "Best answer": "How do you eat an elephant?  One bite at a time :) Seriously, I try to talk to the authors of the code first.  "
    },
    {
        "ID": "6417",
        "Question": "It's not uncommon for projects to fail. As a programmer, how do you deal with projects that fail? Some definitions of failure:  Misses deadline. Code and functionality does not do what it's supposed to. Software becomes vapor-ware or endless number of phases, essentially undeliverable.  Or maybe you have your own definition(s) of failure. Do you start pointing fingers?  Do you blame yourself, the requirements, the technology, the management, the client, etc?  Do you do a lessons learned session as a team? ",
        "Best answer": "You should do lessons learned for all projects, failed or succeeded. There is a lot to learn from a good project.  True failed projects have been very rare for me. In addition to understanding what happened, I do the \"ask why 5 times\" thing to try to get to underlying causes. There is also the matter of why I didn't notice what was happening and either do something about it or at least get out. I think everyone's first position is to blame everything - the client, the tech, the business problem being tackled, the methodology, the team members, the language, the platform, heck even the way we take our coffee in the morning. The nice thing about a retrospective (even if it happens only in your own head) is the chance to reconcile with some or all of those factors and realize they weren't the issue. In my only real failure of the last 30+ years, the project had been in requirements for literally years when we arrived. We got requirements settled. One came from management and hundreds from the end users. We wrote code, lots of code, some of it brilliant. There was testing and acceptance testing and changes and arguments and change requests and unpaid work and paid work and last minute bolt ons and surreal humour and escalations to VPs and all of that. Eventually it just all kind of stumbled to a halt. The reason for the failure was that the single management requirement was unacceptable to the end users. And no matter how many things they got their way on, they could not get past that one and would never accept the system. But management would not have it any other way. So that was that and though we got a lot of money it was, in the end, all horrible. I still work in that technology, I still use those processes and I still work with the same people. I would even do another project for that client. But when the end users say they don't like something their own management has injected into the requirements, I will remember that writing good code that works does not protect you from a failed project. And I will do something about it then, not a year or two later. "
    },
    {
        "ID": "6587",
        "Question": "Recently reading the question What languages do you use without an IDE? One question asked in a few answers was \"is Notepad++ and IDE?\" One answers to the original question said \"None, I use vim...\", implying that vim is an IDE. But then another answer suggested vim isn't an IDE. So where is the line? What about notepad, ed, or nano? Is the only non-IDE coding technique the butterfly technique? ",
        "Best answer": "Taken literally, IDE = Integrated Development Environment. This is the way i look at it:  Integrated: Means you can code / launch / compile / debug your app from the tool. Development: Means it can group files into projects, and does syntax highlighting for your language, maybe has refactoring tools, ability to generate files from templates (like unit test files, class files etc.), auto complete / intellisense Environment: Means both of the above are available from the same tool  Notepad++ allows for development (eg. you can write code), but the other areas of development are not covered. I've never used notepad++ for development, only for occasionally editing files.   "
    },
    {
        "ID": "6633",
        "Question": "I always had this question in mind but couldn't find a proper place to ask. There are some really nice and great open source free software available on the net. How do these products sustain themselves financially? It is one thing writing a small utility which does something nice but writing a complicated product with whole lot of features is a totally different ball game. So to repeat myself again, how do they work financially? ",
        "Best answer": "There's lots of different answers. Some projects are maintained by people who just want to do it for assorted reasons, including prestige or the knowledge that they're doing something good or because they thought somebody had to do it and nobody else was.  This section is almost certainly not as large as it was. Some projects are maintained by people who want to be paid for support and the like.  Most Open Source companies are like that:  they want to create a popular product for free so that they can charge for related things.  It's a form of advertising. Some projects are maintained by companies who aren't in that exact business.  Quite a few companies benefit from being able to use Linux, for example, or Apache, because they then have access to high-quality software that they don't have to write all themselves.   Suppose your company wants to sell web servers.  You want to have as much of the customers' money going to you as possible.  If you sell them Windows-based servers with IIS, a chunk of that money is going to Microsoft.  If you sell them Linux-based servers with Apache, you get to keep that money, and you have a lot more control over what you sell.  That may well be worth donating resources to assorted projects.  (Obviously, Microsoft has the opposite opinion.  They'd like the server people to produce cheap hardware that runs Windows and IIS.  Microsoft is likely the company most inherently opposed to Open Source, but even they take advantage of it in some ways.) Let's look at Apple's use.  Apple makes their money selling hardware, but the main distinguishing feature is their ability to make user interfaces.  The iPhone does nothing previous smart phones didn't do, it's just a lot easier to use, and so it sold millions really fast and redefined the market.  They have a good idea as to what they're selling.  Nobody's going to buy Apple for operating internals, so by having the Darwin part of the OS as Open Source they can get some outside help on it.  They also started with Open Source after failing to produce a top-quality operating system themselves.  Nobody's going to buy Apple for the printer software, so it was easier and faster to use CUPS.  They will for the interface, so that's closed down tight. "
    },
    {
        "ID": "6662",
        "Question": "I've been on the constant road of learning new concepts in OOP, Software Design, Architecture, etc. But there are times when you are in a team where those concepts are foreign to them and they don't have the time or the same eagerness to learn as you. The problem is if you design your code the \"right\" way, the people who code with 2kLOC classes won't understand it. Would you sacrifice good coding principles to support your team? What about a scenario where this will be a long term arrangement? ",
        "Best answer": "Welcome in the real world. I worked with hundred of different developers around the world, in startups and large enterprises. The vast majority of them doen't understand advanced concepts, and won't in the future. It's just too complicated to master something unless you spend over a decade in that particular field. Very few are able to do that. That's why I'm really upset when one of my developers is too \"CV driven\" and try to implement design patterns that do nothing better but allow him to put something new in his resume (or the title \"Architect\"), while the rest of the team is strugling to understand and maintain HIS code. That's why I think that a good developer is not the technically supperior, but the most pragmatic of the pack:  An excellent developer try to convert   a functionnality the business ask by   maximizing the ROI.  IMHO, keeping things simple, is the way to go. If you want to do the \"right\" stuff, do it at home. Your boss is especting something else from you. "
    },
    {
        "ID": "6665",
        "Question": "The class diagram is modeled on the system requirements, and it is important to create solutions based on those requirements. If I have said class diagram should I strictly adhere to it? What about refactoring? What if the diagram did not provide some design principle that I feel were left out? ",
        "Best answer": "Short Answer: No.  Your output should be working (hopefully tested) code that performs the business function it's supposed to do. How you accomplish that task shouldn't be mandated (again, unless you work for NASA).  A lame analogy: I get into a taxi and tell them where to go. I leave it up to them to drive me there. I trust them to get me there safely and in a timely manner. I am not going to sit there and micromanage the taxi driver and tell him when to turn on his turn signal, how much to press the accelerator, or when to get gas. That's his job.  "
    },
    {
        "ID": "6677",
        "Question": "The way I see it if you create one before you get the advantage of:  Planning ahead Overview of the project  but you lose:  Time (doing work you'll probably end up repeating when writing code)  On the other hand, I could just create them all after writing my code just to keep it as a reference for future developers. Which one serves the purpose of class diagrams and which is more advantageous? ",
        "Best answer": "When I've had them created before coding, we view them as \"temporary\" documents. That is, we create the diagrams and get our thoughts onto paper. We start coding from those class diagrams. We then throw them out. It's not worth spending the time to maintain them once coding has started. And if you want up-to-date class models, use a tool to create them from the code.  "
    },
    {
        "ID": "6815",
        "Question": "As I advance in my career, I have found that I do less technical work and more project management work.  I joke that I am getting dumber every day.  Each time I go back to doing technical work it seems to be a little harder to get things going.  What suggestions do people have for maintaining technical expertise throughout your career? ",
        "Best answer": "Keep on coding I've always tried to steer away from a position where I'm forced to do more management than coding.  In fact it's something I always point out in interviews - I'm a coder - always will be. I would say that's #1 on keeping your technical skills sharp - as simply as it sounds - keep on coding.  Whether or not that's what you want to do is a different story. You can also try being more involved with group code reviews.  Not only is this a great way of sharing knowledge and elimination key-person dependency, it will also show you what's going on in the codebase and keep your skills sharp. The problem (in my opinion) with programmers moving into project manager positions is that there is absolutely nothing that says if you're good at programming you will be good at project management.  In my experience the exact opposite is usually true. "
    },
    {
        "ID": "6827",
        "Question": "This includes architecture decisions, platform choices or any situation where a such a bad choice led to negative consequences. ",
        "Best answer": "Years ago, I was the lead developer on a database centered application that started throwing errors. I tracked it down to the fact there were duplicate values in a database field that shouldn't have allowed them.  I was beating myself up about forgetting to set a unique constraint on the database when I had pushed it to production because it was just so obvious that this field needed one. I commiserated to one of my fellow developers who corrected me... Other Developer: \"Oh you didn't forget, there was a unique constraint on that field. I just removed it.\" Me: \"Why did you remove it?\" Other Developer: \"I did that a few weeks back. I was getting data files from the customer and they wouldn't import because the unique constraint was blocking the new data. So I removed the constraint so that I could finish importing it.\" Me: \"Did you stop to consider that maybe there was a problem if we were getting new data that overlapped with existing data and think about mentioning it to someone before importing it?\" Other Developer: (blank stare) Me: Facepalm. "
    },
    {
        "ID": "6834",
        "Question": "Modern IDEs have a lot of tricks up their sleeves to help with code writing, refactoring,  searching. All those are very helpful, but rarely any of them looks like a real \"magic\" and makes me think \"Wow! How did it figure that out?\" Can you name any impressive IDE code automation (or other) features that blew your mind first time you saw them? ",
        "Best answer": "Backwards Debugging Visual Studio 2010 (and now 2012) lets me debug backwards with IntelliTrace. Never again will I have to re-live the moment where I hit F10 one too many times and have to restart debugging. "
    },
    {
        "ID": "6884",
        "Question": "I'm sure that many of you have encountered a bad client. I'm also sure you took some measures to prevent such encounters in the future. What is the most influential characteristic of a client that warns you to walk away? ",
        "Best answer": "Some time ago I read 6 Warning Signs of a Problem Client and found it a good 'bad client smell' list.  Have you ever had a project that turned out to cause way more stress that it was worth? Of course you have. We all have. Most of the time you’re left saying “Why didn’t I see this coming?” Here are some early warning signs of a problem project and some tips for upgrading them from hopeless to profitable. 1. “I tried doing it myself, but…” 2. There’s No Real Deadline 3. “Somebody Told Me I Should…” 4. Multiple Points Of Contact 5. “Trust Me, This Is Going To Be Huge!” 6. Repeated Meeting Cancellations ...  "
    },
    {
        "ID": "6905",
        "Question": "I've used TestNG and JUnit.  What other frameworks are out there? What makes them special and/or different from the rest? ",
        "Best answer": "I suggest to use TestNG as core unit test framework for Java project, because TestNG is more advance in parameterize testing, dependency testing and suite testing (Grouping concept). TestNG is meant for high-level testing and complex integration test. Its flexibility is especially useful with large test suites. In addition, TestNG also cover the entire core JUnit4 functionality. It’s just no reason for me to use JUnit anymore. "
    },
    {
        "ID": "6974",
        "Question": "What's the worst programming-related or technical book you've ever read? This can be any book which one way or another can be connected to programming, as long as it's not fiction. ",
        "Best answer": "Any book that allows you to teach yourself X in Y hours. I've read some in the past but once read you don't know any details whatsoever about X and you can't use the book as a reference for X either. After discovering that it seems better to go for the big books.  "
    },
    {
        "ID": "7000",
        "Question": "Processors are getting more and more cores these days, which leaves me wondering... Should we, programmers, adapt to this behaviour and spent more effort on programming for multiple cores? To what extent should we do and optimize this? Thread? Affinity? Hardware optimizations? Something else? ",
        "Best answer": "No matter how good you are, it will be unlikely that you'll come up with a better scheme of managing threads etc. than the teams developing the language and compiler you are writing your code in. If you need your application to be multi-threaded then create the threads you need and let the compiler and OS get on with their jobs. You do need to be aware of how those threads are managed so you can make best use of the resources. Not creating too many threads is one thing that springs to mind as an example. You also need to be aware of what is going on (see Lorenzo's comment) so you can provide hints to the thread management (or override it in special cases), but I would have thought that these would be few and far between. "
    },
    {
        "ID": "7008",
        "Question": "What different types of security do there exist? Why and when should they be implemented? Example: SQL Injection Prevention ",
        "Best answer": "Preventing Buffer overflow  a buffer overflow, or buffer overrun, is an anomaly where a program, while writing data to a buffer, overruns the buffer's boundary and overwrites adjacent memory. This is a special case of violation of memory safety. Buffer overflows can be triggered by inputs that are designed to execute code, or alter the way the program operates. This may result in erratic program behavior, including memory access errors, incorrect results, a crash, or a breach of system security. Thus, they are the basis of many software vulnerabilities and can be maliciously exploited...  I cannot count exploits that are based on this. "
    },
    {
        "ID": "7038",
        "Question": "I'm using VS 2010 since we're developing an app in .Net 4 and the performance is driving me crazy. It's mostly bad when I don't view the IDE for a while (such as when I get pulled away for a help desk call or come in in the morning).  I realize it's probably built in WPF which unloads its resources when unused, but the few minute delay while it loads everything back up is really annoying. I've also noticed some significant delays when opening files or compiling. ",
        "Best answer": "Get a faster machine? "
    },
    {
        "ID": "7055",
        "Question": "Which design pattern do you think is the most popular? ",
        "Best answer": "I'm pretty sure the most common is 'The Big Ball of Mud'.  Unfortunately for us all.  http://en.wikipedia.org/wiki/Big_ball_of_mud "
    },
    {
        "ID": "7057",
        "Question": "How should I be keeping track of a php script's versions/changes when it pertains to a single script in one file? Should I have a separate changelog, and if so (1) what should it be named, (2) how should the contents of the log be formatted, and (3) how should the log be associated with the php script/file? Or, should I include the changes in a comment at the top of the php file?  Currently, I have the following comments at the top of the file:  /**  * @author    John Doe <contact@John Doe.com>  * @version   1.0  * @copyright Copyright (c) 2010, John Doe  */   Thanks in advance for your response! ",
        "Best answer": "Aren't you using a VCS such as SVN, Git or Mercurial? There's no better way to keep track of the changes than being able to see the difference of the file. Of course, you would want to include the changelog on both: the main comment block and the last commit you do. "
    },
    {
        "ID": "7157",
        "Question": "I was wondering if there was a standard for laying out a class's regions.  I currently use Fields Constructor Properties Public Methods Private Methods  Fields being Private Properties and Properties being the public ones. I'll normally use subregions within that if needed, or will occasionally add other regions below (such as interface or baseClass members).  ",
        "Best answer": "Sub Regions? Does your class have a Single Responsibility? (implicit in that ... my answer is \"Rarely any regions, except maybe to group properties, constructors and methods\"... but even then, I don't use it that much) "
    },
    {
        "ID": "7166",
        "Question": "Thoughts on these?  Python is one example, and no this is not a stab against Python I like the language.   What languages have a indentation requirement? ",
        "Best answer": "In Makefiles, it's annoying. In python, I find it very apropos and it makes the syntax a lot cleaner. I think the thing that makes it better in python is that no special characters are required, the only requirement is that you be consistent. You should be doing it anyway, so you get no cost added by following it. "
    },
    {
        "ID": "7217",
        "Question": "Most programmers defending methodologies politically correct like Agile, Waterfall, RUP, etc. Some of them follow the methodology but not all of them. Frankly, if you can choose the methodology, you certainly would go to mainstream \"correct\" methodologies or you would prefer the \"easier\" methodology like cowboy programming? Why? I know it depends. Please, explain when you would use one or another. Please, say what advantages do you see on Cowboy coding. See about Cowboy coding on Wikipedia ",
        "Best answer": "I think almost every experienced programmer has gone through three stages and some go through four:  Cowboy coders or nuggets know little to nothing about design and view it as an unnecessary formality.  If working on small projects for non-technical stakeholders, this attitude may serve them well for a while; it Gets Things Done, it impresses the boss, makes the programmer feel good about himself and confirms the idea that he knows what he's doing (even though he doesn't).  Architecture Astronauts have witnessed the failures of their first ball-of-yarn projects to adapt to changing circumstances.  Everything must be rewritten and to prevent the need for another rewrite in the future, they create inner platforms, and end up spending 4 hours a day on support because nobody else understands how to use them properly.  Quasi-engineers often mistake themselves for actual, trained engineers because they are genuinely competent and understand some engineering principles.  They're aware of the underlying engineering and business concepts: Risk, ROI, UX, performance, maintainability, and so on.  These people see design and documentation as a continuum and are usually able to adapt the level of architecture/design to the project requirements. At this point, many fall in love with methodologies, whether they be Agile, Waterfall, RUP, etc.  They start believing in the absolute infallibility and even necessity of these methodologies without realizing that in the actual software engineering field, they're merely tools, not religions.  And unfortunately, it prevents them from ever getting to the final stage, which is:  Duct tape programmers AKA gurus or highly-paid consultants know what architecture and design they're going to use within five minutes after hearing the project requirements.  All of the architecture and design work is still happening, but it's on an intuitive level and happening so fast that an untrained observer would mistake it for cowboy coding - and many do. Generally these people are all about creating a product that's \"good enough\" and so their works may be a little under-engineered but they are miles away from the spaghetti code produced by cowboy coders.  Nuggets cannot even identify these people when they're told about them, because to them, everything that is happening in the background just doesn't exist.   Some of you will probably be thinking to yourselves at this point that I haven't answered the question.  That's because the question itself is flawed.  Cowboy coding isn't a choice, it's a skill level, and you can't choose to be a cowboy coder any more than you can choose to be illiterate. If you are a cowboy coder, then you know no other way. If you've become an architecture astronaut, you are physically and psychologically incapable of producing software with no design. If you are a quasi-engineer (or a professional engineer), then completing a project with little or no up-front design effort is a conscious choice (usually due to absurd deadlines) that has to be weighed against the obvious risks, and undertaken only after the stakeholders have agreed to them (usually in writing). And if you are a duct-tape programmer, then there is never any reason to \"cowboy code\" because you can build a quality product just as quickly. Nobody \"prefers\" cowboy coding over other methodologies because it isn't a methodology.  It's the software development equivalent of mashing buttons in a video game.  It's OK for the beginner levels but anybody who's moved past that stage simply won't do it.  They might do something that looks similar but it will not be the same thing. "
    },
    {
        "ID": "7230",
        "Question": "While the basic scenarios are white on black and black on white, most programmers find more varied syntax highlighting useful. What advantages do you find from a general setup?  (E.g. \"a dark background allows...\") What specific tweaks do you find most helpful?  (E.g. \"slightly off-white works to...\", or \"highlighting quote marks and escapes, like \\n, differently shows...\") One answer per person, please; list multiple points as part of your one response, if needed. ",
        "Best answer": "Either way though, I personally find that a white screen with dark text is too bright and hard on the eyes for long coding sessions.  The black is much less intrusive on my eyes.   "
    },
    {
        "ID": "7242",
        "Question": "Who here is learning Go? Are other companies looking at using it? Is it likely to become widely used? ",
        "Best answer": "When it comes to programming languages, the old adage, \"it's not who you are, it's who you know\" definitely holds true.  C and C++ were sponsored by AT&T, Java was brought to us by Sun, the .NET family came out of Microsoft, and all of them got very popular very quickly.  Then we have Objective-C and Python, which were around for quite a while and stayed really obscure until they were discovered and hyped up by Apple and Google, respectively, and then suddenly they really took off.  But languages without a major sponsor tend to languish in obscurity, no matter how good they are. Go is sponsored by Google.  It's not difficult to arrive at the right conclusion here.  Give it five years and it's gonna be huge. "
    },
    {
        "ID": "7245",
        "Question": "I had a question posed to me the other day by another programmer.  I remember (a very long time ago) wondering the very same.  Why was a browser-side include tag never considered?  Or was it? Specifically with a tag that instructed the browser to include additional HTML from other sources. e.g. <include src=\"http://server/foo/bar.html\">.  Many folks will make javascript calls and fill innerHTML to accomplish the same, when the same outside a the javascript engine could be accomplished by the browser. It would have been painful to have nested <HTML>s <BODY>s (i.e.) but we have to consider that aspect anywhere anyway. ",
        "Best answer": " Why was a browser-side include tag never considered? Or was it?  It was certainly requested by every newbie web author who hadn't worked out Server Side Includes yet, back in the early days on the www-html list. But in those days W3 were happy to completely ignore web author pressure. If cross-site inclusion were allowed it would be a security disaster. You could pull in a page from the user's bank and read content from it. (Originally, DOM scripting was limited, but you could still have read from document.links, document.images, scripting functions dropped by the target page, etc. Since then you can do what you like with imported content.) If cross-site inclusion weren't allowed... well then the feature wouldn't have any advantage over server-side includes. It'd be more, slower work for the client to do that the server could have dealt with better. Unlike <iframe>, an include would have to block page loading. SSIs would be in every way superior. "
    },
    {
        "ID": "7305",
        "Question": "What is your favorite method to declare a pointer? int* i;  or int *i;  or int * i;  or int*i;  Please explain why. see also: http://www.stroustrup.com/bs_faq2.html#whitespace ",
        "Best answer": "If you write: int* i, j, k;  you misleadingly suggest that all of i, j and k are pointers to int. So I contend it's superior to annex the * to the variable name. "
    },
    {
        "ID": "7325",
        "Question": "A typical curly brace programming lang has two types of AND and OR: logical and bitwise. && and || for logical ops and & and | for bitwise ops. Logical ops are more commonly used than bitwise ops, why logical ops are longer to type? Do you think they should be switched? ",
        "Best answer": "Probably a legacy thing. Bitwise operations may not be very common nowadays, but when coding on very low level you use them all the time. So when C was deviced in the 70's or whenever it was created, bitwise OPs were probably more common than logical OPs. And since C has it that way, I take it many other languages (such as Java, indirectly from C++) followed the same convention. Now that I've used the double notation (&& and ||) for so long, I'd only be confused if they were switched. But for completely new programmers, it would probably be a nice thing: you save a whopping 50% per logical operation! Imagine the productivity! ^^ EDIT: Provided these changed were done in a new language, of course, not in any existing languages. "
    },
    {
        "ID": "7347",
        "Question": "I'm talking about the way we write simple routines in order to improve performance without making your code harder to read... for instance, this is the typical for we learned: for(int i = 0; i < collection.length(); i++ ){    // stuff here }  But, I usually do this when a foreach is not applicable: for(int i = 0, j = collection.length(); i < j; i++ ){    // stuff here }  I think this is a better approach since it will call the length method once only... my girlfriend says it's cryptic though. Is there any other simple trick you use on your own developments? ",
        "Best answer": "insert premature-discussion-is-the-root-of-all-evil lecture That said, here are some habits I've gotten into to avoid unnecessary efficiency, and in some cases, make my code simpler and more correct as well. This isn't a discussion of general principles, but of some things to be aware of to avoid introducing unnecessary inefficiencies into code. Know your big-O This should probably be merged into the lengthy discussion above.  It's pretty much common sense that a loop inside of a loop, where the inner loop repeats a calculation, is gonna be slower.  For example: for (i = 0; i < strlen(str); i++) {     ... }  This will take a horrendous amount of time if the string is really long, because the length is being recalculated on every iteration of the loop.  Note that GCC actually optimizes this case because strlen() is marked as a pure function. When sorting a million 32-bit integers, bubble sort would be the wrong way to go.  In general, sorting can be done in O(n * log n) time (or better, in the case of radix sort), so unless you know your data is going to be small, look for an algorithm that's at least O(n * log n). Likewise, when dealing with databases, be aware of indexes.  If you SELECT * FROM people WHERE age = 20, and you don't have an index on people(age), it'll require an O(n) sequential scan rather than a much faster O(log n) index scan. Integer arithmetic hierarchy When programming in C, bear in mind that some arithmetic operations are more expensive than others.  For integers, the hierarchy goes something like this (least expensive first):  + - ~ & | ^ << >> * /  Granted, the compiler will usually optimize things like n / 2 to n >> 1 automatically if you're targeting a mainstream computer, but if you're targeting an embedded device, you might not get that luxury. Also, % 2 and & 1 have different semantics.  Division and modulus usually rounds toward zero, but it's implementation defined.  Good ol' >> and & always rounds toward negative infinity, which (in my opinion) makes a lot more sense.  For instance, on my computer: printf(\"%d\\n\", -1 % 2); // -1 (maybe) printf(\"%d\\n\", -1 & 1); // 1  Hence, use what makes sense.  Don't think you're being a good boy by using % 2 when you were originally going to write & 1. Expensive floating point operations Avoid heavy floating point operations like pow() and log() in code that doesn't really need them, especially when dealing with integers.  Take, for example, reading a number: int parseInt(const char *str) {     const char *p;     int         digits;     int         number;     int         position;      // Count the number of digits     for (p = str; isdigit(*p); p++)         {}     digits = p - str;      // Sum the digits, multiplying them by their respective power of 10.     number = 0;     position = digits - 1;     for (p = str; isdigit(*p); p++, position--)         number += (*p - '0') * pow(10, position);      return number; }  Not only is this use of pow() (and the int<->double conversions needed to use it) rather expensive, but it creates an opportunity for precision loss (incidentally, the code above doesn't have precision issues).  That's why I wince when I see this type of function used in a non-mathematical context. Also, notice how the \"clever\" algorithm below, which multiplies by 10 on each iteration, is actually more concise than the code above: int parseInt(const char *str) {     const char *p;     int         number;      number = 0;     for (p = str; isdigit(*p); p++) {         number *= 10;         number += *p - '0';     }      return number; }  "
    },
    {
        "ID": "7349",
        "Question": "As a general purpose programmer, what should you learn first and what should you learn later on? Here are some skills I wonder about...  SQL   Regular Expressions   Multi-threading / Concurrency   Functional Programming   Graphics   The mastery of your mother programming language's syntax/semantics/featureset   The mastery of your base class framework libraries   Version Control System   Unit Testing   XML   Do you know other important ones? Please specify them...  On which skills should I focus first? ",
        "Best answer": "In my experience, programmers who are \"trying to be good programmers\" by learning things like they would learn basic math are never as good as those who program with a purpose. Just learn what you need to do to accomplish an idea you have; learning any of the points you listed is useless if you're not going to use it. "
    },
    {
        "ID": "7455",
        "Question": "I mean, I still have a MSX2 with a Z80 processor and if you look at any Konami's game made for that computer in its time (roughly between '84 and '90) is amazing the high quality code of those games. I was a kid at the time, trying to learn how to program a computer and still today fascinated me how well made they are, mostly zero bugs or glitches, despite the really complex behavior. What hardware/software tools could they have used to accomplish that quality, which metodology? I know computers are really more complex today but at that time, even a stock control program I made in Basic was plagued with many bugs and was painful to debug. Any light you can shed will be deeply appreciated.  ",
        "Best answer": "I don't know anything about Konami, so I'm taking an educated guess here.  Games on machines like the MSX would have required direct access to the hardware, so that pretty much limits the choice of languages to either C or Z80 assembly language.  (There were C compilers for the Z80 back then, for example this one.) I doubt if the games were completely written in C, if at all; mostly likely a lot of assembly code for performance reasons. As far as platforms go, since the MSX didn't have a hard drive, I would further assume the programs were initially written on a larger Z80 system, perhaps running CP/M.  For debugging, the code could probably have been downloaded into a special game cartridge for the MSX that had RAM memory in place of ROM -- this would have allowed the developer to download the program over and over again without burning ROM chips.  Debugging (e.g. setting breakpoints) could have been accomplished by replacing the Z80 inside the MSX with an In-Circuit Emulator (ICE) interface. "
    },
    {
        "ID": "7502",
        "Question": "I have the \"user's side\" of the story, I think they want it better if it's on Spanish. But, what about the programmers? Do you make your programs multi-language? Why? Why not?  Who translate your software? Are you ok with paying somebody to translate your app or you prefer doing it yourselves? Is the benefit bigger than the costs? ",
        "Best answer": "There's really only one question you need to answer:  Is there a demand for the application to be translated into one (or more) other language?  If the demand is there then you need to look into translation. There may be political (both with a lower case \"p\" and upper case \"P\" - bilingual countries like Canada spring to mind), social or ethical reasons that need to be considered as well as the cost. As to the methodology - when I worked on software that was translated we got our German and French distributors to do the translation. The benefit of this is that you are using someone who knows the product and will (hopefully) choose the most appropriate translation when more than one is available. If you don't have distributors familiar with the language then there are services available that will do the translation for you. Failing that there's always Google Translate :) "
    },
    {
        "ID": "7505",
        "Question": "I've been handed the ER diagram for a quite complex database.  Complex to me at least, 849 tables. One of the architects says to understand the code, you need to understand the database and relationships. Now I am basically a Java programmer hence not too familiar with this How do I start? Should I start from something basic like USER or ORDER and see which relationships they have with other tables around them? Any tips or tutorials would help a lot ",
        "Best answer": "An ER Diagram is out there to visualize a design, which was made to accomplish a certain job. Understand what the job is first, then ask questions to the diagram.  \"How is an order stored?\", \"How do I retrieve user information\", \"How can I tell which user ordered a certain product between these intervals and with these options?\". Such questions might help you understand the design. If there is a requirements analysis documentation, it will help you a lot with coming up with these questions. You can explore how certain requirements are handled. I suspect that a database with 849 tables is highly normalized so most of those tables might be lookup tables which does not have much effect on the relationships of the entities. Try to focus on the parent tables holding keys to those lookup tables. "
    },
    {
        "ID": "7539",
        "Question": "I'm writing a small database-centric application in Java Swing that will be used internally in a small company. I haven't much experience with developing production-level applications. I don't use an ORM, just a few simple methods that run SQL queries with Java JDBC. On every method that access the database I use a try-catch statement for SQLException and IOException. Should I do any logging here? In case I should, how much should I log? Please give me examples of good practice in this case. ",
        "Best answer": "Two main things in production system are:  Don't blow up the logs with information that is not interesting Allow raising the log level for troubleshooting purpose.  Use some kind of a logging infrastructure. If the exception can occur during the normal operation, report it in debug level. If it is a real problem, report it in error level. Either way you will have a way to troubleshoot the system by raising the log level. Also - when you report an exception always make sure the the entire stack trace + inner exceptions are printed. "
    },
    {
        "ID": "7547",
        "Question": "I develop a web application and we test it on several browsers, including Firefox and Internet Explorer. During our development we tested the application on Firefox 3.5.2 and our testing team tested the same on 3.5.6 and found the UI looks good. Once in production, though, we've started receiving client complaints that it doesn't look good in 3.5.8. How do we handle these minor version issues? How can we check the browser compatibility during development and during testing? Is there any tool to test the application on 3.5.X, X being all the minor versions? ",
        "Best answer": "I would say stick with the age-old traditions in web development.   Stick with the standards.  Add small adjustments for the specific browsers your users are using if necessary. You can't really do any better than that.  There is no tool that will ensure your site works on every single browser and version.  Stick with the standards.  Add small adjustments. "
    },
    {
        "ID": "7551",
        "Question": "Why are there so many programming languages? And what prompts someone to create a programming languages in spite of the fact that other languages already exist? ",
        "Best answer": "Programming languages evolve New programming languages often learn from existing languages and add, remove and combine features in a new way. There is a few different paradigms like object oriented and functional and many modern languages try to mix features from them both. There is also new problems that needs to be solved, e.g. the increase of multi-core CPUs. The most common solution to that have been threads, but some programming languages try to solve the concurrency problem in a different way e.g. the Actor Model. See Erlang - Software for a Concurrent World "
    },
    {
        "ID": "7565",
        "Question": " Possible Duplicate: What good book shoud I buy to learn Agile from scratch?   It seem that Agile for the solo developer is a good idea. But how to learn it?  Is there any good book, web reference or course that a solo developer could start from? ",
        "Best answer": "If you have to purchase only ONE book. Buy Practices of an Agile Developer.  "
    },
    {
        "ID": "7581",
        "Question": "Is Java becoming the de facto standard from Linux application development in the same way .NET is the standard for Windows application development?  If not why not?   ",
        "Best answer": "In short: No. It really depends on what sort of application you are writing. For many the answer is still regular old C/C++ (if doing, say Qt or GTK+ GUI development). Many doing GTK+ development may also be using Python + PyGTK. If doing web or web services development, you see lots of Ruby, Python, PHP, and Java. "
    },
    {
        "ID": "7618",
        "Question": "Perhaps the greatest promise of using object-oriented paradigm is the code reuse. Some dispute that this was achieved. Why was it (not) achieved? Does code reuse as OOP defines it, make projects more productive? Or more manageable? Or easier to maintain? Or with more quality? Probably we all agree that code reuse is a good thing, but there are several ways to achieve this goal. The question is about the method of code reuse offered by OOP. Was it a good thing? Are there better methods to achieved code reuse than object orientation, sub-classing, polymorphism, etc.? What ways are better? Why? Tell us your experience with OOP reuse or other paradigms reuse. ",
        "Best answer": "Code re-use is achieved in OOP but it is also achieved in functional programming.  Anytime you take a block of code and make it callable by the rest of your code such that you can use this functionality elsewhere is code re-use. This type of code re-use also makes code more manageable because changing this one callable block changes all places that it is called.  I would say this result increased quality too and readability.   I am not sure OOP is simply there to provide code reuse.  I look at OOP as more of a way to interact with objects and abstract away the details of the data structure.   From Wikpedia:  Object-oriented programming has roots that can be traced to the 1960s. As hardware and software became increasingly complex, manageability often became a concern. Researchers studied ways to maintain software quality and developed object-oriented programming in part to address common problems by strongly emphasizing discrete, reusable units of programming logic[citation needed]. The technology focuses on data rather than processes, with programs composed of self-sufficient modules (\"classes\"), each instance of which (\"objects\") contains all the information needed to manipulate its own data structure (\"members\"). This is in contrast to the existing modular programming that had been dominant for many years that focused on the function of a module, rather than specifically the data, but equally provided for code reuse, and self-sufficient reusable units of programming logic, enabling collaboration through the use of linked modules (subroutines). This more conventional approach, which still persists, tends to consider data and behavior separately.  "
    },
    {
        "ID": "7629",
        "Question": "What coding standards do you think are important for .NET / C# projects?  This could be anything from dealing with curly braces and spacing and pedantry like that.  Or it could be more fundamental questions such as what namespaces in the .NET Framework to avoid, best practices with config files, etc. Try to avoid creating a post that is simply the corollary to another.  For example, it would be fine to have one post focusing on curly braces.  We don't need two to support one style vs. the other.  The idea is not to vote for your pet standard, but rather to flesh out what should be thought about when creating standards. ",
        "Best answer": "Here is the official Microsoft Guide on coding standards for the .NET framework Version 4.0. If you want the older version for 1.1, try here. I don't necessarily follow this to a 'T', as they say.  However, when in doubt, this is the best place to start to be consistent with the current .NET framework, which makes it easier on everyone, no matter if they're new to your particular project or not. "
    },
    {
        "ID": "7686",
        "Question": "I am curious about experiences of programmers who have gone beyond college or university and now work in the industry. I am not talking about academia (you need PhD there anyway). Do you have a Master's degree? Has it helped your career? Are there any other benefits besides the knowledge one gains while pursuing the degree? ",
        "Best answer": "Yes it does. It helps a lot in getting your resume shortlisted by the HR who have no idea what programming is all about. "
    },
    {
        "ID": "7720",
        "Question": "I'm looking at licensing some open source software and am looking at the GPL.  What are the pros and cons of using this license? ",
        "Best answer": "Ok, my list of pros and cons of GPL: Pros  It makes people think hard about whether they really buy into Open Source; are you prepared to live by it, and let other people use what you've written, rather than just liking it because of what you can get out of it? It makes sure that when something has been developed by the Open Source community, it stays Open Source; no chance of someone taking all the work that others have been doing, repackaging it and selling it on.  Cons  It's a complete no-no for most corporate organisations; they can't afford the risk of GPL-licenced code getting into their products, so virtually all medium-large companies have clauses explicitly banning GPL-licenced code. It puts people off Open Source. Is it really fair, that because I use your Open-Source image picker control in my app, my whole app must now be Open Source too?  Even if I improved the image picker and contributed that code back to the community?  The terms are too onerous for many developers. Lots of people aren't aware of the stringent terms of GPL, so use it as it's the licence they've heard of without realising what restrictions they're placing on anyone else that wants to use it. Its extremely viral.  If your project contains a component that contains a component that contains a component that is under the GPL (phew!), your whole project is subject to the GPL too.  Ultimately for me the cons outweigh the pros.  To me it smacks of Open Source Evangelists trying to trick the world into going Open Source instead of persuading the world of its benefits. "
    },
    {
        "ID": "7804",
        "Question": "I tried programming Scala in Netbeans and Eclipse, but it is not what I'm looking for. In Netbeans suggestions for method names etc. are not working. In Eclipse I can't go to some classes sources by pressing F3. (e.g. scala List). Is support in IntelliJ IDEA any better? Are there other IDE's supporting Scala? ",
        "Best answer": "IntelliJ IDEA Same question has been asked on Stack Overflow. Check out Which is the best IDE for Scala development? "
    },
    {
        "ID": "7834",
        "Question": "I'm two months away from getting my degree in systems engineering, which is to say, I learned how to code and code well using managed languages. The only reason I got into this career was because I wanted to create video games. I know now that with my current skillset, I won't be able to create some of the things I have in my head. Would getting a second degree in pure mathematics would help me with this goal? ",
        "Best answer": "No type of degree will help you as a programmer more than programming. Experience trumps studying. If you want to be a good programmer then start programming. I don't have a degree but I've been programming on various projects for fun since I was around 15-16; needless to say I'm light years ahead of my friends who studied computer science at a university and ask me questions like \"is it better to check admin privileges for my website through PHP or the SQL GRANT option?\". "
    },
    {
        "ID": "7859",
        "Question": "As a solo developer, I think I'm using an Agile-like process, but I'd like to compare what I'm doing to real Agile and see if I can improve my own process. Is there a book out there that's the de-facto standard for describing best practices, methodologies, and other helpful information on Agile? What about that book makes it special? ",
        "Best answer": "Is there a canonical book? There is the agile manifesto, but for a canonical book? No. There are lots of books out there. Specific book recommendations: Agile Software Development, Principles, Patterns, and Practices by Robert C. Martin  Agile Software Development, Principles, Patterns, and Practices. This is focused on developer practices and coding and is a must read for any developer serious about agile software development. There is also a C# version of the book that he and his son Micah wrote, so if you are a .NET developer, that version might be the one for you.  The art of Agile Development by James Shore  For an insight into overall agile project practices look at The Art of Agile by James Shore & Shane Warden. It's focused on XP practices (but that's really because XP is where all the specific developer practices are defined), but has a big picture focus on how Agile projects work. A great thing about this book is that James Shore is publishing the whole text on his website for free, so you can try before you buy.  Practices of an Agile Developer: Working in the Real World by  Subramaniam and Hunt  Practices of an Agile Developer: Working in the Real World  Scrum and XP from the Trenches by Henrik Kniberg  It's a great book for getting a feel for how an agile team works, and it it's a very quick read (couple of hours). I give it to new staff in my organisation - technical and non-technical - and I've had consistently positive feedback. Amazon  Extreme Programming Explained by Kent Beck  Probably the oldest book I can remember which helped make Agile principles popular. Agile is fast becoming a buzz word in the world of Tech. I feel Extreme Programming (XP) is a good place to start before the term Agile just seems to lose meaning. Amazon  Agile Estimating and Planning by Mike Cohn  For \"the Agile process\" - look to Mike Cohn's \"Agile Estimating and Planning\" - bearing in mind that it's Scrum-centric. Cohn covers a lot of the basics as well as some of the things new Scrum teams often struggle with - estimation using Story Points vs. Ideal days, what do do if you fail a story in a sprint, when to re-estimate/size and when not to, etc. He also goes into some really interesting stuff that's mainly the domain of a Product Owner - things like how to assess and prioritize features, etc.  The Art of Unit Testing by Roy Osherove  Osherove presents a very pragmatic approach to unit testing. Presents a good approach on how to refactor code to become more testable, how to look for seams, etc. It is a .Net centric book, however. Amazon  The Agile Samurai by Jonathan Rasmusson  Just purchased this myself and found it to be a refreshing look on how to get started with agile. Amazon    Alistair Cockburns book on his Crystal methodologies is worth while reading - partly because it gives you an alternative the the usual Scrum methods, and partly because he was one of the original guys who came up with Agile in the first place, so I hope he know what he's talking about. Crystal is an interesting methodology as it scales from small teams to very large ones, he describes the changes required to make agile work in these different environments.  Unsorted books mentioned  Agile Adoption Patterns: A Roadmap to Organizational Success by Amr Elssamadisy  Agile and Iterative Development: A Manager’s Guide by Craig Larman  Agile Estimating and Planning by Mike Cohn  Agile Project Management: Creating Innovative Products by Jim Highsmith  Agile Retrospectives: Making Good Teams Great by Esther Derby and Diana Larsen  Agile Software Development by Alistair Cockburn  Agile Software Development with Scrum by Ken Schwaber and Mike Beedle  Becoming Agile: ...in an imperfect world by Greg Smith and Dr. Ahmed Sidky  The Business Value of Agile Software Methods: Maximizing Roi with Just-In-Time Processes and Documentation by David F. Rico, Hasan H. Sayani, and Saya Sone  Collaboration Explained by Jean Tabaka  Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation by Humble and Farley  Crystal Clear: A Human-Powered Methodology for Small Teams by Alistair Cockburn  Encyclopedia of Software Engineering edited by Phillip A. Laplante  Fearless Change by Linda Rising and Mary Lynn Manns  Growing Object-Oriented Software, Guided by Tests Freeman and Pryce  Innovation Games: Creating Breakthrough Products Through Collaborative Play by Luke Hohmann  Lean Software Development – An Agile Toolkit for Software Development Managers by Mary and Tom Poppendieck  Lean Solutions by Jim Womack and Dan Jones  Lean Thinking by Jim Womack and Dan Jones  Managing Agile Projects by Sanjiv Augustine  Managing the Design Factory by Donald G. Reinertsen  Planning Extreme Programming by Kent Beck and Martin Fowler  Scaling Lean & Agile Development: Thinking and Organizational Tools for Large-Scale Scrum by Craig Larman and Bas Vodde  Scrum Pocket Guide: A Quick Start Guide to Agile Software Development by Peter Saddington  The Software Project Manager's Bridge to Agility by Michele Sliger and Stacia Broderick  Today and Tomorrow by Henry Ford (From 1926)  User Stories Applied by Mike Cohn   Book lists  Agile Design Recommended Reading  "
    },
    {
        "ID": "7861",
        "Question": "I know we've covered what questions you should ask about a company before you would decide to work there.  But what do you do with the answers? In other words, what would you consider a dealbreaker?  I.e. what would scare you so much about a company that you wouldn't work there, even if everything else was great? For example, if they tell me they don't use version control, I wouldn't work there.  End of story. ",
        "Best answer": "Companies that feel the need to mention up-front that unpaid (for salaried employees) overtime is required 100% of the time. "
    },
    {
        "ID": "7912",
        "Question": "How do you endorse/support a code project that you find helpful, be it established, emergent or fledgling? I think there are some obvious answers, but hopefully there will be some novel suggestions too. ",
        "Best answer": "It is really going to depend on what state the project is in.  If this is code that is avaialble as a completed app that's offered as free to try/purchase to continue then I'll probably pay for the app if I think I'll use it. "
    },
    {
        "ID": "7927",
        "Question": "No one's perfect, and no matter what we do, we are going to produce code that has bugs in it from time to time. What are some methods/techniques for reducing the number of bugs you produce, both when writing new software and changing/maintaining existing code? ",
        "Best answer": "Avoid fancy coding.  The more complicated the code, the more likely there's bugs.  Usually on modern systems, clearly written code will be fast and small enough. Use available libraries.  The easiest way to not have bugs writing a utility routine is to not write it. Learn a few formal techniques for the more complicated stuff.  If there's complicated conditions, nail them down with pen and paper.  Ideally, know some proof techniques.  If I can prove code correct, it's almost always good except for big, dumb, obvious bugs that are easy to fix.  Obviously, this only goes so far, but sometimes you can formally reason about small but complicated things. For existing code, learn how to refactor:  how to make small changes in the code, often using an automated tool, that make the code more readable without changing the behavior. Don't do anything too quickly.  Taking a little time up front to do things right, to check what you've done, and to think about what you're doing can pay off big time later. Once you've written the code, use what you've got to make it good.  Unit tests are great.  You can often write tests ahead of time, which can be great feedback (if done consistently, this is test-driven development). Compile with warning options, and pay attention to the warnings.   Get somebody else to look at the code.  Formal code reviews are good, but they may not be at a convenient time. Pull requests, or similar if your scm doesn't support them allow for asynchronous reviews. Buddy checking can be a less formal review. Pair programming ensures two pairs of eyes look at everything.  "
    },
    {
        "ID": "7993",
        "Question": "During iteration retrospectives on agile projects, one of the topics that comes up most often for us is that the product owner is (or product owners are) not available or engaged in the project at a day to day level.  It seems to be a common theme that customers are unwilling to \"give up\" the necessary amount of their product owner's time to the project, but instead have them answer questions via email, or during product demos only. This has the effect of increasing the length of the feedback cycle and making the project less effective. Have you had to overcome this hurdle? How did you do it? ",
        "Best answer": "The product owner's presence in required meetings (Sprint Review and Planning) is (should be) non-negotiable.  Do what you need to negotiate a time that works, and then absolutely hold the product owner to it.  If something comes up, delay it but hold the product owner responsible for bringing the entire team to a halt.   If the product owner is actually (from) your customer and they are unwilling to participate in that capacity, then maybe it makes sense to find an internal Product Owner that communicates with the customer but is capable/authorized to make some calls on their own, on the customer's behalf.  That is the typical arrangement anyhow, since there are some things that a Product Owner is responsible for that shouldn't really pass by a customer's eyes. Otherwise, your only choice is basically to abandon agile.  You're not going to make it work without a PO at those meetings. "
    },
    {
        "ID": "8020",
        "Question": "Console app (my favorite), quick & sloppy form, MS Paint (for GUI); what works best most of the time for your standard application? why? ",
        "Best answer": "For me hands down it is Balsamiq I love it for a number of reasons.  Easy to use - The interface for Balsamiq is incredibly simple and fast for me to pull things together. Looks like a mockup - When showing it to clients/customers/vendors it looks like a mockup, so there isn't confusion that \"I'm almost done\" or something like that. Looks professional - In addition to the previous point, yes, it looks \"hand drawn\" but still looks professional. Common UI Controls - Are all available, to quickly build out mockups that resemble real apps.   "
    },
    {
        "ID": "8034",
        "Question": "In an open source project, a number of other open source libraries have been included to implement needed functionality, some as libraries (LGPL), and some as source code (non-LGPL). The new BSD license was selected for the project. The included open source libraries are licensed under the new BSD, MIT, Apache, and LGPL licenses, but no GPL licensed code. How should these other open source libraries be credited? Do all the library licenses need to be included in the main project license file? Is it sufficient to just provide links to the project web sites in the Help->About dialog and documentation? Is any credit really needed? ",
        "Best answer": "Each library that you use as a dependency should have a LICENSE file in their source code. I would just take these licenses and rename them to \"LIBRARY_NAME_LICENSE\" and include it with the source code. I know licenses (like the BSD license) require that the original license be included when any source code is reused. If you are just using these as linked libraries, I don't believe any of this is needed. But I may be wrong about this one. "
    },
    {
        "ID": "8055",
        "Question": "If I would start to focus on the .NET platform and be self-employed, then I probably would like to have some Windows 7, Windows Server 2008, Visual Studio 2010 licenses just for the development environment and for testing, and then a few licenses for the production environment (a Windows Server 2008 Web) and added to that upgrades when new versions is available. This will end up in a quite big amount of money. Is there any kind of bundle discount that I can get from Microsoft in such a case? And what is the requirement to be able to get that discount? ",
        "Best answer": "How about a 100% discount? If you are making software you intend to sell, you qualify for BizSpark, which gives all your developers MSDN subscriptions. If you intend instead to offer your services, you don't qualify for BizSpark, but you still don't need to buy separate licenses for dev, staging etc. You can get an MSDN subscription, which covers one developer across any number of machines other than production. You don't install dev tools on production, and your clients are responsible for the Windows, SQL etc licenses they need. It is generally useful to join the partner program. The Registered level is free and lets you buy an MSDN subscription at a dramatically reduced price, 80-90% off or so. The program names vary over time - Empower, Action Pack, etc so you would need to check the partner program to be sure what they are and what they cost at the moment. Finally, back to the free angle, don't rule out Visual Studio Express, SQL Express etc - absolutely no cost ever and almost all the features of the full products. "
    },
    {
        "ID": "8093",
        "Question": "What are some somewhat common math formulas you learned that helped you write better algorithms and become a better programmer? Example: I learned about the ecludian distance formula: sqrt((x1-x2)^2+(y1-y2)^2) which helped me understand how to find like objects by comparing 2 factors.  ",
        "Best answer": "Knowing the powers of 2 is handy, especially when dealing with low-level bitwise operations.   "
    },
    {
        "ID": "8098",
        "Question": "As I've implied through my other posts, I'm still fairly new to the workforce. During team meetings, I tend to be able to keep up with technical discussion, but when my project manager starts talking about how we've won a new contract, or we're involved in a new proposal bid, or... anything that's business rather than technical, really... I can get lost pretty quickly. What is the bare minimum all developers need to know about project management/business to function? ",
        "Best answer": "I think you need to understand how your company makes money. You also need to be able to evaluate if you should do anything to help it make more money, i.e. do your job better. Most importantly this means that you need to be able the tell which task you're working on you should put the most effort into and how to prioritize the tasks you've been given. Also, programmers need to understand that even though something might technically be the best choice, that choice might not be the best choice for the business. And that is a good reason to not take the technically best way. "
    },
    {
        "ID": "8104",
        "Question": "So I know everyone here is all about private offices, how many developers actually have them. I am sort of half skeptical. I can believe that lead developers have them, but that's normally just one person in your average office. That makes me wonder, how many developers have private offices. Which leads to the actual question: why should they have them? ",
        "Best answer": "In the management world, where concentration on a task is not an issue, offices are a means to represent status. They think \"private office == more status, big private office == even more status, etc.\" What most people fail to understand: Every time our concentration is broken, we create at least one bug and/or delay the deadline for another half-hour. Private offices is not a \"nice to have\" for developers but a must. This is not about status, this is about brain physics.  Working in an open space costs at least 30% productivity (I read that in a newspaper, start with this blog post if you want to know more). Worst part: This goes unnoticed. If you always work in such an environment, you'll never notice that it happens! Until you wonder why your neck is stiff, you feel tense/nervous all the time, etc. If you want another productivity increase, take the telephones away, too. Unless you're doing production support, the next day is always soon enough. To relax the team, supply free soft drinks. That costs $100-300/month for a team of 10 and makes sure they take regular breaks, drink enough (so they don't dehydrate). The funny thing is: These aren't a bunch of myths but hard facts. Still, most companies ignore these simple, cheap ways to boost productivity. Well, except for the successful ones, of course (Google, Microsoft, etc). See also:  Open Offices Reduce Productivity and Increase Stress The High Cost of Interruptions A study on unplanned interruptions in software development How to explain a layperson why a developer should not be interrupted while neck-deep in coding?  "
    },
    {
        "ID": "8119",
        "Question": "In what circumstances should an IT Consultant encrypt their hard drive to protect their code/data of their clients? I am thinking that if it does not add much to your work load you might as well use full disc encryption with a 'weak' password to at least prevent someone from accessing your email files and other documents if your laptop is stolen, even if they will not get access to any database files or other very sensitive data.  ",
        "Best answer": "I agree that full-disc encryption is good, especially if you have sensitive data on your a laptop (you probably do). So, with the new laptop models being plenty fast, I'd say \"always\". That said, there are caveats:  if you forget your password, this means all your data are as good as gone (until you remember the password again). (corollary: any encryption solution that has a \"recover password\" option is likely snake oil, not encryption) weak passwords == no protection (your cow-orkers probably won't try to break into your computer, but a stolen laptop's data could be worth some money; plus, pass-phrases are quite strong and easy to remember) the full-disk encryption could make sleep mode/hibernation impractical, if not impossible (check the product you plan to use) some data may be accessible from additional locations (e.g. your e-mails may be stored on a server, with a copy stored locally in your computer) full-disc encryption is not magical pixie dust - it doesn't provide security against other attack vectors, you still need to address those separately (backups, antivirus, firewall, phishing protection, social engineering, rubber hose cryptanalysis)  Note that encryption should not be seen as a way of securing the data forever from anyone - its goal is just to delay an attacker long enough to make the attack uninteresting. With strong encryption, it should take years before the attacker gets to the data by brute force, at which point the data is so old that it's useless. Although the National Security Agency (or similarly powerful entity) can probably crack the encryption much faster (as it can throw enormous amounts of computing power at it), full-disk crypto is still good protection against anyone else cracking it (e.g. your competitors or a random thief). As a bonus, encryption eliminates casual snooping: if you forget your (powered-off) laptop somewhere, an almost-honest person might decide to browse through your files before returning it to you, just out of curiosity. There's a proverb that says \"most locks are made to keep honest people honest\"; strong locks will do that, and also keep the really malicious people out for long enough. "
    },
    {
        "ID": "8187",
        "Question": "A recent question on stackoverflow provoked a discussion about the immutability of primary keys. I had thought that it was a kind of rule that primary keys should be immutable. If there is a chance that some day a primary key would be updated, I thought you should use a surrogate key. However it is not in the SQL standard and some RDBMS' \"cascade update\" feature allows a primary key to change.  So my question is: is it still a bad practice to have a primary key that may change ? What are the cons, if any, of having a mutable primary key ? ",
        "Best answer": "You only need the primary key to be immutable if it's linked to a foreign key, or if it's used as an identifier outside the database (for example in an URL pointing to a page for the item). On the other hand, you only need to have a mutable key if it carries some information that might change. I always use a surrogate key if the record doesn't have a simple, immutable identifier that can be used as key. "
    },
    {
        "ID": "8283",
        "Question": "What was a project or spec that got put on your desk that could not possibly be done? How did you explain the dilemma to the \"requester\"? More importantly, did they understand after you explained the fundamental issue?  ",
        "Best answer": "I was told to make the printer print faster. Serious, and I was written up for failing. The boss wasn't very tech savvy and didn't understand why I couldn't speed it up.  "
    },
    {
        "ID": "8301",
        "Question": "In my experience, software developers tend to wear multiple hats and fill multiple roles with different responsibilities.  From not only coding, but sometimes also writing SQL, designing the user-interface, designing the database, graphics manipulation, to even QA testing. If the primary role is to write software/code, what roles should the developer not take on?  Are there any? The intention of this question is not because a developer is incapable of filling another role-- but having the additional role actually works against the primary role, or should really be a dedicated role of someone who does not primarily program. ",
        "Best answer": "Sysadmin.  Developing software and handling the IT infrastructure are two different skillsets that look similar to an outsider.  (It's all just banging on computers, right?)  For a smallish company, the temptation will be very strong to make The Computer Guy responsible for all the machines in the office.   If you have the skills to actually wear both hats, awesome; but it's one of those things that can be a much greater time sink than people realize, and if you're self-teaching as you go, chances are you're not doing it very well. "
    },
    {
        "ID": "8352",
        "Question": "I really like using ClassNames and memberNames as convention but I am not sure how I would name the file containing a class. I like making my classes defined in a file with the exact same name as the class. But I also like making php files all lowercase. So I am conflicted. If I have a class called ProductGroup should that be defined in ProductGroup.php, productgroup.php, or product_group.php? I know there is no right answer, so I am looking for what is most common or your opinion of which to use.. which do you use? ",
        "Best answer": "At work we use underscores as folder delimiters and name the files exactly the same as the path. The autoloader is very simple, it just has to replace _ with / and add '.php' to the end. ProjectName_Models_ProductGroup() will always reside in ProjectName/Models/ProductGroup.php. It can make for some very long class names, but it doesn't really matter with an IDE. You could use the same convention, but just run strtolower() before including the file. "
    },
    {
        "ID": "8364",
        "Question": "Many developers recommend Firefox for web development for a variety of reasons. But, after looking at Opera, it seems to me that Opera has all of the same web development functionality that Firefox has built into it. So what is wrong with Opera for web development? ",
        "Best answer": "I think any browser you like to work in is the right browser to work in. I like Chrome--I think its developer interface is very nice indeed. Problem is, a very compliant browser is going to fool you when you switch to a less-compliant one (lookin at you, Internet Explorer). Things will be building nicely, and then your boss will look at it on IE6 and it'll be a calamity. So you've got to at least be looking very frequently at your work the browser that's simultaneously most popular and most breakage-prone. "
    },
    {
        "ID": "8391",
        "Question": "In a book I'm reading there is a chapter on documentation for your code. The book is about PHP and described some easy methods but also going for some complicated and time consuming methods (xml, xsl) like DocBook. At my current small company (5 people) we even rarely write comments, but I'm wondering if in a big company how detailed documentation do they write? Do they use such tools like DocBook? Is it complex or simple? ",
        "Best answer": "Working on PHP and NetBeans, the documentation style is pretty much PHPDoc way. Thus I write a little more than what the IDE generates. e.g. IDE generates: /**    * Description for ClassA    *    *    * @author Sam-Mauris Yong    */    class ClassA{      function __construct(){         echo \"5\";     }  }  I'll probably write: /**    * Class A Helper Class  * Some example class used here  *    * @author Sam-Mauris Yong  * @license GNU Public License v3  */    class ClassA{      /**      * Constructor for example class      * echos 5      */     function __construct(){         echo \"5\";     }  }  "
    },
    {
        "ID": "8429",
        "Question": "Which way is more beneficial and productive? ",
        "Best answer": "I think you need both. You have to focus on your core competencies and improve your understanding of them, but at the same time it's beneficial to look outside and see what else is out there. Exposure to other approaches and other languages is very important to make one a better developer overall. There are many ways to skin a cat, as it were, and knowing as many of them as possible will make you  a psychopath better at picking the right tool for a particular task. So, spend most of your time getting better at your chosen proficiency and spend some of your time on learning something new. "
    },
    {
        "ID": "8445",
        "Question": "After 15 years of C++, I've still haven't learn to love using const. I understand it's use, but I've never actually been in situation where being const correct would have avoided the problem I was facing. So how did you come to love benefits of consts? ",
        "Best answer": "Well I wasn't convinced until I tried to embrace the philosophy. I first started by putting const to really read-only members of my most basic class members and member functions arguments. From there, I couldn't compile anymore. Then I persevered in going in the code using those basic classes, see if the previously const additions were really legitimate compared to the use I made of them. It helped me fix some bugs on the way as I added constness to other parts of the code. It's contagious. Most of the code got even more constness and I found easier to debug it because it makes you confident that the compiler will stop you if you start modifying something you shouldn't.  Once I got the application running again, it was faster (had to change some algorithms that I've discovered weren't right for the job), with a lot less bugs and easier to understand when reading the code. I was convinced.  Now, I think that it's even better when you're using a lot of assertions in addition to constness because it makes you feel confident when you have to write new code or modify the current code. You know the compiler will stop you if necessary. It lets you forget about having to check everything you shouldn't modify and then you have more thinking time for more business-specific thinking, or architectural thinking. "
    },
    {
        "ID": "8544",
        "Question": "For someone with .Net experience and wanting to develop for iPhone/iPod/iPad, is it worth learning Objective-C? Is MonoTouch a good alternative? What are some of the trade-offs when using MonoTouch vs coding in Objective-C? ",
        "Best answer": "MonoTouch is a fantastic alternative. I've been using it for pretty much one year now, and I can't ever imagine going back to objective-c. Highlights: LINQ, LINQ to XML, LINQ, C#, LINQ, Garbage collector, LINQ, MonoTouch.Dialog, and a lot of other things. Seriously, though.. nowadays most apps are always downloading data from the web, and you'll need to be converting that to objects, keeping them in lists, sorting and filtering them, and pushing them to databases. That stuff is so simple to do with C# and LINQ that I can't imagine people doing that in other languages.  The $400 dollar cost is not low, but you can probably make that money back in 1 month or so with no advertisement. And the amount of time MT will save you will offset that easily. Also remember, you don't have to pay until the app is ready for testing in a device, so its free for learning. With that said, yes, its still totally worthy to learn Objective-C. It'll make you a better developer for the platform, you'll understand why some things are the way they are, and so on. You'll also be able to read Obj-C examples in the web and translate them to C#.  Finally, here's my suggestion: if you're thinking of getting in iOS development, go to MonoTouch. Spend a few weeks using it, and then make the decision of jumping to Obj-C. The hardest part of going to iOS development is not the Obj-C language, is all the new frameworks you'll have to learn. Being able to learn them in C# is a HUGE deal, you'll be a lot more productive from the start up. Just after you know those things look into Obj-C: everything will be already familiar, so it'll be easy to understand everything. "
    },
    {
        "ID": "8564",
        "Question": "Obviously the size of the project you're working on will be a huge factor in how long you spend writing the design document/specification.  But do you go through everything, picking out every tiny detail? Or do you take a more agile approach and start writing the software quite early on and solve the problems as they come to you? I've always found that there's only so far you can go with designing.  There will inevitably be some things that are missed, and at that point how well you can adapt to the situation means more than the specification itself. Am I taking the right viewpoint on this? Is it actually an opinion, or is a perfect design spec always the best route to go? ",
        "Best answer": "It depends a bit on your target audience, but my experience ( more in small/medium scale development than very large scale work ) is that detailed design documents are arduous and boring to write, rarely read and tend to end up out of date by the time a project is delivered. This does not mean that they are worthless - if you are delivering something for someone, there needs to be an authoritative and agreed statement of what will be delivered sufficiently detailed that everyone can point to it in case anyone is dissatisfied with the deal and say \"this is what we promised\" and evaluate it against what was delivered. If I were setting up a company to build a product, however, I wouldn't worry so much about a detailed specification. I would want to document what we were going to do, but I wouldn't want to go into too much depth regarding how - that is the part that is most likely to change and leave the documents out of date and useless or even inaccurate enough to be actually obstructive. I would prefer to document the \"how\" stuff in code using whatever documentation format the language or IDE supports best, so that as the code changes it is easier to update the documentation at the same time. It won't stop it going out of date, but it will reduce it somewhat. Ideally you would want a design document that could double as your manual when your code is complete, but I don't know of anyone who has managed that successfully.  "
    },
    {
        "ID": "8588",
        "Question": "SQL is officially pronounced as /ˌɛskjuːˈɛl/ like \"S-Q-L\", as stated in   Beaulieu, Alan (April 2009). Mary E. Treseler. ed. Learning SQL (2nd ed.). Sebastapol, CA, USA: O'Reilly. ISBN 978-0-596-52083-0.  But often it is pronounced  /ˈsiːkwəl/ like \"sequel\", what is the history behind this second pronunciation? ",
        "Best answer": "SEQUEL = Structured English QUEry Language.  For a good historical perspective read   Don Chamberlin: ...A bunch of things were happening at about this time that I think we ought to mention just in passing. One was that we had to change the name of our language from SEQUEL to SQL. And the reason that we had to do that was because of a legal challenge that came from a lawyer. Mike, you probably can help me out with this. I believe it was from the Hawker Siddeley Aircraft Company in Great Britain, that said SEQUEL was their registered trademark. We never found out what kind of an aircraft a SEQUEL was, but they said we couldn't use their name anymore, so we had to figure out what to do about that. I think I was the one who condensed all the vowels out of SEQUEL to turn it into SQL, based on the pattern of APL and languages that had three-lettered names that end in L. So that was how that happened. ...  "
    },
    {
        "ID": "8631",
        "Question": "When you are defining a function/variable/etc and are not sure what to name it, what do you name it? How do you come up with a name? If you use a temporary name as a place-card until you give it it's real name, what temporary name do you use?  update I have been using things like WILL_NAME_LATER, NEEDS_NAME, or TO_BE_NAMED. I was hoping there was an adopted convention, I was actually hoping that if I used this adopted convention my IDE would highlight the name until I changed it. ",
        "Best answer": "I always try to give my variables and functions great names. If I can't think of a great name, I'll settle for a good name. If I can't come up with a good name, I'll use an okay name. I have never, in 15 years of professional programming, been unable to come up with a decent name. "
    },
    {
        "ID": "8677",
        "Question": "I'm not sure if I'm using the correct term, but would you program using High-level abstractions like Powerbuilder, or some CMS like MODx or DotNetNuke? I haven't dabbled in any of these yet. The reason I'm asking is that I kind of feel intimidated by the whole notion of using any abstraction over the languages I'm using. I'm thinking that my job might be over-simplified. While it may provide business solutions faster, I'd rather be coding straight from, in my case, .NET.  Do/Would you use abstractions like these or prefer them over programming in lower level languages? ",
        "Best answer": "I've got no problem with using high-level abstractions, with two caveats:  Any abstraction that you can't get underneath when necessary is evil, because it will occasionally be necessary.  Avoid these. Don't ever use any abstraction without a solid understanding of what's really going on under the hood.  Not doing this will frequently cause performance problems, and occasionally cause correctness problems, both of which are very difficult to debug since you don't know what's really happening.  "
    },
    {
        "ID": "8758",
        "Question": "Disclaimer: I by no means condone the use of pirated software. Have you ever witnessed the use of pirated software for development purposes? May be a company didn't have enough money to buy a piece of software and there were no free alternatives? May be a company wanted to try something out before buying and there were no trial licenses for that product. Whatever the circumstances, have you worked at a company where using pirated/cracked software was accepted? Were there any consequences to doing this? ",
        "Best answer": "While I don't have any problem when some companies or individuals use unlicensed software when they can't afford them (yet), I'm always amazed to see how commercial software development factories do it without shame. They are unrespectful to their own profession! Thanks to programs like Microsoft Bizspark (3 years of free Microsoft softwares for any startup that generate less than 1.000.000 a year in revenues), you can now get them legally. "
    },
    {
        "ID": "8805",
        "Question": "Assuming I've found an open source project I'm interested in, how do I evaluate the project(the members, the activity level, etc) to determine if joining the project will be a good use of my time and energy? ",
        "Best answer": "Look at the source control history. From that, you can see checkins, review code, gauge the activity level, and generally see the quality of commits.  You can learn the most from just looking at the source code activity. "
    },
    {
        "ID": "8886",
        "Question": "Interested in knowing from the more experienced ones if someone can find a job as a programmer without even a highschool degree. Consider the said person to be an average programmer. Would someone even consider giving him/her a chance on an interview ? The languages of interest would be python/php/java/c# Please answer for your region/city/country only. No \"go back to school\" answers please. ",
        "Best answer": "Your biggest difficulty is going to be getting through the HR filter. If you can do that, experience will trump education (most of the time).   In the meantime, try to find some small shop that just needs someone who can code. You should also try to join an opensource project (or two) to get some experience and show that you have some skills. You are going to have to start small and build on that. "
    },
    {
        "ID": "8955",
        "Question": "After working out a project, it might require too much tweaks and changes to get it working right... What can I do to prevent this? ",
        "Best answer": "There is simple rule, that I apply all the time because I tend to be a perfectionist too. And perfectionism leads you to mediocrity.  Set a deadline. Ship at that deadline.  To prevent your software from having an unfishined state of missing feature that will make it unusable, use this definition of done for each feature you produce. Don't start the next feature until ALL steps are completed:  Develop the feature Test is (80% code coverage) Commit/Integrate Document (both technical & end user documentation) Update Release Note (both in file and maybe for your website including screenshots) Update Installer (if necessary)  I assume you can create a release with one mouse click (using build scripts) "
    },
    {
        "ID": "8966",
        "Question": "Are there ways to unit test your multi-threaded code for race conditions and deadlocks? To see if they are performing the way they should be... ",
        "Best answer": "CHESS, a project of Microsoft Research.  Quoting their site:  CHESS is a tool for finding and reproducing Heisenbugs in concurrent programs. CHESS repeatedly runs a concurrent test ensuring that every run takes a different interleaving. If an interleaving results in an error, CHESS can reproduce the interleaving for improved debugging. CHESS is available for both managed and native programs.  Update (9/23/2015): For C, C++, and Go, you can use ThreadSanitizer. "
    }
]