[
    {
        "ID": "3241",
        "Question": "This question is a little abstract but I'm hoping someone can point me in the right direction. My question is what amount of time can one expect to devote to a software project's bugs in relation to the original development time. I realize there are a huge number of determining factors that go into but I was hoping for a typical or average breakdown.  For example, if Project A takes 40 hours to complete and an additional 10 fixing bugs then this project would have a 4:1 ratio. If another Project (B) takes 10 hours to complete but another 8 on bugs then it would have a 5:4 ratio.  Is this a documented/researched concept? UPDATE Thanks for all the informative answers. I understand that it's impossible to put a standard to this kind of metric due to all the variables and environmental factors involved. Before I assign an answer I'd like to know if this metric has an agreed-upon name so I can do further research. I would like to get to a point where I can understand the measurements necessary to generate the metrics myself and eventually come up with a baseline standard for my project. ",
        "ChatGpt answer": "The concept you are referring to is often known as the \"cost of quality\" or the \"quality cost ratio\" in software development. It measures the amount of time (cost) spent on fixing bugs (quality) in relation to the time spent on original development.   There is no set standard or agreed-upon ratio for this metric as it can vary greatly depending on the complexity of the project, the experience of the developers, the quality of the initial code, the testing process, and many other factors.  If you are looking to further research this concept, you may want to explore books and articles on software quality assurance, software metrics, and software development methodologies. Additionally, you may want to look into specific quality metrics such as defect density, defect removal efficiency, and defect containment efficiency.  Ultimately, it will be important for you to track and analyze the metrics specific to your own projects to understand the relationship between development time and bug fixing time. This will help you establish a baseline standard and improve the overall quality of your software projects.",
        "Stack Overflow best answer": "The equilibrium percentage of total capacity allocated to defect-fixing is equal to the defect injection rate. Many factors can affect this rate, among them, of course: what kind of product the team is developing, what technologies and technical practices they use, the team's skill level, the company culture, etc. Considering Team B, if they create on average 8 units of rework for every 10 units of work they complete, then working those 8 units will create new 6.4 units of rework.  We can estimate the total effort they will eventually have to expend as the sum of a geometric progression: 10 + 8 + 6.4 + 5.12 + ... The number of bugs will decrease exponentially with time, but Team B has such a coefficient in their exponent that it will go to zero very slowly.  Actually, the sum of the first three terms in the above series is only 24.4; of the first five, 33.6; of the first 10, 45; of the entire series, 50.  So, Team B summary: defect injection rate, 0.8; feature development, 10/50 = 20%; defect-fixing, 80%.  20/80 is their sustainable capacity allocation. By contrast, Team A is in much better shape.  Their progression looks like this: 40 + 10 + 2.5 + 0.625 + ... The sum of this series is 53 1/3, so Team A's feature development allocation is 40/(53 1/3) = 75% and defect-fixing allocation is 25%, which matches their defect injection rate of 10/40 = 0.25. Actually, all terms in Team A's series after the first three are negligibly small.  What this means in practical terms is that Team A can probably squash all their bugs with a couple of maintenance releases, the second release being pretty small in scope.  This also creates an illusion that any team can do that.  But not Team B. I thought about this equivalence while reading David Anderson's new book, \"Kanban\".  (The book is on a different subject, but addresses quality concerns, too.)  When discussing software quality, Anderson quotes this book, by Capers Jones, \"Software Assessments, Benchmarks, and Best Practices\": \"...in 2000... measured software quality for North American teams... ranged from 6 defects per function point down to less than 3 per 100 function points, a range of 200 to 1.  The midpoint is approximately 1 defect per 0.6 to 1.0 function points.  This implies that it is common for teams to spend more than 90 percent of their effort fixing defects.\"  He cites an example provided by one of his colleagues of a company that spends 90% of the time fixing their bugs. The fluency with which Anderson goes from the defect injection rate to the defext-fixing capacity allocation (failure demand is the term for it) suggests that the equivalence of the two things is well known to software quality researchers and has probably been known for some time. The key words in the line of reasoning that I'm trying to present here are \"equlibrium\" and \"sustainable\".  If we take away sustainability, then there's an obvious way to cheat these numbers: you do the initial coding, then move on to code somewhere else, and leave maintenance to others.  Or you run up the technical debt and unload it on a new owner. Obviously, no particular allocation will suit all teams.  If we decreed that 20% must be spent on bugs, then, if a team has an ultra-low defect injection rate, they will simply not have enough bugs to fill the time, and if a team had a very high rate, their bugs will continue to accumulate. The math I used here is way simplified.  I neglected things like transaction costs (planning and estimation meetings, post-mortems, etc.), which would affect the percentages somewhat.  I also omitted equations simulating sustaining one product and developing another one concurrently.  But the conclusion still stands.  Do what you can, in terms of technical practices, like unit-testing, continuous integration, code reviews, etc., to reduce your defect injection rate and, consequently, your failure demand.  If you can create only one bug for every 10 features, you will have a lot of free time to develop new features and satisfy your customers. ",
        "Are the two answers equivalent?": "No"
    },
    {
        "ID": "3918",
        "Question": "What should you do, if a co-worker is editing your code?   Without the purpose of adding functionality or fixing bugs, just to change how it looks... ",
        "ChatGpt answer": "If a co-worker is editing your code just to change how it looks (i.e. formatting, indentation, commenting style), it is best to communicate with them directly and clarify your coding style preferences. It is important to have a discussion about coding standards and come to a mutual agreement on a consistent style to follow for the project. It is also important to ensure that the changes are not impacting the functionality of the code. If the changes are purely cosmetic and do not affect how the code runs, then it may not be a major issue. However, it is always best to work collaboratively and respect each other's coding preferences.",
        "Stack Overflow best answer": "Talk to them about it.  Go into the conversation with the attitude of \"They're not doing this to annoy me or because they have some form of obsessive-compulsive disorder; they're trying to make my code better.\" Because you could be wrong.  That could be a subtle bug fix and you just didn't spot it. Or, it could be that there's a coding standard you don't know about that you're violating, and they're just correcting it. Or, it could be that they're trying to annoy you, or they have some form of obsessive-compulsive disorder.  If that's the case, ask them nicely to stop, and if that doesn't work, take it up with your boss. But you'll never know unless you ask. ",
        "Are the two answers equivalent?": "Yes"
    },
    {
        "ID": "7455",
        "Question": "I mean, I still have a MSX2 with a Z80 processor and if you look at any Konami's game made for that computer in its time (roughly between '84 and '90) is amazing the high quality code of those games. I was a kid at the time, trying to learn how to program a computer and still today fascinated me how well made they are, mostly zero bugs or glitches, despite the really complex behavior. What hardware/software tools could they have used to accomplish that quality, which metodology? I know computers are really more complex today but at that time, even a stock control program I made in Basic was plagued with many bugs and was painful to debug. Any light you can shed will be deeply appreciated.  ",
        "ChatGpt answer": "It's great to hear about your appreciation for the high-quality code in Konami's games for the MSX2 back in the '80s and '90s. During that time, developers had to work with limited resources and tools compared to today, so they had to be extremely efficient in their coding practices.  One key factor that contributed to the quality of those games was the use of assembly language. Assembly language allows for more fine-tuned control over the hardware, which can lead to faster and more efficient code. By writing the code directly in assembly language, developers were able to optimize the code for the specific hardware of the MSX2.  Additionally, developers likely utilized debugging tools specific to the MSX2 platform, such as emulators and debuggers, to help identify and fix any issues that arose during development. These tools would have allowed developers to step through their code, track variables, and identify potential bugs more easily.  In terms of methodology, it's likely that developers followed best practices such as modularization, code reuse, and thorough testing to ensure the quality of their code. By breaking down the code into smaller, more manageable modules and reusing code where possible, developers could reduce the likelihood of bugs and improve the overall maintainability of the code. Additionally, thorough testing, both during development and after completion, would have helped catch any issues early on and ensure a high level of quality in the final product.  Overall, the combination of efficient coding practices, use of assembly language, specialized debugging tools, and adherence to best practices likely contributed to the high quality of the code in Konami's games for the MSX2 during that time.",
        "Stack Overflow best answer": "I don't know anything about Konami, so I'm taking an educated guess here.  Games on machines like the MSX would have required direct access to the hardware, so that pretty much limits the choice of languages to either C or Z80 assembly language.  (There were C compilers for the Z80 back then, for example this one.) I doubt if the games were completely written in C, if at all; mostly likely a lot of assembly code for performance reasons. As far as platforms go, since the MSX didn't have a hard drive, I would further assume the programs were initially written on a larger Z80 system, perhaps running CP/M.  For debugging, the code could probably have been downloaded into a special game cartridge for the MSX that had RAM memory in place of ROM -- this would have allowed the developer to download the program over and over again without burning ROM chips.  Debugging (e.g. setting breakpoints) could have been accomplished by replacing the Z80 inside the MSX with an In-Circuit Emulator (ICE) interface. ",
        "Are the two answers equivalent?": "No."
    },
    {
        "ID": "7927",
        "Question": "No one's perfect, and no matter what we do, we are going to produce code that has bugs in it from time to time. What are some methods/techniques for reducing the number of bugs you produce, both when writing new software and changing/maintaining existing code? ",
        "ChatGpt answer": "1. Write clean, readable code: By following best practices and standards, you can make your code more maintainable and easier to understand, reducing the chances of introducing bugs.  2. Use version control: By using version control systems like Git, you can easily track changes made to your code and revert back to a working version if needed.  3. Test early and often: Implement automated testing as part of your development process to catch bugs early on and ensure that changes do not introduce new issues.  4. Peer reviews: Have your code reviewed by other developers to get feedback and catch errors that you may have missed.  5. Refactor regularly: As code changes and evolves, take the time to refactor and clean up the code to reduce technical debt and prevent bugs from accumulating.  6. Use linters and static analysis tools: These tools can help identify common coding errors and enforce coding standards, reducing the chances of introducing bugs.  7. Document your code: Good documentation can help others understand your code and prevent misunderstandings that could lead to bugs.  8. Continuously learn and improve: Stay up to date with best practices, new technologies, and tools to improve your coding skills and reduce the likelihood of introducing bugs.",
        "Stack Overflow best answer": "Avoid fancy coding.  The more complicated the code, the more likely there's bugs.  Usually on modern systems, clearly written code will be fast and small enough. Use available libraries.  The easiest way to not have bugs writing a utility routine is to not write it. Learn a few formal techniques for the more complicated stuff.  If there's complicated conditions, nail them down with pen and paper.  Ideally, know some proof techniques.  If I can prove code correct, it's almost always good except for big, dumb, obvious bugs that are easy to fix.  Obviously, this only goes so far, but sometimes you can formally reason about small but complicated things. For existing code, learn how to refactor:  how to make small changes in the code, often using an automated tool, that make the code more readable without changing the behavior. Don't do anything too quickly.  Taking a little time up front to do things right, to check what you've done, and to think about what you're doing can pay off big time later. Once you've written the code, use what you've got to make it good.  Unit tests are great.  You can often write tests ahead of time, which can be great feedback (if done consistently, this is test-driven development). Compile with warning options, and pay attention to the warnings.   Get somebody else to look at the code.  Formal code reviews are good, but they may not be at a convenient time. Pull requests, or similar if your scm doesn't support them allow for asynchronous reviews. Buddy checking can be a less formal review. Pair programming ensures two pairs of eyes look at everything.  ",
        "Are the two answers equivalent?": "No"
    }
]